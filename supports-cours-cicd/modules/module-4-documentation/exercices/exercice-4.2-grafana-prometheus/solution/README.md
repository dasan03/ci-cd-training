# Solution - Exercice 4.2 : Configuration de dashboards avec Grafana et Prometheus

## Vue d'ensemble de la solution

Cette solution pr√©sente une impl√©mentation compl√®te d'une stack de monitoring avec Prometheus et Grafana pour les tests automatis√©s, incluant :
- Stack compl√®te Prometheus/Grafana/AlertManager avec Docker Compose
- Application Node.js exposant des m√©triques de tests personnalis√©es
- Dashboards Grafana interactifs avec visualisations avanc√©es
- Syst√®me d'alerting complet avec notifications
- Scripts d'automatisation et de d√©ploiement

## Architecture de la solution

```mermaid
graph TB
    A[Application de Tests] --> B[M√©triques Prometheus]
    B --> C[Prometheus Server]
    C --> D[Grafana Dashboard]
    C --> E[AlertManager]
    
    E --> F[Slack Notifications]
    E --> G[Email Alerts]
    
    H[Node Exporter] --> C
    I[Grafana Metrics] --> C
    
    D --> J[Test Dashboard]
    D --> K[Performance Dashboard]
    D --> L[Quality Dashboard]
```

## Points cl√©s de l'impl√©mentation

### 1. Stack de monitoring compl√®te

La solution utilise Docker Compose pour orchestrer tous les services :

```yaml
services:
  prometheus:     # Collecte et stockage des m√©triques
  grafana:        # Visualisation et dashboards
  alertmanager:   # Gestion des alertes
  node-exporter:  # M√©triques syst√®me
  test-metrics:   # Application de test avec m√©triques
```

**Avantages :**
- D√©ploiement simple avec une seule commande
- Isolation des services
- Configuration centralis√©e
- Scalabilit√© horizontale

### 2. M√©triques de tests personnalis√©es

L'application Node.js expose des m√©triques sp√©cifiques aux tests :

```javascript
// M√©triques principales
const testCounter = new client.Counter({
  name: 'tests_total',
  help: 'Total number of tests executed',
  labelNames: ['status', 'suite', 'environment', 'test_type']
});

const testDuration = new client.Histogram({
  name: 'test_duration_seconds',
  help: 'Time spent executing tests',
  buckets: [0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0]
});
```

**M√©triques collect√©es :**
- **Compteurs** : Nombre de tests par statut, suite, environnement
- **Histogrammes** : Distribution des temps d'ex√©cution
- **Jauges** : Tests actifs, taille de la queue, couverture, flakiness

### 3. Dashboards Grafana avanc√©s

Le dashboard principal inclut :

#### M√©triques de performance
- **Taux de r√©ussite** avec seuils color√©s
- **Tests actifs** en temps r√©el
- **Taille de la queue** avec alertes visuelles
- **Couverture de code** avec objectifs

#### Visualisations temporelles
- **Taux d'ex√©cution** des tests par seconde
- **Percentiles de dur√©e** (50e, 95e, 99e)
- **Tendances** sur diff√©rentes p√©riodes

#### Analyses de r√©partition
- **Tests par suite** (graphique en secteurs)
- **R√©sultats par statut** (passed/failed/skipped)
- **Flakiness par suite** (graphique en barres)

### 4. Syst√®me d'alerting intelligent

Les r√®gles d'alerte couvrent diff√©rents aspects :

```yaml
# Alerte sur taux d'√©chec √©lev√©
- alert: HighTestFailureRate
  expr: rate(tests_total{status="failed"}[5m]) / rate(tests_total[5m]) > 0.1
  for: 2m
  
# Alerte sur performance d√©grad√©e
- alert: SlowTestExecution
  expr: histogram_quantile(0.95, rate(test_duration_seconds_bucket[5m])) > 60
  for: 5m
```

**Fonctionnalit√©s avanc√©es :**
- **Seuils adaptatifs** selon le contexte
- **P√©riodes de gr√¢ce** pour √©viter les faux positifs
- **Routage intelligent** par √©quipe et s√©v√©rit√©
- **Inhibition** des alertes redondantes

## Configuration d√©taill√©e

### 1. Prometheus

#### Configuration des targets
```yaml
scrape_configs:
  - job_name: 'test-metrics'
    static_configs:
      - targets: ['test-metrics:8000']
    scrape_interval: 5s  # Collecte fr√©quente pour les tests
```

#### R√®gles d'alerte
- **Seuils bas√©s sur l'exp√©rience** : 10% d'√©chec, 60s de temps d'ex√©cution
- **P√©riodes d'observation** : 2-10 minutes selon la criticit√©
- **Labels enrichis** : √©quipe, s√©v√©rit√©, runbook

### 2. Grafana

#### Provisioning automatique
- **Sources de donn√©es** configur√©es automatiquement
- **Dashboards** d√©ploy√©s via JSON
- **Permissions** et organisations g√©r√©es

#### Panels optimis√©s
```json
{
  "fieldConfig": {
    "defaults": {
      "unit": "percent",
      "thresholds": {
        "steps": [
          {"color": "red", "value": 0},
          {"color": "yellow", "value": 80},
          {"color": "green", "value": 95}
        ]
      }
    }
  }
}
```

### 3. AlertManager

#### Routage par √©quipe
```yaml
routes:
- match:
    team: qa
  receiver: 'qa-team'
- match:
    severity: critical
  receiver: 'critical-alerts'
```

#### Notifications multiples
- **Slack** pour les alertes temps r√©el
- **Email** pour les alertes critiques
- **Webhooks** pour l'int√©gration avec d'autres outils

## Requ√™tes PromQL avanc√©es

### Analyse de performance

```promql
# D√©tection d'anomalies dans les temps d'ex√©cution
test_duration_seconds > on() group_left() (
  avg_over_time(test_duration_seconds[1h]) + 
  2 * stddev_over_time(test_duration_seconds[1h])
)

# Comparaison de performance entre environnements
histogram_quantile(0.95, 
  sum(rate(test_duration_seconds_bucket[5m])) by (environment, le)
)
```

### Analyse de qualit√©

```promql
# √âvolution du taux de r√©ussite par jour
increase(tests_total{status="passed"}[1d]) / 
increase(tests_total[1d]) * 100

# Tests les plus instables
topk(10, 
  sum(rate(tests_total{status="failed"}[1h])) by (test_name) /
  sum(rate(tests_total[1h])) by (test_name) * 100
)
```

### M√©triques m√©tier

```promql
# Temps moyen de feedback (du commit au r√©sultat de test)
avg(test_duration_seconds) + avg(build_duration_seconds)

# V√©locit√© de l'√©quipe (tests ajout√©s par semaine)
increase(tests_total[1w])
```

## Bonnes pratiques appliqu√©es

### 1. Nommage des m√©triques

- **Pr√©fixes coh√©rents** : `test_`, `build_`, `deploy_`
- **Unit√©s explicites** : `_seconds`, `_bytes`, `_total`
- **Labels pertinents** : environnement, √©quipe, version

### 2. Optimisation des performances

```javascript
// Buckets adapt√©s aux temps de test
buckets: [0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0]

// Collecte par d√©faut d√©sactiv√©e pour les m√©triques non pertinentes
client.collectDefaultMetrics({ 
  register,
  prefix: 'test_app_',
  gcDurationBuckets: [0.001, 0.01, 0.1, 1, 2, 5]
});
```

### 3. Gestion des alertes

- **Seuils bas√©s sur des donn√©es historiques**
- **P√©riodes de gr√¢ce** pour √©viter le bruit
- **Documentation** des runbooks pour chaque alerte
- **Tests r√©guliers** des canaux de notification

## Scripts d'automatisation

### D√©ploiement automatis√©

```bash
#!/bin/bash
# deploy-monitoring.sh

# V√©rification des pr√©requis
check_prerequisites() {
    command -v docker-compose >/dev/null 2>&1 || {
        echo "Docker Compose requis mais non install√©"
        exit 1
    }
}

# D√©ploiement avec v√©rifications
deploy_stack() {
    echo "üöÄ D√©ploiement de la stack de monitoring..."
    docker-compose up -d --build
    
    # Attente et v√©rification de sant√©
    wait_for_services
    verify_health
}
```

### Sauvegarde et restauration

```bash
# Sauvegarde des donn√©es Prometheus
docker run --rm -v prometheus-data:/data -v $(pwd):/backup \
  alpine tar czf /backup/prometheus-backup.tar.gz /data

# Restauration
docker run --rm -v prometheus-data:/data -v $(pwd):/backup \
  alpine tar xzf /backup/prometheus-backup.tar.gz -C /
```

## Monitoring de la stack elle-m√™me

### M√©triques de sant√©

```promql
# Disponibilit√© des services
up{job=~"prometheus|grafana|alertmanager"}

# Performance de Prometheus
prometheus_tsdb_head_samples_appended_total
prometheus_rule_evaluation_duration_seconds

# Utilisation m√©moire de Grafana
process_resident_memory_bytes{job="grafana"}
```

### Alertes sur l'infrastructure

```yaml
- alert: PrometheusDown
  expr: up{job="prometheus"} == 0
  for: 1m
  annotations:
    summary: "Prometheus is down"

- alert: GrafanaDown
  expr: up{job="grafana"} == 0
  for: 1m
  annotations:
    summary: "Grafana is down"
```

## Int√©grations avanc√©es

### 1. Int√©gration CI/CD

```yaml
# GitHub Actions
- name: Send metrics to Prometheus
  run: |
    curl -X POST http://prometheus:9090/api/v1/write \
      -H 'Content-Type: application/x-protobuf' \
      --data-binary @metrics.pb
```

### 2. Int√©gration Jira

```javascript
// Corr√©lation des m√©triques avec les tickets
const jiraIntegration = {
  linkTestFailureToTicket: (testName, error) => {
    // Cr√©ation automatique de ticket pour les √©checs r√©currents
  },
  updateTicketWithMetrics: (ticketId, metrics) => {
    // Mise √† jour des tickets avec les m√©triques de test
  }
};
```

### 3. Int√©gration Slack

```yaml
# AlertManager - Notifications enrichies
slack_configs:
- api_url: 'https://hooks.slack.com/services/...'
  channel: '#qa-alerts'
  title: 'Test Alert - {{ .GroupLabels.alertname }}'
  text: |
    {{ range .Alerts }}
    *Alert:* {{ .Annotations.summary }}
    *Description:* {{ .Annotations.description }}
    *Runbook:* {{ .Annotations.runbook_url }}
    *Dashboard:* http://grafana:3000/d/tests
    {{ end }}
```

## Analyse des r√©sultats

### M√©triques cl√©s √† surveiller

1. **Performance** :
   - Temps d'ex√©cution m√©dian et 95e percentile
   - Throughput (tests/seconde)
   - Temps de queue

2. **Qualit√©** :
   - Taux de r√©ussite global et par suite
   - Taux de flakiness
   - Couverture de code

3. **Fiabilit√©** :
   - Disponibilit√© des environnements de test
   - Stabilit√© des tests dans le temps
   - Temps de r√©cup√©ration apr√®s incident

### Tableaux de bord par audience

#### Dashboard D√©veloppeur
- Focus sur les tests unitaires et d'int√©gration
- M√©triques de couverture de code
- Temps de feedback rapide

#### Dashboard QA
- Vue d'ensemble de tous les types de tests
- Analyse des √©checs et de la flakiness
- Tendances de qualit√©

#### Dashboard Management
- KPIs de haut niveau
- Tendances sur plusieurs semaines/mois
- Impact sur la v√©locit√© de l'√©quipe

## Maintenance et √©volution

### Optimisation continue

1. **R√©vision des seuils d'alerte** bas√©e sur l'historique
2. **Ajustement des buckets** d'histogrammes selon les donn√©es r√©elles
3. **Nettoyage des m√©triques** obsol√®tes
4. **Optimisation des requ√™tes** PromQL lentes

### √âvolutions recommand√©es

1. **Machine Learning** pour la d√©tection d'anomalies
2. **Pr√©diction** des √©checs bas√©e sur les tendances
3. **Corr√©lation automatique** entre m√©triques et √©v√©nements
4. **Optimisation automatique** des seuils d'alerte

## Troubleshooting avanc√©

### Probl√®mes de performance

```bash
# Analyse de la consommation m√©moire de Prometheus
docker exec prometheus promtool query instant \
  'prometheus_tsdb_head_series'

# V√©rification des m√©triques les plus co√ªteuses
docker exec prometheus promtool query instant \
  'topk(10, count by (__name__)({__name__=~".+"}))'
```

### Probl√®mes de collecte

```bash
# V√©rification des targets
curl http://localhost:9090/api/v1/targets

# Test de connectivit√©
docker exec prometheus wget -qO- http://test-metrics:8000/metrics
```

### Probl√®mes d'alerting

```bash
# V√©rification des r√®gles d'alerte
curl http://localhost:9090/api/v1/rules

# Test des notifications
curl -X POST http://localhost:9093/api/v1/alerts \
  -H 'Content-Type: application/json' \
  -d '[{"labels":{"alertname":"TestAlert"}}]'
```

## Conclusion

Cette solution fournit :
- **Monitoring complet** des tests avec m√©triques personnalis√©es
- **Visualisations riches** adapt√©es √† diff√©rentes audiences
- **Alerting intelligent** avec routage et notifications
- **Automatisation** du d√©ploiement et de la maintenance
- **Extensibilit√©** pour l'ajout de nouvelles m√©triques et int√©grations

L'impl√©mentation de cette stack de monitoring am√©liore significativement la visibilit√© sur la qualit√© et les performances des tests, permettant une approche proactive de l'am√©lioration continue et une d√©tection rapide des r√©gressions.