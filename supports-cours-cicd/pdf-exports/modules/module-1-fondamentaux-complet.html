<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Module 1 - Fondamentaux CI/CD</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 2cm; line-height: 1.6; }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; }
        h2 { color: #34495e; margin-top: 2em; }
        h3 { color: #7f8c8d; }
        code { background: #f8f9fa; padding: 2px 4px; border-radius: 3px; }
        pre { background: #f8f9fa; padding: 1em; border-radius: 5px; overflow-x: auto; }
        li { margin: 0.5em 0; }
        @media print {
            body { margin: 1cm; }
            h1 { page-break-before: always; }
        }
    </style>
</head>
<body>
    <h1>Module 1 - Fondamentaux CI/CD</h1>
    <h1>Module 1 - Fondamentaux CI/CD</h1><br><br><h1>Module 1 - Fondamentaux CI/CD</h1><br><br><h2>üìã Informations G√©n√©rales</h2><br><br><li><strong>Dur√©e</strong> : 4 heures</li><br><li><strong>Niveau</strong> : D√©butant</li><br><li><strong>Pr√©requis</strong> : Bases du d√©veloppement logiciel, notions de Git</li><br><li><strong>Comp√©tences</strong> : C8, C17</li><br><br><h2>üéØ Objectifs P√©dagogiques</h2><br><br>√Ä l'issue de ce module, vous serez capable de :<br><li>Comprendre les concepts fondamentaux CI/CD</li><br><li>Diff√©rencier les tests manuels et automatis√©s</li><br><li>Configurer un pipeline CI/CD de base</li><br><li>Int√©grer des tests automatis√©s dans un pipeline</li><br><li>Utiliser GitHub Actions et Docker pour l'automatisation</li><br><br><h2>üìö Table des Mati√®res</h2><br><br><h3>[üìñ Support Th√©orique](support-theorique.md)</h3><br><br>#### Section 1 : Introduction aux Concepts CI/CD (45 min)<br><li>[1.1 Qu'est-ce que CI/CD ?](support-theorique.md#11-quest-ce-que-cicd)</li><br><li>[1.2 Diff√©rences tests manuels vs automatis√©s](support-theorique.md#12-tests-manuels-vs-automatises)</li><br><li>[1.3 Avantages de l'automatisation](support-theorique.md#13-avantages-automatisation)</li><br><li><strong>[üíª Exercice associ√©](../../exercices/module-1/exercice-1-1.md)</strong> : Premier pipeline CI/CD</li><br><br>#### Section 2 : Types et Cat√©gories de Tests (45 min)<br><li>[2.1 Tests unitaires, d'int√©gration, fonctionnels](support-theorique.md#21-types-de-tests)</li><br><li>[2.2 Pyramide des tests](support-theorique.md#22-pyramide-des-tests)</li><br><li>[2.3 Tests de r√©gression](support-theorique.md#23-tests-regression)</li><br><li><strong>[üíª Exercice associ√©](../../exercices/module-1/exercice-1-2.md)</strong> : Configuration de tests automatis√©s</li><br><br>#### Section 3 : Int√©gration des Tests dans CI/CD (45 min)<br><li>[3.1 Strat√©gies d'int√©gration](support-theorique.md#31-strategies-integration)</li><br><li>[3.2 Tests en parall√®le](support-theorique.md#32-tests-paralleles)</li><br><li>[3.3 Gestion des √©checs](support-theorique.md#33-gestion-echecs)</li><br><li><strong>[üíª Exercice associ√©](../../exercices/module-1/exercice-1-3.md)</strong> : Int√©gration de tests en parall√®le</li><br><br>#### Section 4 : Outils et Bonnes Pratiques (45 min)<br><li>[4.1 GitHub Actions](support-theorique.md#41-github-actions)</li><br><li>[4.2 Jenkins](support-theorique.md#42-jenkins)</li><br><li>[4.3 Docker pour les tests](support-theorique.md#43-docker-tests)</li><br><li>[4.4 Bonnes pratiques](support-theorique.md#44-bonnes-pratiques)</li><br><br><h3>[üíª Exercices Pratiques](../../exercices/module-1/README.md)</h3><br><br>| Exercice | Titre | Dur√©e | Difficult√© | Outils |<br>|----------|-------|-------|------------|--------|<br>| <strong>[1.1](../../exercices/module-1/exercice-1-1.md)</strong> | Premier pipeline CI/CD avec GitHub Actions | 30 min | üü¢ D√©butant | GitHub Actions, Docker |<br>| <strong>[1.2](../../exercices/module-1/exercice-1-2.md)</strong> | Configuration de tests automatis√©s avec Docker | 30 min | üü¢ D√©butant | Docker, PyTest |<br>| <strong>[1.3](../../exercices/module-1/exercice-1-3.md)</strong> | Int√©gration de tests en parall√®le | 30 min | üü° Interm√©diaire | GitHub Actions, Matrix |<br><br><h3>[‚úÖ QCM Interm√©diaire](../../evaluations/qcm-intermediaires/module-1-qcm.md)</h3><br><br><li><strong>8 questions</strong> couvrant tous les concepts</li><br><li><strong>Dur√©e</strong> : 15 minutes</li><br><li><strong>Seuil de r√©ussite</strong> : 6/8 (75%)</li><br><li><strong>Comp√©tences √©valu√©es</strong> : C8, C17</li><br><br>#### R√©partition des Questions<br><li>Questions 1-2 : Concepts CI/CD</li><br><li>Questions 3-4 : Types de tests</li><br><li>Questions 5-6 : Int√©gration dans pipelines</li><br><li>Questions 7-8 : Outils et bonnes pratiques</li><br><br><h2>üîó Liens Crois√©s</h2><br><br><h3>Vers les Autres Modules</h3><br><li><strong>[Module 2](../module-2-ia-tests/README.md)</strong> : Approfondissement avec l'IA</li><br><li><strong>[Module 3](../module-3-tests-fonctionnels/README.md)</strong> : Tests fonctionnels avanc√©s</li><br><li><strong>[Module 4](../module-4-documentation/README.md)</strong> : Documentation des pipelines</li><br><br><h3>Vers les Ressources</h3><br><li><strong>[Templates GitHub Actions](../../ressources/templates/github-actions-templates.md)</strong></li><br><li><strong>[Configuration Docker](../../ressources/outils/docker-setup.md)</strong></li><br><li><strong>[Troubleshooting](../../ressources/troubleshooting.md#module-1)</strong></li><br><br><h3>Comp√©tences D√©velopp√©es</h3><br><li><strong>[C8 - TDD](../../index.md#c8---test-driven-development-tdd)</strong> : Sections 2.1, 2.2 + Exercices 1.2, 1.3</li><br><li><strong>[C17 - Tests CI/CD](../../index.md#c17---tests-automatises-dans-cicd)</strong> : Toutes les sections + Tous les exercices</li><br><br><h2>üìÖ Planning D√©taill√©</h2><br><br><h3>Matin (4h) - Jour 1</h3><br><br>| Horaire | Activit√© | Dur√©e | Type |<br>|---------|----------|-------|------|<br>| 09:00-09:45 | [Section 1 : Concepts CI/CD](support-theorique.md#section-1) | 45 min | üìñ Th√©orie |<br>| 09:45-10:15 | [Exercice 1.1 : Premier pipeline](../../exercices/module-1/exercice-1-1.md) | 30 min | üíª Pratique |<br>| 10:15-10:30 | <strong>Pause</strong> | 15 min | ‚òï |<br>| 10:30-11:15 | [Section 2 : Types de tests](support-theorique.md#section-2) | 45 min | üìñ Th√©orie |<br>| 11:15-11:45 | [Exercice 1.2 : Tests automatis√©s](../../exercices/module-1/exercice-1-2.md) | 30 min | üíª Pratique |<br>| 11:45-12:30 | [Section 3 : Int√©gration tests](support-theorique.md#section-3) | 45 min | üìñ Th√©orie |<br>| 12:30-13:00 | [Exercice 1.3 : Tests parall√®les](../../exercices/module-1/exercice-1-3.md) | 30 min | üíª Pratique |<br>| 13:00-13:15 | [QCM Module 1](../../evaluations/qcm-intermediaires/module-1-qcm.md) | 15 min | ‚úÖ √âvaluation |<br><br><h2>üõ†Ô∏è Pr√©requis Techniques</h2><br><br><h3>Logiciels Requis</h3><br><li><strong>Git</strong> (version 2.30+)</li><br><li><strong>Docker</strong> (version 20.10+)</li><br><li><strong>√âditeur de code</strong> (VS Code recommand√©)</li><br><li><strong>Navigateur web</strong> moderne</li><br><br><h3>Comptes N√©cessaires</h3><br><li><strong>GitHub</strong> (compte gratuit)</li><br><li><strong>Docker Hub</strong> (compte gratuit)</li><br><br><h3>Configuration</h3><br><li><strong>[Guide d'installation](../../ressources/outils/installation-guide.md#module-1)</strong></li><br><li><strong>[V√©rification environnement](../../ressources/outils/environment-check.md)</strong></li><br><br><h2>üìä √âvaluation et Validation</h2><br><br><h3>Crit√®res de R√©ussite</h3><br><li>‚úÖ Compl√©tion des 3 exercices pratiques</li><br><li>‚úÖ Score minimum 6/8 au QCM interm√©diaire</li><br><li>‚úÖ D√©monstration d'un pipeline fonctionnel</li><br><br><h3>Indicateurs de Progression</h3><br><li><strong>D√©butant</strong> : Comprend les concepts, suit les exercices guid√©s</li><br><li><strong>Interm√©diaire</strong> : Adapte les solutions, r√©sout les probl√®mes mineurs</li><br><li><strong>Avanc√©</strong> : Propose des am√©liorations, aide les autres participants</li><br><br><h2>üÜò Support et Aide</h2><br><br><h3>Pendant le Module</h3><br><li><strong>Formateur</strong> disponible en permanence</li><br><li><strong>Documentation</strong> compl√®te fournie</li><br><li><strong>Pair programming</strong> encourag√©</li><br><br><h3>Ressources d'Aide</h3><br><li><strong>[FAQ Module 1](../../ressources/faq-technique.md#module-1)</strong></li><br><li><strong>[Troubleshooting](../../ressources/troubleshooting.md#module-1)</strong></li><br><li><strong>[Glossaire](../../ressources/glossaire.md)</strong></li><br><br>---<br><br><h2>üß≠ Navigation</h2><br><br><h3>Navigation Principale</h3><br><li><strong>[‚¨ÖÔ∏è Retour aux modules](../README.md)</strong></li><br><li><strong>[üè† Index g√©n√©ral](../../index.md)</strong></li><br><li><strong>[‚û°Ô∏è Module 2](../module-2-ia-tests/README.md)</strong></li><br><br><h3>Navigation Interne</h3><br><li><strong>[üìñ Commencer la th√©orie](support-theorique.md)</strong></li><br><li><strong>[üíª Voir les exercices](../../exercices/module-1/README.md)</strong></li><br><li><strong>[‚úÖ Passer le QCM](../../evaluations/qcm-intermediaires/module-1-qcm.md)</strong></li><br><br><h3>Outils Formateur</h3><br><li><strong>[üìä Tableau de bord](../../guides/guide-formateur.md#module-1)</strong></li><br><li><strong>[üéØ Objectifs p√©dagogiques](../../guides/guide-formateur.md#objectifs-module-1)</strong></li><br><li><strong>[‚è±Ô∏è Gestion du temps](../../guides/guide-formateur.md#timing-module-1)</strong></li><br><br><em>Derni√®re mise √† jour : [Date] | Version : 1.0</em><br><br>\newpage<br><br><h1>Support Th√©orique</h1><br><br><h1>1. Introduction √† l'Automatisation des Tests</h1><br><br><h2>üéØ Objectifs d'Apprentissage</h2><br><br>√Ä l'issue de cette section, vous serez capable de :<br><li>Distinguer les tests manuels des tests automatis√©s</li><br><li>Identifier les avantages et inconv√©nients de chaque approche</li><br><li>Comprendre les diff√©rentes cat√©gories de tests automatis√©s</li><br><li>Positionner les tests dans la pyramide de test</li><br><br><h2>üìã Tests Manuels vs Tests Automatis√©s</h2><br><br><h3>Tests Manuels</h3><br><br>#### D√©finition<br>Les tests manuels sont ex√©cut√©s par des testeurs humains qui interagissent directement avec l'application pour v√©rifier son comportement.<br><br>#### Avantages ‚úÖ<br><li><strong>Flexibilit√©</strong> : Adaptation rapide aux changements</li><br><li><strong>Cr√©ativit√©</strong> : D√©couverte de bugs inattendus</li><br><li><strong>Tests exploratoires</strong> : Investigation approfondie</li><br><li><strong>Tests d'utilisabilit√©</strong> : √âvaluation de l'exp√©rience utilisateur</li><br><li><strong>Co√ªt initial faible</strong> : Pas de d√©veloppement de scripts</li><br><br>#### Inconv√©nients ‚ùå<br><li><strong>Temps d'ex√©cution</strong> : Lent et r√©p√©titif</li><br><li><strong>Erreur humaine</strong> : Risque d'oublis ou d'incoh√©rences</li><br><li><strong>Co√ªt √† long terme</strong> : Ressources humaines importantes</li><br><li><strong>Reproductibilit√©</strong> : Difficile √† standardiser</li><br><li><strong>Couverture limit√©e</strong> : Impossible de tester tous les cas</li><br><br><h3>Tests Automatis√©s</h3><br><br>#### D√©finition<br>Les tests automatis√©s sont ex√©cut√©s par des scripts ou des outils qui simulent les interactions utilisateur et v√©rifient automatiquement les r√©sultats.<br><br>#### Avantages ‚úÖ<br><li><strong>Rapidit√©</strong> : Ex√©cution en quelques minutes/heures</li><br><li><strong>Reproductibilit√©</strong> : R√©sultats coh√©rents et fiables</li><br><li><strong>Couverture √©tendue</strong> : Tests de r√©gression complets</li><br><li><strong>Ex√©cution continue</strong> : Int√©gration dans les pipelines CI/CD</li><br><li><strong>ROI √† long terme</strong> : √âconomies sur la dur√©e</li><br><br>#### Inconv√©nients ‚ùå<br><li><strong>Co√ªt initial √©lev√©</strong> : D√©veloppement et maintenance des scripts</li><br><li><strong>Rigidit√©</strong> : Adaptation difficile aux changements d'interface</li><br><li><strong>Faux positifs/n√©gatifs</strong> : Scripts fragiles</li><br><li><strong>Comp√©tences techniques</strong> : Expertise en programmation requise</li><br><li><strong>Maintenance</strong> : Mise √† jour constante des scripts</li><br><br><h2>üèóÔ∏è Cat√©gories de Tests Automatis√©s</h2><br><br><h3>1. Tests Unitaires</h3><br><br>#### D√©finition<br>Tests qui v√©rifient le comportement d'une unit√© de code isol√©e (fonction, m√©thode, classe).<br><br>#### Caract√©ristiques<br><li><strong>Port√©e</strong> : Tr√®s limit√©e (une fonction)</li><br><li><strong>Vitesse</strong> : Tr√®s rapide (millisecondes)</li><br><li><strong>Isolation</strong> : Aucune d√©pendance externe</li><br><li><strong>Maintenance</strong> : Faible</li><br><br>#### Exemple<br><pre><code>python<br>def test_addition():<br>    assert add(2, 3) == 5<br>    assert add(-1, 1) == 0<br>    assert add(0, 0) == 0<br></code></pre><br><br><h3>2. Tests d'Int√©gration</h3><br><br>#### D√©finition<br>Tests qui v√©rifient l'interaction entre plusieurs composants ou modules.<br><br>#### Types<br><li><strong>Int√©gration de composants</strong> : Entre modules de l'application</li><br><li><strong>Int√©gration de syst√®mes</strong> : Entre applications diff√©rentes</li><br><li><strong>Int√©gration d'API</strong> : Entre services web</li><br><br>#### Exemple<br><pre><code>python<br>def test_user_registration_integration():<br>    # Test de l'int√©gration entre le service utilisateur et la base de donn√©es<br>    user_service = UserService()<br>    user_data = {"name": "John", "email": "john@example.com"}<br>    <br>    user_id = user_service.create_user(user_data)<br>    retrieved_user = user_service.get_user(user_id)<br>    <br>    assert retrieved_user.name == "John"<br>    assert retrieved_user.email == "john@example.com"<br></code></pre><br><br><h3>3. Tests End-to-End (E2E)</h3><br><br>#### D√©finition<br>Tests qui simulent un parcours utilisateur complet √† travers l'application.<br><br>#### Caract√©ristiques<br><li><strong>Port√©e</strong> : Application compl√®te</li><br><li><strong>Vitesse</strong> : Lent (minutes)</li><br><li><strong>R√©alisme</strong> : Proche de l'utilisation r√©elle</li><br><li><strong>Complexit√©</strong> : √âlev√©e</li><br><br>#### Exemple<br><pre><code>javascript<br>// Test Cypress E2E<br>describe('User Login Flow', () => {<br>  it('should allow user to login and access dashboard', () => {<br>    cy.visit('/login')<br>    cy.get('[data-cy=email]').type('user@example.com')<br>    cy.get('[data-cy=password]').type('password123')<br>    cy.get('[data-cy=login-button]').click()<br>    <br>    cy.url().should('include', '/dashboard')<br>    cy.get('[data-cy=welcome-message]').should('contain', 'Welcome')<br>  })<br>})<br></code></pre><br><br><h3>4. Tests Non-Fonctionnels</h3><br><br>#### Tests de Performance<br>V√©rifient les temps de r√©ponse, le d√©bit et la consommation de ressources.<br><br><pre><code>bash<br><h1>Exemple avec JMeter</h1><br>jmeter -n -t test-plan.jmx -l results.jtl<br></code></pre><br><br>#### Tests de S√©curit√©<br>Identifient les vuln√©rabilit√©s et failles de s√©curit√©.<br><br><pre><code>bash<br><h1>Exemple avec OWASP ZAP</h1><br>zap-baseline.py -t https://example.com<br></code></pre><br><br>#### Tests de Charge<br>√âvaluent le comportement sous forte charge utilisateur.<br><br><h2>üìä La Pyramide de Test</h2><br><br><h3>Structure de la Pyramide</h3><br><br><pre><code><br>        /\<br>       /  \<br>      / E2E \<br>     /______\<br>    /        \<br>   /Integration\<br>  /__________\<br> /            \<br>/   Unitaires  \<br>/______________\<br></code></pre><br><br><h3>R√©partition Recommand√©e</h3><br><li><strong>70% Tests Unitaires</strong> : Base solide, rapides et fiables</li><br><li><strong>20% Tests d'Int√©gration</strong> : V√©rification des interactions</li><br><li><strong>10% Tests E2E</strong> : Validation des parcours critiques</li><br><br><h3>Principes</h3><br>1. <strong>Plus on monte, plus c'est lent</strong> : Les tests E2E prennent plus de temps<br>2. <strong>Plus on monte, plus c'est fragile</strong> : Les tests E2E sont plus susceptibles de casser<br>3. <strong>Plus on monte, plus c'est cher</strong> : Co√ªt de d√©veloppement et maintenance √©lev√©<br><br><h2>üîÑ Cycle de Vie des Tests Automatis√©s</h2><br><br><h3>1. Planification</h3><br><li>Identification des cas de test √† automatiser</li><br><li>Priorisation selon le ROI</li><br><li>Choix des outils et frameworks</li><br><br><h3>2. D√©veloppement</h3><br><li>√âcriture des scripts de test</li><br><li>Mise en place de l'infrastructure</li><br><li>Configuration des environnements</li><br><br><h3>3. Ex√©cution</h3><br><li>Lancement des tests</li><br><li>Collecte des r√©sultats</li><br><li>Analyse des √©checs</li><br><br><h3>4. Maintenance</h3><br><li>Mise √† jour des scripts</li><br><li>Optimisation des performances</li><br><li>Refactoring du code de test</li><br><br><h2>üéØ Crit√®res de S√©lection pour l'Automatisation</h2><br><br><h3>Tests √† Automatiser ‚úÖ</h3><br><li><strong>Tests de r√©gression</strong> : Ex√©cut√©s fr√©quemment</li><br><li><strong>Tests r√©p√©titifs</strong> : M√™me sc√©nario, donn√©es diff√©rentes</li><br><li><strong>Tests critiques</strong> : Fonctionnalit√©s essentielles</li><br><li><strong>Tests de performance</strong> : Impossible manuellement</li><br><li><strong>Tests sur plusieurs environnements</strong> : Navigateurs, OS</li><br><br><h3>Tests √† Garder Manuels ‚ùå</h3><br><li><strong>Tests exploratoires</strong> : Cr√©ativit√© humaine requise</li><br><li><strong>Tests d'utilisabilit√©</strong> : Ressenti utilisateur</li><br><li><strong>Tests ad-hoc</strong> : Ex√©cution ponctuelle</li><br><li><strong>Tests complexes</strong> : ROI n√©gatif</li><br><li><strong>Tests d'accessibilit√©</strong> : Jugement humain n√©cessaire</li><br><br><h2>üìà M√©triques et Indicateurs</h2><br><br><h3>M√©triques de Couverture</h3><br><li><strong>Couverture de code</strong> : Pourcentage de code test√©</li><br><li><strong>Couverture fonctionnelle</strong> : Pourcentage de fonctionnalit√©s test√©es</li><br><li><strong>Couverture de r√©gression</strong> : Tests de non-r√©gression</li><br><br><h3>M√©triques de Qualit√©</h3><br><li><strong>Taux de d√©tection de bugs</strong> : Bugs trouv√©s par les tests</li><br><li><strong>Temps de feedback</strong> : D√©lai entre commit et r√©sultat</li><br><li><strong>Stabilit√© des tests</strong> : Pourcentage de tests stables</li><br><br><h3>M√©triques de Performance</h3><br><li><strong>Temps d'ex√©cution</strong> : Dur√©e totale des tests</li><br><li><strong>Parall√©lisation</strong> : Nombre de tests en parall√®le</li><br><li><strong>Utilisation des ressources</strong> : CPU, m√©moire, r√©seau</li><br><br><h2>üõ†Ô∏è Bonnes Pratiques</h2><br><br><h3>1. Strat√©gie de Test</h3><br><li>Suivre la pyramide de test</li><br><li>Prioriser selon la criticit√© business</li><br><li>Maintenir un √©quilibre co√ªt/b√©n√©fice</li><br><br><h3>2. Conception des Tests</h3><br><li>Tests ind√©pendants et isol√©s</li><br><li>Donn√©es de test g√©r√©es proprement</li><br><li>Assertions claires et sp√©cifiques</li><br><br><h3>3. Maintenance</h3><br><li>Refactoring r√©gulier du code de test</li><br><li>Suppression des tests obsol√®tes</li><br><li>Documentation √† jour</li><br><br><h3>4. Int√©gration CI/CD</h3><br><li>Ex√©cution automatique sur chaque commit</li><br><li>Feedback rapide aux d√©veloppeurs</li><br><li>Blocage des d√©ploiements en cas d'√©chec</li><br><br><h2>üéì Points Cl√©s √† Retenir</h2><br><br>1. <strong>Compl√©mentarit√©</strong> : Tests manuels et automatis√©s se compl√®tent<br>2. <strong>Pyramide de test</strong> : Fondation solide avec les tests unitaires<br>3. <strong>ROI</strong> : L'automatisation est un investissement √† long terme<br>4. <strong>Maintenance</strong> : Les tests automatis√©s n√©cessitent une maintenance continue<br>5. <strong>Strat√©gie</strong> : Choisir les bons tests √† automatiser est crucial<br><br>---<br><br><strong>Prochaine section :</strong> [Mise en place d'un pipeline CI/CD de base](02-pipeline-cicd-base.md)<br><br><strong>Comp√©tences travaill√©es :</strong> C8, C17  <br><strong>Dur√©e estim√©e :</strong> 90 minutes<br><br><h1>2. Mise en Place d'un Pipeline CI/CD de Base</h1><br><br><h2>üéØ Objectifs d'Apprentissage</h2><br><br>√Ä l'issue de cette section, vous serez capable de :<br><li>Comprendre les concepts fondamentaux de CI/CD</li><br><li>Diff√©rencier CI, CD (Delivery) et CD (Deployment)</li><br><li>Identifier les composants d'un pipeline CI/CD</li><br><li>Configurer un pipeline simple avec GitHub Actions</li><br><br><h2>üîÑ Concepts Fondamentaux CI/CD</h2><br><br><h3>Continuous Integration (CI)</h3><br><br>#### D√©finition<br>L'int√©gration continue est une pratique de d√©veloppement o√π les d√©veloppeurs int√®grent fr√©quemment leur code dans un d√©p√¥t partag√©, d√©clenchant automatiquement des builds et des tests.<br><br>#### Principes Cl√©s<br><li><strong>Commits fr√©quents</strong> : Int√©gration plusieurs fois par jour</li><br><li><strong>Build automatique</strong> : Compilation automatique du code</li><br><li><strong>Tests automatiques</strong> : Validation imm√©diate des changements</li><br><li><strong>Feedback rapide</strong> : Notification imm√©diate des probl√®mes</li><br><br>#### B√©n√©fices<br><li><strong>D√©tection pr√©coce des bugs</strong> : Probl√®mes identifi√©s rapidement</li><br><li><strong>R√©duction des conflits</strong> : Int√©gration fr√©quente √©vite les gros merges</li><br><li><strong>Qualit√© constante</strong> : Validation continue du code</li><br><li><strong>Confiance accrue</strong> : Base de code toujours stable</li><br><br><h3>Continuous Delivery (CD)</h3><br><br>#### D√©finition<br>La livraison continue √©tend la CI en automatisant la pr√©paration des releases, rendant le code toujours pr√™t √† √™tre d√©ploy√© en production.<br><br>#### Caract√©ristiques<br><li><strong>Automatisation compl√®te</strong> : Du code √† l'environnement de staging</li><br><li><strong>D√©ploiement manuel</strong> : D√©cision humaine pour la production</li><br><li><strong>Environnements identiques</strong> : Coh√©rence dev/staging/prod</li><br><li><strong>Rollback facile</strong> : Retour en arri√®re rapide si n√©cessaire</li><br><br><h3>Continuous Deployment (CD)</h3><br><br>#### D√©finition<br>Le d√©ploiement continu pousse l'automatisation jusqu'au d√©ploiement automatique en production apr√®s validation des tests.<br><br>#### Diff√©rences avec Delivery<br><li><strong>D√©ploiement automatique</strong> : Aucune intervention humaine</li><br><li><strong>Tests exhaustifs</strong> : Couverture de test tr√®s √©lev√©e requise</li><br><li><strong>Monitoring avanc√©</strong> : Surveillance continue de la production</li><br><li><strong>Culture DevOps mature</strong> : Organisation adapt√©e aux changements fr√©quents</li><br><br><h2>üèóÔ∏è Architecture d'un Pipeline CI/CD</h2><br><br><h3>Composants Principaux</h3><br><br><pre><code>mermaid<br>graph LR<br>    A[Code Source] --> B[Build]<br>    B --> C[Tests Unitaires]<br>    C --> D[Tests d'Int√©gration]<br>    D --> E[Packaging]<br>    E --> F[D√©ploiement Staging]<br>    F --> G[Tests E2E]<br>    G --> H[D√©ploiement Production]<br></code></pre><br><br><h3>1. Source Control</h3><br><li><strong>Git</strong> : Gestion de versions distribu√©e</li><br><li><strong>Branches</strong> : Strat√©gies de branching (GitFlow, GitHub Flow)</li><br><li><strong>Pull Requests</strong> : Revue de code et validation</li><br><br><h3>2. Build Stage</h3><br><li><strong>Compilation</strong> : Transformation du code source</li><br><li><strong>Gestion des d√©pendances</strong> : Installation des packages</li><br><li><strong>Optimisation</strong> : Minification, bundling</li><br><li><strong>Artefacts</strong> : Production des livrables</li><br><br><h3>3. Test Stage</h3><br><li><strong>Tests unitaires</strong> : Validation des composants isol√©s</li><br><li><strong>Tests d'int√©gration</strong> : V√©rification des interactions</li><br><li><strong>Tests de s√©curit√©</strong> : Scan des vuln√©rabilit√©s</li><br><li><strong>Analyse de code</strong> : Qualit√© et conformit√©</li><br><br><h3>4. Deploy Stage</h3><br><li><strong>Environnements</strong> : Dev, Staging, Production</li><br><li><strong>Strat√©gies</strong> : Blue-Green, Rolling, Canary</li><br><li><strong>Configuration</strong> : Gestion des variables d'environnement</li><br><li><strong>Monitoring</strong> : Surveillance post-d√©ploiement</li><br><br><h2>üõ†Ô∏è Outils CI/CD Populaires</h2><br><br><h3>Plateformes Cloud</h3><br><li><strong>GitHub Actions</strong> : Int√©gr√© √† GitHub, workflows YAML</li><br><li><strong>GitLab CI/CD</strong> : Pipeline as Code, runners distribu√©s</li><br><li><strong>Azure DevOps</strong> : Suite compl√®te Microsoft</li><br><li><strong>AWS CodePipeline</strong> : Service AWS natif</li><br><br><h3>Solutions On-Premise</h3><br><li><strong>Jenkins</strong> : Open source, tr√®s extensible</li><br><li><strong>TeamCity</strong> : JetBrains, interface intuitive</li><br><li><strong>Bamboo</strong> : Atlassian, int√©gration Jira</li><br><li><strong>CircleCI</strong> : Cloud et on-premise</li><br><br><h3>Outils Sp√©cialis√©s</h3><br><li><strong>Docker</strong> : Containerisation des applications</li><br><li><strong>Kubernetes</strong> : Orchestration de conteneurs</li><br><li><strong>Terraform</strong> : Infrastructure as Code</li><br><li><strong>Ansible</strong> : Automatisation de configuration</li><br><br><h2>üöÄ GitHub Actions - Introduction</h2><br><br><h3>Concepts de Base</h3><br><br>#### Workflow<br>Processus automatis√© d√©fini dans un fichier YAML, d√©clench√© par des √©v√©nements.<br><br><pre><code>yaml<br>name: CI Pipeline<br>on:<br>  push:<br>    branches: [ main, develop ]<br>  pull_request:<br>    branches: [ main ]<br></code></pre><br><br>#### Jobs<br>Ensemble d'√©tapes ex√©cut√©es sur un runner.<br><br><pre><code>yaml<br>jobs:<br>  build:<br>    runs-on: ubuntu-latest<br>    steps:<br>      - uses: actions/checkout@v3<br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: '18'<br></code></pre><br><br>#### Actions<br>Composants r√©utilisables pour automatiser des t√¢ches.<br><br><pre><code>yaml<br><li>name: Run tests</li><br>  run: npm test<br><li>name: Upload coverage</li><br>  uses: codecov/codecov-action@v3<br></code></pre><br><br><h3>Structure d'un Workflow</h3><br><br><pre><code>yaml<br>name: Complete CI/CD Pipeline<br><br>on:<br>  push:<br>    branches: [ main ]<br>  pull_request:<br>    branches: [ main ]<br><br>env:<br>  NODE_VERSION: '18'<br><br>jobs:<br>  test:<br>    runs-on: ubuntu-latest<br>    steps:<br>      - name: Checkout code<br>        uses: actions/checkout@v3<br>      <br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: ${{ env.NODE_VERSION }}<br>          cache: 'npm'<br>      <br>      - name: Install dependencies<br>        run: npm ci<br>      <br>      - name: Run linting<br>        run: npm run lint<br>      <br>      - name: Run unit tests<br>        run: npm test -- --coverage<br>      <br>      - name: Upload coverage reports<br>        uses: codecov/codecov-action@v3<br><br>  build:<br>    needs: test<br>    runs-on: ubuntu-latest<br>    steps:<br>      - name: Checkout code<br>        uses: actions/checkout@v3<br>      <br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: ${{ env.NODE_VERSION }}<br>          cache: 'npm'<br>      <br>      - name: Install dependencies<br>        run: npm ci<br>      <br>      - name: Build application<br>        run: npm run build<br>      <br>      - name: Upload build artifacts<br>        uses: actions/upload-artifact@v3<br>        with:<br>          name: build-files<br>          path: dist/<br><br>  deploy:<br>    needs: build<br>    runs-on: ubuntu-latest<br>    if: github.ref == 'refs/heads/main'<br>    steps:<br>      - name: Download build artifacts<br>        uses: actions/download-artifact@v3<br>        with:<br>          name: build-files<br>          path: dist/<br>      <br>      - name: Deploy to staging<br>        run: |<br>          echo "Deploying to staging environment"<br>          # Commandes de d√©ploiement<br></code></pre><br><br><h2>üîß Configuration d'un Pipeline Simple</h2><br><br><h3>√âtape 1 : Pr√©paration du Projet</h3><br><br><pre><code>bash<br><h1>Structure du projet</h1><br>my-app/<br>‚îú‚îÄ‚îÄ .github/<br>‚îÇ   ‚îî‚îÄ‚îÄ workflows/<br>‚îÇ       ‚îî‚îÄ‚îÄ ci.yml<br>‚îú‚îÄ‚îÄ src/<br>‚îú‚îÄ‚îÄ tests/<br>‚îú‚îÄ‚îÄ package.json<br>‚îî‚îÄ‚îÄ README.md<br></code></pre><br><br><h3>√âtape 2 : Configuration Package.json</h3><br><br><pre><code>json<br>{<br>  "name": "my-app",<br>  "scripts": {<br>    "test": "jest",<br>    "lint": "eslint src/",<br>    "build": "webpack --mode production",<br>    "start": "node dist/server.js"<br>  },<br>  "devDependencies": {<br>    "jest": "^29.0.0",<br>    "eslint": "^8.0.0",<br>    "webpack": "^5.0.0"<br>  }<br>}<br></code></pre><br><br><h3>√âtape 3 : Workflow CI/CD</h3><br><br><pre><code>yaml<br>name: CI/CD Pipeline<br><br>on:<br>  push:<br>    branches: [ main, develop ]<br>  pull_request:<br>    branches: [ main ]<br><br>jobs:<br>  quality-checks:<br>    runs-on: ubuntu-latest<br>    steps:<br>      - uses: actions/checkout@v3<br>      <br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: '18'<br>          cache: 'npm'<br>      <br>      - name: Install dependencies<br>        run: npm ci<br>      <br>      - name: Code linting<br>        run: npm run lint<br>      <br>      - name: Security audit<br>        run: npm audit --audit-level high<br>      <br>      - name: Run tests<br>        run: npm test -- --coverage --watchAll=false<br>      <br>      - name: SonarCloud Scan<br>        uses: SonarSource/sonarcloud-github-action@master<br>        env:<br>          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}<br>          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}<br><br>  build-and-deploy:<br>    needs: quality-checks<br>    runs-on: ubuntu-latest<br>    if: github.ref == 'refs/heads/main'<br>    steps:<br>      - uses: actions/checkout@v3<br>      <br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: '18'<br>          cache: 'npm'<br>      <br>      - name: Install dependencies<br>        run: npm ci<br>      <br>      - name: Build application<br>        run: npm run build<br>      <br>      - name: Build Docker image<br>        run: |<br>          docker build -t my-app:${{ github.sha }} .<br>          docker tag my-app:${{ github.sha }} my-app:latest<br>      <br>      - name: Deploy to staging<br>        run: |<br>          echo "Deploying to staging environment"<br>          # Commandes de d√©ploiement sp√©cifiques<br></code></pre><br><br><h2>üìä M√©triques et Monitoring</h2><br><br><h3>M√©triques de Pipeline</h3><br><li><strong>Temps de build</strong> : Dur√©e totale du pipeline</li><br><li><strong>Taux de succ√®s</strong> : Pourcentage de builds r√©ussis</li><br><li><strong>Temps de feedback</strong> : D√©lai entre commit et notification</li><br><li><strong>Fr√©quence de d√©ploiement</strong> : Nombre de d√©ploiements par p√©riode</li><br><br><h3>Monitoring des Applications</h3><br><li><strong>Uptime</strong> : Disponibilit√© du service</li><br><li><strong>Performance</strong> : Temps de r√©ponse, throughput</li><br><li><strong>Erreurs</strong> : Taux d'erreur, logs d'exception</li><br><li><strong>Utilisation</strong> : CPU, m√©moire, stockage</li><br><br><h3>Outils de Monitoring</h3><br><li><strong>Prometheus + Grafana</strong> : M√©triques et dashboards</li><br><li><strong>ELK Stack</strong> : Logs centralis√©s</li><br><li><strong>New Relic / DataDog</strong> : APM complet</li><br><li><strong>GitHub Insights</strong> : M√©triques de d√©veloppement</li><br><br><h2>üõ°Ô∏è S√©curit√© dans les Pipelines</h2><br><br><h3>Gestion des Secrets</h3><br><pre><code>yaml<br><li>name: Deploy to production</li><br>  env:<br>    API_KEY: ${{ secrets.API_KEY }}<br>    DB_PASSWORD: ${{ secrets.DB_PASSWORD }}<br>  run: |<br>    echo "Deploying with secure credentials"<br></code></pre><br><br><h3>Scan de S√©curit√©</h3><br><pre><code>yaml<br><li>name: Security scan</li><br>  uses: securecodewarrior/github-action-add-sarif@v1<br>  with:<br>    sarif-file: security-scan-results.sarif<br></code></pre><br><br><h3>Bonnes Pratiques</h3><br><li><strong>Principe du moindre privil√®ge</strong> : Permissions minimales</li><br><li><strong>Rotation des secrets</strong> : Renouvellement r√©gulier</li><br><li><strong>Audit des acc√®s</strong> : Tra√ßabilit√© des actions</li><br><li><strong>Isolation des environnements</strong> : S√©paration dev/prod</li><br><br><h2>üéØ Strat√©gies de D√©ploiement</h2><br><br><h3>Blue-Green Deployment</h3><br><li><strong>Deux environnements identiques</strong> : Blue (actuel) et Green (nouveau)</li><br><li><strong>Bascule instantan√©e</strong> : Switch du trafic</li><br><li><strong>Rollback rapide</strong> : Retour √† l'environnement pr√©c√©dent</li><br><br><h3>Rolling Deployment</h3><br><li><strong>Mise √† jour progressive</strong> : Instance par instance</li><br><li><strong>Disponibilit√© continue</strong> : Service toujours accessible</li><br><li><strong>D√©tection d'erreurs</strong> : Arr√™t automatique si probl√®me</li><br><br><h3>Canary Deployment</h3><br><li><strong>D√©ploiement partiel</strong> : Petit pourcentage d'utilisateurs</li><br><li><strong>Validation progressive</strong> : Augmentation graduelle</li><br><li><strong>Risque minimis√©</strong> : Impact limit√© en cas de probl√®me</li><br><br><h2>üéì Points Cl√©s √† Retenir</h2><br><br>1. <strong>CI/CD = Automatisation</strong> : R√©duction des t√¢ches manuelles r√©p√©titives<br>2. <strong>Feedback rapide</strong> : D√©tection pr√©coce des probl√®mes<br>3. <strong>D√©ploiements fr√©quents</strong> : R√©duction des risques par petits changements<br>4. <strong>Culture DevOps</strong> : Collaboration entre d√©veloppement et op√©rations<br>5. <strong>Am√©lioration continue</strong> : Optimisation constante des processus<br><br>---<br><br><strong>Section pr√©c√©dente :</strong> [Introduction √† l'automatisation des tests](01-introduction-automatisation-tests.md)  <br><strong>Prochaine section :</strong> [Int√©gration des tests dans CI/CD](03-integration-tests-cicd.md)<br><br><strong>Comp√©tences travaill√©es :</strong> C8, C17  <br><strong>Dur√©e estim√©e :</strong> 120 minutes<br><br><h1>3. Int√©gration des Tests dans le Cycle CI/CD</h1><br><br><h2>üéØ Objectifs d'Apprentissage</h2><br><br>√Ä l'issue de cette section, vous serez capable de :<br><li>Int√©grer diff√©rents types de tests dans un pipeline CI/CD</li><br><li>Configurer l'ex√©cution parall√®le des tests</li><br><li>Mettre en place des gates de qualit√©</li><br><li>Optimiser les temps d'ex√©cution des tests</li><br><br><h2>üîÑ Strat√©gie d'Int√©gration des Tests</h2><br><br><h3>Placement des Tests dans le Pipeline</h3><br><br><pre><code>mermaid<br>graph TD<br>    A[Code Commit] --> B[Build]<br>    B --> C[Tests Unitaires]<br>    C --> D[Tests d'Int√©gration]<br>    D --> E[Analyse Statique]<br>    E --> F[Build Artefacts]<br>    F --> G[D√©ploiement Staging]<br>    G --> H[Tests E2E]<br>    H --> I[Tests de Performance]<br>    I --> J[Tests de S√©curit√©]<br>    J --> K[D√©ploiement Production]<br>    <br>    C --> L[Fail Fast]<br>    D --> L<br>    H --> M[Rollback si √©chec]<br>    I --> M<br>    J --> M<br></code></pre><br><br><h3>Principe du "Fail Fast"</h3><br><br>#### Concept<br>Arr√™ter le pipeline d√®s qu'un test √©choue pour √©conomiser du temps et des ressources.<br><br>#### Impl√©mentation<br><pre><code>yaml<br>jobs:<br>  unit-tests:<br>    runs-on: ubuntu-latest<br>    steps:<br>      - name: Run unit tests<br>        run: npm test<br>        # Si les tests unitaires √©chouent, le pipeline s'arr√™te ici<br>  <br>  integration-tests:<br>    needs: unit-tests  # Ne s'ex√©cute que si unit-tests r√©ussit<br>    runs-on: ubuntu-latest<br>    steps:<br>      - name: Run integration tests<br>        run: npm run test:integration<br></code></pre><br><br><h2>üß™ Configuration des Tests par Type</h2><br><br><h3>Tests Unitaires</h3><br><br>#### Caract√©ristiques<br><li><strong>Ex√©cution</strong> : Premi√®re √©tape apr√®s le build</li><br><li><strong>Dur√©e</strong> : Tr√®s rapide (< 5 minutes)</li><br><li><strong>Parall√©lisation</strong> : Fortement recommand√©e</li><br><li><strong>Couverture</strong> : Objectif 80%+</li><br><br>#### Configuration GitHub Actions<br><pre><code>yaml<br>unit-tests:<br>  runs-on: ubuntu-latest<br>  strategy:<br>    matrix:<br>      node-version: [16, 18, 20]<br>  steps:<br>    - uses: actions/checkout@v3<br>    - name: Setup Node.js ${{ matrix.node-version }}<br>      uses: actions/setup-node@v3<br>      with:<br>        node-version: ${{ matrix.node-version }}<br>    <br>    - name: Install dependencies<br>      run: npm ci<br>    <br>    - name: Run unit tests<br>      run: npm test -- --coverage --maxWorkers=4<br>    <br>    - name: Upload coverage to Codecov<br>      uses: codecov/codecov-action@v3<br>      with:<br>        file: ./coverage/lcov.info<br>        flags: unittests<br>        name: codecov-umbrella<br></code></pre><br><br><h3>Tests d'Int√©gration</h3><br><br>#### Configuration avec Services<br><pre><code>yaml<br>integration-tests:<br>  runs-on: ubuntu-latest<br>  services:<br>    postgres:<br>      image: postgres:13<br>      env:<br>        POSTGRES_PASSWORD: postgres<br>        POSTGRES_DB: testdb<br>      options: >-<br>        --health-cmd pg_isready<br>        --health-interval 10s<br>        --health-timeout 5s<br>        --health-retries 5<br>    <br>    redis:<br>      image: redis:6<br>      options: >-<br>        --health-cmd "redis-cli ping"<br>        --health-interval 10s<br>        --health-timeout 5s<br>        --health-retries 5<br>  <br>  steps:<br>    - uses: actions/checkout@v3<br>    - name: Setup Node.js<br>      uses: actions/setup-node@v3<br>      with:<br>        node-version: '18'<br>    <br>    - name: Install dependencies<br>      run: npm ci<br>    <br>    - name: Run database migrations<br>      run: npm run db:migrate<br>      env:<br>        DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb<br>    <br>    - name: Run integration tests<br>      run: npm run test:integration<br>      env:<br>        DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb<br>        REDIS_URL: redis://localhost:6379<br></code></pre><br><br><h3>Tests End-to-End</h3><br><br>#### Configuration avec Cypress<br><pre><code>yaml<br>e2e-tests:<br>  runs-on: ubuntu-latest<br>  steps:<br>    - uses: actions/checkout@v3<br>    <br>    - name: Setup Node.js<br>      uses: actions/setup-node@v3<br>      with:<br>        node-version: '18'<br>    <br>    - name: Install dependencies<br>      run: npm ci<br>    <br>    - name: Build application<br>      run: npm run build<br>    <br>    - name: Start application<br>      run: npm start &<br>      <br>    - name: Wait for application<br>      run: npx wait-on http://localhost:3000<br>    <br>    - name: Run Cypress tests<br>      uses: cypress-io/github-action@v5<br>      with:<br>        start: npm start<br>        wait-on: 'http://localhost:3000'<br>        wait-on-timeout: 120<br>        browser: chrome<br>        record: true<br>      env:<br>        CYPRESS_RECORD_KEY: ${{ secrets.CYPRESS_RECORD_KEY }}<br>        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}<br></code></pre><br><br><h2>‚ö° Optimisation des Performances</h2><br><br><h3>Parall√©lisation des Tests</h3><br><br>#### Tests Unitaires en Parall√®le<br><pre><code>yaml<br>unit-tests:<br>  runs-on: ubuntu-latest<br>  strategy:<br>    matrix:<br>      shard: [1, 2, 3, 4]<br>  steps:<br>    - uses: actions/checkout@v3<br>    - name: Setup Node.js<br>      uses: actions/setup-node@v3<br>      with:<br>        node-version: '18'<br>    <br>    - name: Install dependencies<br>      run: npm ci<br>    <br>    - name: Run tests shard ${{ matrix.shard }}<br>      run: npm test -- --shard=${{ matrix.shard }}/4<br></code></pre><br><br>#### Tests E2E en Parall√®le<br><pre><code>yaml<br>e2e-tests:<br>  runs-on: ubuntu-latest<br>  strategy:<br>    matrix:<br>      containers: [1, 2, 3, 4]<br>  steps:<br>    - uses: actions/checkout@v3<br>    - name: Run Cypress tests<br>      uses: cypress-io/github-action@v5<br>      with:<br>        start: npm start<br>        wait-on: 'http://localhost:3000'<br>        record: true<br>        parallel: true<br>        group: 'Actions example'<br>      env:<br>        CYPRESS_RECORD_KEY: ${{ secrets.CYPRESS_RECORD_KEY }}<br></code></pre><br><br><h3>Cache et Optimisations</h3><br><br>#### Cache des D√©pendances<br><pre><code>yaml<br><li>name: Cache Node modules</li><br>  uses: actions/cache@v3<br>  with:<br>    path: ~/.npm<br>    key: ${{ runner.os }}-node-${{ hashFiles('<em></em>/package-lock.json') }}<br>    restore-keys: |<br>      ${{ runner.os }}-node-<br><br><li>name: Install dependencies</li><br>  run: npm ci --prefer-offline --no-audit<br></code></pre><br><br>#### Cache des Builds<br><pre><code>yaml<br><li>name: Cache build output</li><br>  uses: actions/cache@v3<br>  with:<br>    path: |<br>      dist/<br>      .next/cache<br>    key: ${{ runner.os }}-build-${{ github.sha }}<br>    restore-keys: |<br>      ${{ runner.os }}-build-<br></code></pre><br><br><h2>üö™ Gates de Qualit√©</h2><br><br><h3>Couverture de Code</h3><br><br>#### Configuration avec Jest<br><pre><code>javascript<br>// jest.config.js<br>module.exports = {<br>  collectCoverage: true,<br>  coverageThreshold: {<br>    global: {<br>      branches: 80,<br>      functions: 80,<br>      lines: 80,<br>      statements: 80<br>    }<br>  },<br>  coverageReporters: ['text', 'lcov', 'html']<br>};<br></code></pre><br><br>#### Int√©gration dans le Pipeline<br><pre><code>yaml<br><li>name: Run tests with coverage</li><br>  run: npm test -- --coverage<br>  <br><li>name: Check coverage threshold</li><br>  run: |<br>    COVERAGE=$(cat coverage/coverage-summary.json | jq '.total.lines.pct')<br>    if (( $(echo "$COVERAGE < 80" | bc -l) )); then<br>      echo "Coverage $COVERAGE% is below threshold of 80%"<br>      exit 1<br>    fi<br></code></pre><br><br><h3>Analyse Statique</h3><br><br>#### SonarQube Integration<br><pre><code>yaml<br><li>name: SonarQube Scan</li><br>  uses: sonarqube-quality-gate-action@master<br>  env:<br>    SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}<br>  with:<br>    scanMetadataReportFile: target/sonar/report-task.txt<br><br><li>name: Quality Gate check</li><br>  id: sonarqube-quality-gate-check<br>  uses: sonarqube-quality-gate-action@master<br>  timeout-minutes: 5<br>  env:<br>    SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}<br></code></pre><br><br>#### ESLint avec Annotations<br><pre><code>yaml<br><li>name: Run ESLint</li><br>  run: npx eslint . --format @microsoft/eslint-formatter-sarif --output-file eslint-results.sarif<br>  continue-on-error: true<br><br><li>name: Upload analysis results to GitHub</li><br>  uses: github/codeql-action/upload-sarif@v2<br>  with:<br>    sarif_file: eslint-results.sarif<br>    wait-for-processing: true<br></code></pre><br><br><h2>üîç Tests de S√©curit√©</h2><br><br><h3>Scan des D√©pendances</h3><br><br>#### npm audit<br><pre><code>yaml<br><li>name: Security audit</li><br>  run: |<br>    npm audit --audit-level high<br>    npm audit --json > audit-results.json<br>    <br><li>name: Upload audit results</li><br>  uses: actions/upload-artifact@v3<br>  with:<br>    name: security-audit<br>    path: audit-results.json<br></code></pre><br><br>#### Snyk Integration<br><pre><code>yaml<br><li>name: Run Snyk to check for vulnerabilities</li><br>  uses: snyk/actions/node@master<br>  env:<br>    SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}<br>  with:<br>    args: --severity-threshold=high<br></code></pre><br><br><h3>SAST (Static Application Security Testing)</h3><br><br>#### CodeQL Analysis<br><pre><code>yaml<br><li>name: Initialize CodeQL</li><br>  uses: github/codeql-action/init@v2<br>  with:<br>    languages: javascript<br><br><li>name: Autobuild</li><br>  uses: github/codeql-action/autobuild@v2<br><br><li>name: Perform CodeQL Analysis</li><br>  uses: github/codeql-action/analyze@v2<br></code></pre><br><br><h2>üìä Reporting et Notifications</h2><br><br><h3>Test Results Reporting</h3><br><br>#### Jest JUnit Reporter<br><pre><code>yaml<br><li>name: Run tests with JUnit output</li><br>  run: npm test -- --reporters=default --reporters=jest-junit<br>  env:<br>    JEST_JUNIT_OUTPUT_DIR: ./test-results<br>    JEST_JUNIT_OUTPUT_NAME: junit.xml<br><br><li>name: Publish test results</li><br>  uses: dorny/test-reporter@v1<br>  if: always()<br>  with:<br>    name: Jest Tests<br>    path: test-results/junit.xml<br>    reporter: jest-junit<br></code></pre><br><br>#### Allure Reports<br><pre><code>yaml<br><li>name: Generate Allure Report</li><br>  uses: simple-elf/allure-report-action@master<br>  if: always()<br>  with:<br>    allure_results: allure-results<br>    allure_history: allure-history<br><br><li>name: Deploy to GitHub Pages</li><br>  uses: peaceiris/actions-gh-pages@v3<br>  if: always()<br>  with:<br>    github_token: ${{ secrets.GITHUB_TOKEN }}<br>    publish_dir: allure-history<br></code></pre><br><br><h3>Notifications</h3><br><br>#### Slack Integration<br><pre><code>yaml<br><li>name: Notify Slack on failure</li><br>  if: failure()<br>  uses: 8398a7/action-slack@v3<br>  with:<br>    status: failure<br>    channel: '#ci-cd'<br>    text: 'Pipeline failed for ${{ github.repository }}'<br>  env:<br>    SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}<br></code></pre><br><br>#### Email Notifications<br><pre><code>yaml<br><li>name: Send email on failure</li><br>  if: failure()<br>  uses: dawidd6/action-send-mail@v3<br>  with:<br>    server_address: smtp.gmail.com<br>    server_port: 465<br>    username: ${{ secrets.MAIL_USERNAME }}<br>    password: ${{ secrets.MAIL_PASSWORD }}<br>    subject: 'CI/CD Pipeline Failed'<br>    to: team@company.com<br>    from: ci-cd@company.com<br>    body: |<br>      Pipeline failed for repository: ${{ github.repository }}<br>      Commit: ${{ github.sha }}<br>      Author: ${{ github.actor }}<br></code></pre><br><br><h2>üéØ Strat√©gies de Test par Environnement</h2><br><br><h3>Environnement de D√©veloppement</h3><br><pre><code>yaml<br>dev-tests:<br>  if: github.ref == 'refs/heads/develop'<br>  runs-on: ubuntu-latest<br>  steps:<br>    - name: Fast feedback tests<br>      run: |<br>        npm run test:unit<br>        npm run lint<br>        npm run type-check<br></code></pre><br><br><h3>Environnement de Staging</h3><br><pre><code>yaml<br>staging-tests:<br>  if: github.ref == 'refs/heads/main'<br>  runs-on: ubuntu-latest<br>  steps:<br>    - name: Comprehensive testing<br>      run: |<br>        npm run test:unit<br>        npm run test:integration<br>        npm run test:e2e<br>        npm run test:performance<br></code></pre><br><br><h3>Environnement de Production</h3><br><pre><code>yaml<br>production-tests:<br>  runs-on: ubuntu-latest<br>  steps:<br>    - name: Smoke tests<br>      run: npm run test:smoke<br>    <br>    - name: Health checks<br>      run: |<br>        curl -f https://api.example.com/health<br>        npm run test:api-health<br></code></pre><br><br><h2>üõ†Ô∏è Outils d'Int√©gration Avanc√©s</h2><br><br><h3>Docker pour les Tests</h3><br><br>#### Multi-stage Dockerfile<br><pre><code>dockerfile<br><h1>Test stage</h1><br>FROM node:18-alpine AS test<br>WORKDIR /app<br>COPY package*.json ./<br>RUN npm ci<br>COPY . .<br>RUN npm test<br>RUN npm run test:integration<br><br><h1>Build stage</h1><br>FROM node:18-alpine AS build<br>WORKDIR /app<br>COPY package*.json ./<br>RUN npm ci --only=production<br>COPY . .<br>RUN npm run build<br><br><h1>Production stage</h1><br>FROM node:18-alpine AS production<br>WORKDIR /app<br>COPY --from=build /app/dist ./dist<br>COPY --from=build /app/node_modules ./node_modules<br>COPY package*.json ./<br>EXPOSE 3000<br>CMD ["npm", "start"]<br></code></pre><br><br>#### Docker Compose pour Tests<br><pre><code>yaml<br>version: '3.8'<br>services:<br>  app:<br>    build:<br>      context: .<br>      target: test<br>    depends_on:<br>      - postgres<br>      - redis<br>    environment:<br>      - DATABASE_URL=postgres://user:pass@postgres:5432/testdb<br>      - REDIS_URL=redis://redis:6379<br>    command: npm test<br><br>  postgres:<br>    image: postgres:13<br>    environment:<br>      POSTGRES_USER: user<br>      POSTGRES_PASSWORD: pass<br>      POSTGRES_DB: testdb<br><br>  redis:<br>    image: redis:6-alpine<br></code></pre><br><br><h2>üéì Points Cl√©s √† Retenir</h2><br><br>1. <strong>Strat√©gie de placement</strong> : Tests rapides en premier, tests lents en dernier<br>2. <strong>Parall√©lisation</strong> : Optimiser les temps d'ex√©cution<br>3. <strong>Gates de qualit√©</strong> : Bloquer les d√©ploiements si crit√®res non respect√©s<br>4. <strong>Feedback rapide</strong> : Notifier imm√©diatement les d√©veloppeurs<br>5. <strong>Monitoring continu</strong> : Surveiller les m√©triques de test<br><br>---<br><br><strong>Section pr√©c√©dente :</strong> [Pipeline CI/CD de base](02-pipeline-cicd-base.md)  <br><strong>Prochaine section :</strong> [Outils et bonnes pratiques](04-outils-bonnes-pratiques.md)<br><br><strong>Comp√©tences travaill√©es :</strong> C8, C17  <br><strong>Dur√©e estim√©e :</strong> 150 minutes<br><br><h1>4. Outils et Bonnes Pratiques</h1><br><br><h2>üéØ Objectifs d'Apprentissage</h2><br><br>√Ä l'issue de cette section, vous serez capable de :<br><li>Choisir les outils appropri√©s selon le contexte</li><br><li>Appliquer les bonnes pratiques de l'industrie</li><br><li>Configurer des environnements de test robustes</li><br><li>Optimiser les workflows CI/CD</li><br><br><h2>üõ†Ô∏è Panorama des Outils de Test</h2><br><br><h3>Frameworks de Test JavaScript</h3><br><br>#### Jest<br><strong>Avantages :</strong><br><li>Configuration z√©ro par d√©faut</li><br><li>Mocking int√©gr√© puissant</li><br><li>Snapshot testing</li><br><li>Couverture de code native</li><br><br><strong>Configuration type :</strong><br><pre><code>javascript<br>// jest.config.js<br>module.exports = {<br>  testEnvironment: 'node',<br>  collectCoverageFrom: [<br>    'src/<em></em>/*.{js,jsx}',<br>    '!src/index.js',<br>    '!src/<em></em>/*.test.js'<br>  ],<br>  setupFilesAfterEnv: ['<rootDir>/src/setupTests.js'],<br>  testMatch: [<br>    '<rootDir>/src/<strong>/__tests__/</strong>/*.{js,jsx}',<br>    '<rootDir>/src/<em></em>/*.{test,spec}.{js,jsx}'<br>  ]<br>};<br></code></pre><br><br><strong>Exemple de test :</strong><br><pre><code>javascript<br>// user.test.js<br>import { createUser, validateEmail } from './user';<br><br>describe('User Management', () => {<br>  test('should create user with valid data', () => {<br>    const userData = {<br>      name: 'John Doe',<br>      email: 'john@example.com'<br>    };<br>    <br>    const user = createUser(userData);<br>    <br>    expect(user).toHaveProperty('id');<br>    expect(user.name).toBe('John Doe');<br>    expect(user.email).toBe('john@example.com');<br>  });<br><br>  test('should validate email format', () => {<br>    expect(validateEmail('valid@email.com')).toBe(true);<br>    expect(validateEmail('invalid-email')).toBe(false);<br>  });<br>});<br></code></pre><br><br>#### Mocha + Chai<br><strong>Avantages :</strong><br><li>Flexibilit√© maximale</li><br><li>Nombreux plugins disponibles</li><br><li>Syntaxe expressive avec Chai</li><br><br><strong>Configuration :</strong><br><pre><code>javascript<br>// mocha.opts<br>--require @babel/register<br>--recursive<br>--timeout 5000<br>test/<em></em>/*.test.js<br></code></pre><br><br><strong>Exemple de test :</strong><br><pre><code>javascript<br>import { expect } from 'chai';<br>import { calculateTotal } from './calculator';<br><br>describe('Calculator', () => {<br>  it('should calculate total with tax', () => {<br>    const result = calculateTotal(100, 0.2);<br>    expect(result).to.equal(120);<br>  });<br><br>  it('should handle edge cases', () => {<br>    expect(() => calculateTotal(-100, 0.2)).to.throw('Invalid amount');<br>  });<br>});<br></code></pre><br><br><h3>Outils de Test E2E</h3><br><br>#### Cypress<br><strong>Avantages :</strong><br><li>Interface utilisateur intuitive</li><br><li>Debugging en temps r√©el</li><br><li>Screenshots et vid√©os automatiques</li><br><li>API moderne et simple</li><br><br><strong>Configuration :</strong><br><pre><code>javascript<br>// cypress.config.js<br>import { defineConfig } from 'cypress'<br><br>export default defineConfig({<br>  e2e: {<br>    baseUrl: 'http://localhost:3000',<br>    supportFile: 'cypress/support/e2e.js',<br>    specPattern: 'cypress/e2e/<em></em>/*.cy.{js,jsx,ts,tsx}',<br>    video: true,<br>    screenshotOnRunFailure: true,<br>    viewportWidth: 1280,<br>    viewportHeight: 720,<br>    defaultCommandTimeout: 10000,<br>    requestTimeout: 10000,<br>    responseTimeout: 10000<br>  }<br>})<br></code></pre><br><br><strong>Exemple de test :</strong><br><pre><code>javascript<br>// cypress/e2e/login.cy.js<br>describe('User Authentication', () => {<br>  beforeEach(() => {<br>    cy.visit('/login');<br>  });<br><br>  it('should login with valid credentials', () => {<br>    cy.get('[data-cy=email]').type('user@example.com');<br>    cy.get('[data-cy=password]').type('password123');<br>    cy.get('[data-cy=login-button]').click();<br>    <br>    cy.url().should('include', '/dashboard');<br>    cy.get('[data-cy=welcome-message]').should('be.visible');<br>  });<br><br>  it('should show error with invalid credentials', () => {<br>    cy.get('[data-cy=email]').type('invalid@example.com');<br>    cy.get('[data-cy=password]').type('wrongpassword');<br>    cy.get('[data-cy=login-button]').click();<br>    <br>    cy.get('[data-cy=error-message]')<br>      .should('be.visible')<br>      .and('contain', 'Invalid credentials');<br>  });<br>});<br></code></pre><br><br>#### Playwright<br><strong>Avantages :</strong><br><li>Support multi-navigateurs natif</li><br><li>Parall√©lisation avanc√©e</li><br><li>API moderne avec async/await</li><br><li>Capture de traces d√©taill√©es</li><br><br><strong>Configuration :</strong><br><pre><code>javascript<br>// playwright.config.js<br>import { defineConfig, devices } from '@playwright/test';<br><br>export default defineConfig({<br>  testDir: './tests',<br>  fullyParallel: true,<br>  forbidOnly: !!process.env.CI,<br>  retries: process.env.CI ? 2 : 0,<br>  workers: process.env.CI ? 1 : undefined,<br>  reporter: 'html',<br>  use: {<br>    baseURL: 'http://localhost:3000',<br>    trace: 'on-first-retry',<br>    screenshot: 'only-on-failure',<br>  },<br>  projects: [<br>    {<br>      name: 'chromium',<br>      use: { ...devices['Desktop Chrome'] },<br>    },<br>    {<br>      name: 'firefox',<br>      use: { ...devices['Desktop Firefox'] },<br>    },<br>    {<br>      name: 'webkit',<br>      use: { ...devices['Desktop Safari'] },<br>    },<br>  ],<br>});<br></code></pre><br><br><strong>Exemple de test :</strong><br><pre><code>javascript<br>// tests/login.spec.js<br>import { test, expect } from '@playwright/test';<br><br>test.describe('User Authentication', () => {<br>  test('should login successfully', async ({ page }) => {<br>    await page.goto('/login');<br>    <br>    await page.fill('[data-testid=email]', 'user@example.com');<br>    await page.fill('[data-testid=password]', 'password123');<br>    await page.click('[data-testid=login-button]');<br>    <br>    await expect(page).toHaveURL(/.*dashboard/);<br>    await expect(page.locator('[data-testid=welcome]')).toBeVisible();<br>  });<br><br>  test('should handle login failure', async ({ page }) => {<br>    await page.goto('/login');<br>    <br>    await page.fill('[data-testid=email]', 'invalid@example.com');<br>    await page.fill('[data-testid=password]', 'wrongpassword');<br>    await page.click('[data-testid=login-button]');<br>    <br>    await expect(page.locator('[data-testid=error]')).toContainText('Invalid credentials');<br>  });<br>});<br></code></pre><br><br>#### Selenium WebDriver<br><strong>Avantages :</strong><br><li>Standard de l'industrie</li><br><li>Support de nombreux langages</li><br><li>√âcosyst√®me mature</li><br><li>Grid pour tests distribu√©s</li><br><br><strong>Exemple avec Node.js :</strong><br><pre><code>javascript<br>// selenium-test.js<br>import { Builder, By, until } from 'selenium-webdriver';<br>import chrome from 'selenium-webdriver/chrome';<br><br>describe('Selenium Tests', () => {<br>  let driver;<br><br>  beforeEach(async () => {<br>    const options = new chrome.Options();<br>    options.addArguments('--headless');<br>    options.addArguments('--no-sandbox');<br>    <br>    driver = await new Builder()<br>      .forBrowser('chrome')<br>      .setChromeOptions(options)<br>      .build();<br>  });<br><br>  afterEach(async () => {<br>    await driver.quit();<br>  });<br><br>  test('should perform login', async () => {<br>    await driver.get('http://localhost:3000/login');<br>    <br>    await driver.findElement(By.id('email')).sendKeys('user@example.com');<br>    await driver.findElement(By.id('password')).sendKeys('password123');<br>    await driver.findElement(By.id('login-button')).click();<br>    <br>    await driver.wait(until.urlContains('dashboard'), 10000);<br>    <br>    const welcomeElement = await driver.findElement(By.id('welcome'));<br>    const isDisplayed = await welcomeElement.isDisplayed();<br>    expect(isDisplayed).toBe(true);<br>  });<br>});<br></code></pre><br><br><h2>üîß Outils d'Analyse et de Qualit√©</h2><br><br><h3>ESLint - Analyse Statique</h3><br><br>#### Configuration avanc√©e<br><pre><code>javascript<br>// .eslintrc.js<br>module.exports = {<br>  env: {<br>    browser: true,<br>    es2021: true,<br>    node: true,<br>    jest: true<br>  },<br>  extends: [<br>    'eslint:recommended',<br>    '@typescript-eslint/recommended',<br>    'plugin:react/recommended',<br>    'plugin:react-hooks/recommended',<br>    'plugin:jsx-a11y/recommended'<br>  ],<br>  parser: '@typescript-eslint/parser',<br>  parserOptions: {<br>    ecmaFeatures: {<br>      jsx: true<br>    },<br>    ecmaVersion: 12,<br>    sourceType: 'module'<br>  },<br>  plugins: [<br>    'react',<br>    '@typescript-eslint',<br>    'jsx-a11y',<br>    'import'<br>  ],<br>  rules: {<br>    'no-console': 'warn',<br>    'no-unused-vars': 'error',<br>    'prefer-const': 'error',<br>    'react/prop-types': 'off',<br>    '@typescript-eslint/no-unused-vars': 'error',<br>    'import/order': ['error', {<br>      'groups': ['builtin', 'external', 'internal'],<br>      'newlines-between': 'always'<br>    }]<br>  },<br>  settings: {<br>    react: {<br>      version: 'detect'<br>    }<br>  }<br>};<br></code></pre><br><br><h3>SonarQube - Qualit√© de Code</h3><br><br>#### Configuration projet<br><pre><code>properties<br><h1>sonar-project.properties</h1><br>sonar.projectKey=my-project<br>sonar.projectName=My Project<br>sonar.projectVersion=1.0<br>sonar.sources=src<br>sonar.tests=src<br>sonar.test.inclusions=<strong>/<em>.test.js,</strong>/</em>.spec.js<br>sonar.javascript.lcov.reportPaths=coverage/lcov.info<br>sonar.coverage.exclusions=<strong>/<em>.test.js,</strong>/</em>.spec.js,<strong>/node_modules/</strong><br></code></pre><br><br>#### Int√©gration CI/CD<br><pre><code>yaml<br><li>name: SonarQube Scan</li><br>  uses: sonarqube-quality-gate-action@master<br>  env:<br>    SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}<br>    SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}<br></code></pre><br><br><h3>Lighthouse - Performance Web</h3><br><br>#### Configuration CI<br><pre><code>yaml<br><li>name: Lighthouse CI</li><br>  uses: treosh/lighthouse-ci-action@v9<br>  with:<br>    configPath: './lighthouserc.json'<br>    uploadArtifacts: true<br>    temporaryPublicStorage: true<br></code></pre><br><br>#### Configuration Lighthouse<br><pre><code>json<br>{<br>  "ci": {<br>    "collect": {<br>      "url": ["http://localhost:3000"],<br>      "startServerCommand": "npm start",<br>      "numberOfRuns": 3<br>    },<br>    "assert": {<br>      "assertions": {<br>        "categories:performance": ["warn", {"minScore": 0.9}],<br>        "categories:accessibility": ["error", {"minScore": 0.9}],<br>        "categories:best-practices": ["warn", {"minScore": 0.9}],<br>        "categories:seo": ["warn", {"minScore": 0.9}]<br>      }<br>    },<br>    "upload": {<br>      "target": "temporary-public-storage"<br>    }<br>  }<br>}<br></code></pre><br><br><h2>üìä Monitoring et Observabilit√©</h2><br><br><h3>Prometheus + Grafana</h3><br><br>#### M√©triques applicatives<br><pre><code>javascript<br>// metrics.js<br>import client from 'prom-client';<br><br>const httpRequestDuration = new client.Histogram({<br>  name: 'http_request_duration_seconds',<br>  help: 'Duration of HTTP requests in seconds',<br>  labelNames: ['method', 'route', 'status_code']<br>});<br><br>const httpRequestsTotal = new client.Counter({<br>  name: 'http_requests_total',<br>  help: 'Total number of HTTP requests',<br>  labelNames: ['method', 'route', 'status_code']<br>});<br><br>export const recordHttpRequest = (method, route, statusCode, duration) => {<br>  httpRequestsTotal.inc({ method, route, status_code: statusCode });<br>  httpRequestDuration.observe({ method, route, status_code: statusCode }, duration);<br>};<br></code></pre><br><br>#### Dashboard Grafana<br><pre><code>json<br>{<br>  "dashboard": {<br>    "title": "Application Metrics",<br>    "panels": [<br>      {<br>        "title": "Request Rate",<br>        "type": "graph",<br>        "targets": [<br>          {<br>            "expr": "rate(http_requests_total[5m])",<br>            "legendFormat": "{{method}} {{route}}"<br>          }<br>        ]<br>      },<br>      {<br>        "title": "Response Time",<br>        "type": "graph",<br>        "targets": [<br>          {<br>            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",<br>            "legendFormat": "95th percentile"<br>          }<br>        ]<br>      }<br>    ]<br>  }<br>}<br></code></pre><br><br><h3>ELK Stack - Logs</h3><br><br>#### Configuration Logstash<br><pre><code>ruby<br><h1>logstash.conf</h1><br>input {<br>  beats {<br>    port => 5044<br>  }<br>}<br><br>filter {<br>  if [fields][logtype] == "application" {<br>    json {<br>      source => "message"<br>    }<br>    <br>    date {<br>      match => [ "timestamp", "ISO8601" ]<br>    }<br>    <br>    mutate {<br>      remove_field => [ "message" ]<br>    }<br>  }<br>}<br><br>output {<br>  elasticsearch {<br>    hosts => ["elasticsearch:9200"]<br>    index => "application-logs-%{+YYYY.MM.dd}"<br>  }<br>}<br></code></pre><br><br><h2>üèóÔ∏è Infrastructure as Code</h2><br><br><h3>Docker pour les Tests</h3><br><br>#### Multi-stage optimis√©<br><pre><code>dockerfile<br><h1>Dockerfile.test</h1><br>FROM node:18-alpine AS base<br>WORKDIR /app<br>COPY package*.json ./<br>RUN npm ci --only=production && npm cache clean --force<br><br>FROM base AS dev-deps<br>RUN npm ci<br><br>FROM dev-deps AS test<br>COPY . .<br>RUN npm run lint<br>RUN npm run test:unit<br>RUN npm run test:integration<br><br>FROM base AS production<br>COPY --from=test /app/dist ./dist<br>EXPOSE 3000<br>CMD ["npm", "start"]<br></code></pre><br><br>#### Docker Compose pour d√©veloppement<br><pre><code>yaml<br><h1>docker-compose.test.yml</h1><br>version: '3.8'<br><br>services:<br>  app:<br>    build:<br>      context: .<br>      dockerfile: Dockerfile.test<br>      target: test<br>    depends_on:<br>      postgres:<br>        condition: service_healthy<br>      redis:<br>        condition: service_healthy<br>    environment:<br>      - NODE_ENV=test<br>      - DATABASE_URL=postgres://test:test@postgres:5432/testdb<br>      - REDIS_URL=redis://redis:6379<br>    volumes:<br>      - ./coverage:/app/coverage<br><br>  postgres:<br>    image: postgres:13-alpine<br>    environment:<br>      POSTGRES_USER: test<br>      POSTGRES_PASSWORD: test<br>      POSTGRES_DB: testdb<br>    healthcheck:<br>      test: ["CMD-SHELL", "pg_isready -U test"]<br>      interval: 10s<br>      timeout: 5s<br>      retries: 5<br><br>  redis:<br>    image: redis:6-alpine<br>    healthcheck:<br>      test: ["CMD", "redis-cli", "ping"]<br>      interval: 10s<br>      timeout: 5s<br>      retries: 5<br></code></pre><br><br><h3>Kubernetes pour les Tests</h3><br><br>#### Job de test<br><pre><code>yaml<br><h1>test-job.yaml</h1><br>apiVersion: batch/v1<br>kind: Job<br>metadata:<br>  name: app-tests<br>spec:<br>  template:<br>    spec:<br>      containers:<br>      - name: test-runner<br>        image: myapp:test<br>        command: ["npm", "run", "test:ci"]<br>        env:<br>        - name: DATABASE_URL<br>          valueFrom:<br>            secretKeyRef:<br>              name: db-secret<br>              key: url<br>        resources:<br>          requests:<br>            memory: "512Mi"<br>            cpu: "500m"<br>          limits:<br>            memory: "1Gi"<br>            cpu: "1000m"<br>      restartPolicy: Never<br>  backoffLimit: 3<br></code></pre><br><br><h2>üéØ Bonnes Pratiques Avanc√©es</h2><br><br><h3>Test Data Management</h3><br><br>#### Factory Pattern<br><pre><code>javascript<br>// factories/userFactory.js<br>import { faker } from '@faker-js/faker';<br><br>export const createUser = (overrides = {}) => ({<br>  id: faker.datatype.uuid(),<br>  name: faker.name.fullName(),<br>  email: faker.internet.email(),<br>  createdAt: faker.date.recent(),<br>  ...overrides<br>});<br><br>export const createUsers = (count = 5, overrides = {}) => <br>  Array.from({ length: count }, () => createUser(overrides));<br></code></pre><br><br>#### Database Seeding<br><pre><code>javascript<br>// seeds/testData.js<br>import { createUser } from '../factories/userFactory';<br>import { User } from '../models/User';<br><br>export const seedTestData = async () => {<br>  // Clean existing data<br>  await User.deleteMany({});<br>  <br>  // Create test users<br>  const users = createUsers(10);<br>  await User.insertMany(users);<br>  <br>  return { users };<br>};<br></code></pre><br><br><h3>Page Object Model</h3><br><br>#### Page Object<br><pre><code>javascript<br>// pages/LoginPage.js<br>export class LoginPage {<br>  constructor(page) {<br>    this.page = page;<br>    this.emailInput = '[data-testid=email]';<br>    this.passwordInput = '[data-testid=password]';<br>    this.loginButton = '[data-testid=login-button]';<br>    this.errorMessage = '[data-testid=error-message]';<br>  }<br><br>  async goto() {<br>    await this.page.goto('/login');<br>  }<br><br>  async login(email, password) {<br>    await this.page.fill(this.emailInput, email);<br>    await this.page.fill(this.passwordInput, password);<br>    await this.page.click(this.loginButton);<br>  }<br><br>  async getErrorMessage() {<br>    return await this.page.textContent(this.errorMessage);<br>  }<br><br>  async isErrorVisible() {<br>    return await this.page.isVisible(this.errorMessage);<br>  }<br>}<br></code></pre><br><br>#### Utilisation dans les tests<br><pre><code>javascript<br>// tests/login.spec.js<br>import { test, expect } from '@playwright/test';<br>import { LoginPage } from '../pages/LoginPage';<br><br>test.describe('Login Tests', () => {<br>  let loginPage;<br><br>  test.beforeEach(async ({ page }) => {<br>    loginPage = new LoginPage(page);<br>    await loginPage.goto();<br>  });<br><br>  test('should login with valid credentials', async () => {<br>    await loginPage.login('user@example.com', 'password123');<br>    await expect(page).toHaveURL(/.*dashboard/);<br>  });<br><br>  test('should show error with invalid credentials', async () => {<br>    await loginPage.login('invalid@example.com', 'wrongpassword');<br>    <br>    expect(await loginPage.isErrorVisible()).toBe(true);<br>    expect(await loginPage.getErrorMessage()).toContain('Invalid credentials');<br>  });<br>});<br></code></pre><br><br><h3>Test Environment Management</h3><br><br>#### Configuration par environnement<br><pre><code>javascript<br>// config/test.js<br>const config = {<br>  development: {<br>    database: {<br>      host: 'localhost',<br>      port: 5432,<br>      name: 'myapp_dev'<br>    },<br>    redis: {<br>      host: 'localhost',<br>      port: 6379<br>    }<br>  },<br>  test: {<br>    database: {<br>      host: process.env.DB_HOST || 'localhost',<br>      port: process.env.DB_PORT || 5432,<br>      name: 'myapp_test'<br>    },<br>    redis: {<br>      host: process.env.REDIS_HOST || 'localhost',<br>      port: process.env.REDIS_PORT || 6379<br>    }<br>  },<br>  ci: {<br>    database: {<br>      host: 'postgres',<br>      port: 5432,<br>      name: 'testdb'<br>    },<br>    redis: {<br>      host: 'redis',<br>      port: 6379<br>    }<br>  }<br>};<br><br>export default config[process.env.NODE_ENV || 'development'];<br></code></pre><br><br><h2>üéì Points Cl√©s √† Retenir</h2><br><br>1. <strong>Choix d'outils</strong> : Adapter selon le contexte et les besoins<br>2. <strong>Configuration</strong> : Investir dans une configuration robuste<br>3. <strong>Maintenance</strong> : Pr√©voir la maintenance des tests et outils<br>4. <strong>Monitoring</strong> : Surveiller les performances et la qualit√©<br>5. <strong>√âvolution</strong> : Rester √† jour avec les nouvelles pratiques<br><br>---<br><br><strong>Section pr√©c√©dente :</strong> [Int√©gration des tests dans CI/CD](03-integration-tests-cicd.md)  <br><strong>Module suivant :</strong> [Module 2 - IA et Automatisation des Tests](../../module-2-ia-tests/README.md)<br><br><strong>Comp√©tences travaill√©es :</strong> C8, C17  <br><strong>Dur√©e estim√©e :</strong> 120 minutes<br><br><h1>Support Th√©orique - Module 1 : Fondamentaux CI/CD</h1><br><br><h2>Vue d'Ensemble du Contenu</h2><br><br>Ce support th√©orique couvre l'ensemble des concepts fondamentaux n√©cessaires pour comprendre et impl√©menter l'automatisation des tests dans un contexte CI/CD. Le contenu est structur√© en 4 sections progressives, √©quivalent √† 30 slides de pr√©sentation.<br><br><h2>Progression P√©dagogique</h2><br><br><h3>üéØ Objectifs G√©n√©raux</h3><br>√Ä l'issue de ce module th√©orique, les apprenants seront capables de :<br><li>Ma√Ætriser les concepts fondamentaux de CI/CD</li><br><li>Distinguer et utiliser les diff√©rents types de tests automatis√©s</li><br><li>Configurer un pipeline CI/CD complet avec GitHub Actions</li><br><li>Appliquer les bonnes pratiques de l'industrie</li><br><li>Choisir les outils appropri√©s selon le contexte</li><br><br><h2>Structure du Contenu</h2><br><br><h3>[Section 1 : Introduction √† l'Automatisation des Tests](01-introduction-automatisation-tests.md)</h3><br><strong>Dur√©e :</strong> 90 minutes | <strong>Slides √©quivalent :</strong> 8 slides<br><br>#### Points Cl√©s Abord√©s<br><li><strong>Tests Manuels vs Automatis√©s</strong> : Avantages, inconv√©nients, cas d'usage</li><br><li><strong>Cat√©gories de Tests</strong> : Unitaires, int√©gration, E2E, non-fonctionnels</li><br><li><strong>Pyramide de Test</strong> : Structure, r√©partition, principes</li><br><li><strong>Crit√®res de S√©lection</strong> : Quels tests automatiser, ROI</li><br><li><strong>M√©triques</strong> : Couverture, qualit√©, performance</li><br><br>#### Comp√©tences D√©velopp√©es<br><li>Analyse des besoins en automatisation</li><br><li>Compr√©hension des strat√©gies de test</li><br><li>√âvaluation du ROI de l'automatisation</li><br><br>---<br><br><h3>[Section 2 : Mise en Place d'un Pipeline CI/CD de Base](02-pipeline-cicd-base.md)</h3><br><strong>Dur√©e :</strong> 120 minutes | <strong>Slides √©quivalent :</strong> 10 slides<br><br>#### Points Cl√©s Abord√©s<br><li><strong>Concepts CI/CD</strong> : D√©finitions, diff√©rences CI/CD/CD</li><br><li><strong>Architecture Pipeline</strong> : Composants, flux, √©tapes</li><br><li><strong>GitHub Actions</strong> : Workflows, jobs, actions</li><br><li><strong>Configuration</strong> : YAML, variables, secrets</li><br><li><strong>Strat√©gies de D√©ploiement</strong> : Blue-Green, Rolling, Canary</li><br><br>#### Comp√©tences D√©velopp√©es<br><li>Configuration de workflows automatis√©s</li><br><li>Compr√©hension des architectures CI/CD</li><br><li>Ma√Ætrise des outils cloud (GitHub Actions)</li><br><br>---<br><br><h3>[Section 3 : Int√©gration des Tests dans le Cycle CI/CD](03-integration-tests-cicd.md)</h3><br><strong>Dur√©e :</strong> 150 minutes | <strong>Slides √©quivalent :</strong> 12 slides<br><br>#### Points Cl√©s Abord√©s<br><li><strong>Strat√©gies d'Int√©gration</strong> : Placement, s√©quencement, parall√©lisation</li><br><li><strong>Configuration par Type</strong> : Unitaires, int√©gration, E2E</li><br><li><strong>Optimisation</strong> : Cache, parall√©lisation, fail-fast</li><br><li><strong>Gates de Qualit√©</strong> : Couverture, seuils, blocages</li><br><li><strong>Reporting</strong> : Notifications, m√©triques, dashboards</li><br><br>#### Comp√©tences D√©velopp√©es<br><li>Optimisation des pipelines de test</li><br><li>Configuration d'environnements de test</li><br><li>Mise en place de gates de qualit√©</li><br><br>---<br><br><h3>[Section 4 : Outils et Bonnes Pratiques](04-outils-bonnes-pratiques.md)</h3><br><strong>Dur√©e :</strong> 120 minutes | <strong>Slides √©quivalent :</strong> 10 slides<br><br>#### Points Cl√©s Abord√©s<br><li><strong>Frameworks de Test</strong> : Jest, Mocha, Cypress, Playwright, Selenium</li><br><li><strong>Outils d'Analyse</strong> : ESLint, SonarQube, Lighthouse</li><br><li><strong>Infrastructure</strong> : Docker, Kubernetes, IaC</li><br><li><strong>Patterns Avanc√©s</strong> : Page Object Model, Factory Pattern</li><br><li><strong>Monitoring</strong> : Prometheus, Grafana, ELK Stack</li><br><br>#### Comp√©tences D√©velopp√©es<br><li>S√©lection d'outils appropri√©s</li><br><li>Application de patterns de test</li><br><li>Mise en place de monitoring</li><br><br><h2>Ressources P√©dagogiques</h2><br><br><h3>Diagrammes et Sch√©mas</h3><br><li>Pyramide de test interactive</li><br><li>Architecture de pipeline CI/CD</li><br><li>Flux de donn√©es dans les tests</li><br><li>Comparaison d'outils</li><br><br><h3>Exemples de Code</h3><br><li>Configuration GitHub Actions compl√®te</li><br><li>Tests unitaires avec Jest</li><br><li>Tests E2E avec Cypress et Playwright</li><br><li>Configuration Docker multi-stage</li><br><br><h3>Cas Pratiques</h3><br><li>Projet web moderne (React/Node.js)</li><br><li>API REST avec base de donn√©es</li><br><li>Application microservices</li><br><li>Pipeline de d√©ploiement cloud</li><br><br><h2>√âvaluation des Acquis</h2><br><br><h3>Questions de Compr√©hension</h3><br>Chaque section inclut des questions pour v√©rifier la compr√©hension :<br><li>Questions conceptuelles</li><br><li>Exercices de r√©flexion</li><br><li>Cas d'usage pratiques</li><br><br><h3>QCM Interm√©diaire</h3><br>8 questions couvrant l'ensemble du module :<br><li>2 questions sur les concepts de base</li><br><li>2 questions sur les types de tests</li><br><li>2 questions sur les pipelines CI/CD</li><br><li>2 questions sur les outils et bonnes pratiques</li><br><br><h2>Liens entre les Sections</h2><br><br><pre><code>mermaid<br>graph TD<br>    A[Section 1: Introduction Tests] --> B[Section 2: Pipeline CI/CD]<br>    B --> C[Section 3: Int√©gration Tests]<br>    C --> D[Section 4: Outils & Pratiques]<br>    <br>    A --> E[Concepts Fondamentaux]<br>    B --> F[Configuration Pratique]<br>    C --> G[Optimisation]<br>    D --> H[Expertise Avanc√©e]<br>    <br>    E --> F --> G --> H<br></code></pre><br><br><h2>Adaptation selon le Public</h2><br><br><h3>D√©veloppeurs D√©butants</h3><br><li>Focus sur les concepts de base</li><br><li>Exemples simples et progressifs</li><br><li>Accompagnement renforc√© sur la configuration</li><br><br><h3>D√©veloppeurs Exp√©riment√©s</h3><br><li>Approfondissement des bonnes pratiques</li><br><li>Patterns avanc√©s</li><br><li>Optimisations et monitoring</li><br><br><h3>DevOps/SRE</h3><br><li>Architecture et scalabilit√©</li><br><li>Monitoring et observabilit√©</li><br><li>Strat√©gies de d√©ploiement avanc√©es</li><br><br><h2>Ressources Compl√©mentaires</h2><br><br><h3>Documentation Officielle</h3><br><li>[GitHub Actions](https://docs.github.com/en/actions)</li><br><li>[Jest](https://jestjs.io/docs/getting-started)</li><br><li>[Cypress](https://docs.cypress.io/)</li><br><li>[Playwright](https://playwright.dev/docs/intro)</li><br><br><h3>Articles et Blogs</h3><br><li>Martin Fowler sur les tests</li><br><li>Google Testing Blog</li><br><li>DevOps.com ressources CI/CD</li><br><br><h3>Outils en Ligne</h3><br><li>GitHub Actions Marketplace</li><br><li>Cypress Dashboard</li><br><li>SonarCloud</li><br><br><h2>Prochaines √âtapes</h2><br><br>Apr√®s ce module th√©orique, les apprenants pourront :<br>1. <strong>Passer aux exercices pratiques</strong> du Module 1<br>2. <strong>Approfondir avec le Module 2</strong> (IA et automatisation)<br>3. <strong>Appliquer dans leurs projets</strong> personnels ou professionnels<br><br>---<br><br><strong>Comp√©tences ECF travaill√©es :</strong> C8 (R√©aliser des tests d'int√©gration), C17 (Automatiser les tests)  <br><strong>Dur√©e totale :</strong> 480 minutes (8 heures)  <br><strong>Format :</strong> Th√©orie interactive avec d√©monstrations<br><br>\newpage<br><br><h1>Exercices Pratiques</h1><br><br><h1>Exercices Pratiques - Module 1 : Fondamentaux CI/CD</h1><br><br><h2>Vue d'Ensemble</h2><br><br>Ce module contient 3 exercices pratiques progressifs qui permettent d'appliquer concr√®tement les concepts th√©oriques abord√©s dans le Module 1. Chaque exercice est con√ßu pour renforcer les comp√©tences C8 (R√©aliser des tests d'int√©gration) et C17 (Automatiser les tests).<br><br><h2>Structure des Exercices</h2><br><br><h3>üéØ Progression P√©dagogique</h3><br><br>Les exercices suivent une progression logique :<br>1. <strong>Exercice 1.1</strong> : D√©couverte et configuration de base<br>2. <strong>Exercice 1.2</strong> : Approfondissement avec containerisation<br>3. <strong>Exercice 1.3</strong> : Optimisation et bonnes pratiques<br><br><h3>üìã Format Standard</h3><br><br>Chaque exercice comprend :<br><li><strong>Objectifs d'apprentissage</strong> clairs et mesurables</li><br><li><strong>Pr√©requis techniques</strong> et connaissances n√©cessaires</li><br><li><strong>√ânonc√© d√©taill√©</strong> avec contexte professionnel</li><br><li><strong>Instructions √©tape par √©tape</strong> avec captures d'√©cran</li><br><li><strong>Fichiers de ressources</strong> et templates fournis</li><br><li><strong>Solution compl√®te</strong> avec explications</li><br><li><strong>Points de validation</strong> pour auto-√©valuation</li><br><li><strong>Extensions possibles</strong> pour aller plus loin</li><br><br><h2>Liste des Exercices</h2><br><br><h3>[Exercice 1.1 - Premier Pipeline CI/CD avec GitHub Actions](exercice-1.1-premier-pipeline/README.md)</h3><br><strong>Dur√©e :</strong> 90 minutes  <br><strong>Niveau :</strong> D√©butant  <br><strong>Objectif :</strong> Cr√©er son premier workflow GitHub Actions avec build et tests unitaires<br><br><strong>Comp√©tences travaill√©es :</strong><br><li>Configuration de workflows automatis√©s</li><br><li>Int√©gration de tests unitaires dans CI/CD</li><br><li>Gestion des artefacts de build</li><br><br>---<br><br><h3>[Exercice 1.2 - Configuration de Tests Automatis√©s avec Docker](exercice-1.2-tests-docker/README.md)</h3><br><strong>Dur√©e :</strong> 120 minutes  <br><strong>Niveau :</strong> Interm√©diaire  <br><strong>Objectif :</strong> Mettre en place un environnement de test containeris√© avec services<br><br><strong>Comp√©tences travaill√©es :</strong><br><li>Containerisation des environnements de test</li><br><li>Configuration de services de test (base de donn√©es, cache)</li><br><li>Tests d'int√©gration avec d√©pendances externes</li><br><br>---<br><br><h3>[Exercice 1.3 - Int√©gration de Tests en Parall√®le](exercice-1.3-tests-paralleles/README.md)</h3><br><strong>Dur√©e :</strong> 90 minutes  <br><strong>Niveau :</strong> Interm√©diaire/Avanc√©  <br><strong>Objectif :</strong> Optimiser les temps d'ex√©cution avec la parall√©lisation des tests<br><br><strong>Comp√©tences travaill√©es :</strong><br><li>Optimisation des pipelines CI/CD</li><br><li>Parall√©lisation des tests</li><br><li>Monitoring et m√©triques de performance</li><br><br><h2>Pr√©requis G√©n√©raux</h2><br><br><h3>Outils Requis</h3><br><li><strong>Git</strong> : Version 2.30+</li><br><li><strong>Node.js</strong> : Version 18+ avec npm</li><br><li><strong>Docker Desktop</strong> : Version 4.0+</li><br><li><strong>Compte GitHub</strong> : Avec acc√®s aux GitHub Actions</li><br><li><strong>IDE</strong> : VS Code recommand√© avec extensions Git et Docker</li><br><br><h3>Connaissances Pr√©alables</h3><br><li>Bases de Git (clone, commit, push, pull)</li><br><li>Notions de ligne de commande</li><br><li>Concepts de base du d√©veloppement web</li><br><li>Compr√©hension des concepts HTTP/REST</li><br><br><h3>Configuration de l'Environnement</h3><br>Avant de commencer les exercices, suivez le [Guide de Configuration](../../../ressources/outils/outils-requis.md) pour pr√©parer votre environnement de d√©veloppement.<br><br><h2>√âvaluation et Validation</h2><br><br><h3>Crit√®res de R√©ussite</h3><br>Chaque exercice inclut des <strong>points de validation</strong> permettant de v√©rifier :<br><li>‚úÖ Configuration correcte des outils</li><br><li>‚úÖ Fonctionnement des workflows CI/CD</li><br><li>‚úÖ Ex√©cution r√©ussie des tests</li><br><li>‚úÖ Respect des bonnes pratiques</li><br><br><h3>Auto-√âvaluation</h3><br>Des <strong>questions de r√©flexion</strong> sont propos√©es √† la fin de chaque exercice pour :<br><li>Analyser les r√©sultats obtenus</li><br><li>Identifier les points d'am√©lioration</li><br><li>R√©fl√©chir aux applications en contexte professionnel</li><br><br><h3>Support et Aide</h3><br><li><strong>Solutions d√©taill√©es</strong> disponibles pour chaque exercice</li><br><li><strong>FAQ</strong> avec probl√®mes courants et r√©solutions</li><br><li><strong>Ressources compl√©mentaires</strong> pour approfondir</li><br><br><h2>Ressources Communes</h2><br><br><h3>Templates et Fichiers de Base</h3><br><li>Configuration GitHub Actions de base</li><br><li>Dockerfile multi-stage pour tests</li><br><li>Scripts de configuration d'environnement</li><br><li>Exemples d'applications de test</li><br><br><h3>Documentation de R√©f√©rence</h3><br><li>[GitHub Actions Documentation](https://docs.github.com/en/actions)</li><br><li>[Docker Documentation](https://docs.docker.com/)</li><br><li>[Jest Testing Framework](https://jestjs.io/)</li><br><li>[Node.js Best Practices](https://github.com/goldbergyoni/nodebestpractices)</li><br><br><h2>Planning Sugg√©r√©</h2><br><br><h3>Session de 4 heures (demi-journ√©e)</h3><br><pre><code><br>09:00-09:15  | Pr√©sentation des exercices et setup<br>09:15-10:45  | Exercice 1.1 - Premier pipeline<br>10:45-11:00  | Pause<br>11:00-13:00  | Exercice 1.2 - Tests avec Docker<br>13:00-14:00  | D√©jeuner<br>14:00-15:30  | Exercice 1.3 - Tests en parall√®le<br>15:30-16:00  | D√©briefing et questions<br></code></pre><br><br><h3>Session de 6 heures (journ√©e compl√®te)</h3><br><pre><code><br>09:00-09:30  | Pr√©sentation et setup environnement<br>09:30-11:00  | Exercice 1.1 - Premier pipeline<br>11:00-11:15  | Pause<br>11:15-13:15  | Exercice 1.2 - Tests avec Docker<br>13:15-14:15  | D√©jeuner<br>14:15-15:45  | Exercice 1.3 - Tests en parall√®le<br>15:45-16:00  | Pause<br>16:00-17:00  | D√©briefing et extensions<br></code></pre><br><br><h2>Extensions et Approfondissements</h2><br><br><h3>Pour Aller Plus Loin</h3><br><li>Int√©gration avec SonarQube pour l'analyse de qualit√©</li><br><li>Configuration de notifications Slack/Teams</li><br><li>D√©ploiement automatique sur des environnements cloud</li><br><li>Mise en place de tests de s√©curit√© avec Snyk</li><br><br><h3>Projets Personnels</h3><br>Les apprenants sont encourag√©s √† :<br><li>Appliquer les concepts sur leurs propres projets</li><br><li>Adapter les configurations √† leur stack technique</li><br><li>Partager leurs exp√©riences et difficult√©s rencontr√©es</li><br><br>---<br><br><strong>Comp√©tences ECF :</strong> C8, C17  <br><strong>Dur√©e totale :</strong> 300 minutes (5 heures)  <br><strong>Format :</strong> Travaux pratiques individuels avec support formateur<br><br>
</body>
</html>