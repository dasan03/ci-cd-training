<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Module 1 - Fondamentaux CI/CD</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 2cm; line-height: 1.6; }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; }
        h2 { color: #34495e; margin-top: 2em; }
        h3 { color: #7f8c8d; }
        code { background: #f8f9fa; padding: 2px 4px; border-radius: 3px; }
        pre { background: #f8f9fa; padding: 1em; border-radius: 5px; overflow-x: auto; }
        li { margin: 0.5em 0; }
        @media print {
            body { margin: 1cm; }
            h1 { page-break-before: always; }
        }
    </style>
</head>
<body>
    <h1>Module 1 - Fondamentaux CI/CD</h1>
    <h1>Module 1 - Fondamentaux CI/CD</h1><br><br><h1>Module 1 - Fondamentaux CI/CD</h1><br><br><h2>📋 Informations Générales</h2><br><br><li><strong>Durée</strong> : 4 heures</li><br><li><strong>Niveau</strong> : Débutant</li><br><li><strong>Prérequis</strong> : Bases du développement logiciel, notions de Git</li><br><li><strong>Compétences</strong> : C8, C17</li><br><br><h2>🎯 Objectifs Pédagogiques</h2><br><br>À l'issue de ce module, vous serez capable de :<br><li>Comprendre les concepts fondamentaux CI/CD</li><br><li>Différencier les tests manuels et automatisés</li><br><li>Configurer un pipeline CI/CD de base</li><br><li>Intégrer des tests automatisés dans un pipeline</li><br><li>Utiliser GitHub Actions et Docker pour l'automatisation</li><br><br><h2>📚 Table des Matières</h2><br><br><h3>[📖 Support Théorique](support-theorique.md)</h3><br><br>#### Section 1 : Introduction aux Concepts CI/CD (45 min)<br><li>[1.1 Qu'est-ce que CI/CD ?](support-theorique.md#11-quest-ce-que-cicd)</li><br><li>[1.2 Différences tests manuels vs automatisés](support-theorique.md#12-tests-manuels-vs-automatises)</li><br><li>[1.3 Avantages de l'automatisation](support-theorique.md#13-avantages-automatisation)</li><br><li><strong>[💻 Exercice associé](../../exercices/module-1/exercice-1-1.md)</strong> : Premier pipeline CI/CD</li><br><br>#### Section 2 : Types et Catégories de Tests (45 min)<br><li>[2.1 Tests unitaires, d'intégration, fonctionnels](support-theorique.md#21-types-de-tests)</li><br><li>[2.2 Pyramide des tests](support-theorique.md#22-pyramide-des-tests)</li><br><li>[2.3 Tests de régression](support-theorique.md#23-tests-regression)</li><br><li><strong>[💻 Exercice associé](../../exercices/module-1/exercice-1-2.md)</strong> : Configuration de tests automatisés</li><br><br>#### Section 3 : Intégration des Tests dans CI/CD (45 min)<br><li>[3.1 Stratégies d'intégration](support-theorique.md#31-strategies-integration)</li><br><li>[3.2 Tests en parallèle](support-theorique.md#32-tests-paralleles)</li><br><li>[3.3 Gestion des échecs](support-theorique.md#33-gestion-echecs)</li><br><li><strong>[💻 Exercice associé](../../exercices/module-1/exercice-1-3.md)</strong> : Intégration de tests en parallèle</li><br><br>#### Section 4 : Outils et Bonnes Pratiques (45 min)<br><li>[4.1 GitHub Actions](support-theorique.md#41-github-actions)</li><br><li>[4.2 Jenkins](support-theorique.md#42-jenkins)</li><br><li>[4.3 Docker pour les tests](support-theorique.md#43-docker-tests)</li><br><li>[4.4 Bonnes pratiques](support-theorique.md#44-bonnes-pratiques)</li><br><br><h3>[💻 Exercices Pratiques](../../exercices/module-1/README.md)</h3><br><br>| Exercice | Titre | Durée | Difficulté | Outils |<br>|----------|-------|-------|------------|--------|<br>| <strong>[1.1](../../exercices/module-1/exercice-1-1.md)</strong> | Premier pipeline CI/CD avec GitHub Actions | 30 min | 🟢 Débutant | GitHub Actions, Docker |<br>| <strong>[1.2](../../exercices/module-1/exercice-1-2.md)</strong> | Configuration de tests automatisés avec Docker | 30 min | 🟢 Débutant | Docker, PyTest |<br>| <strong>[1.3](../../exercices/module-1/exercice-1-3.md)</strong> | Intégration de tests en parallèle | 30 min | 🟡 Intermédiaire | GitHub Actions, Matrix |<br><br><h3>[✅ QCM Intermédiaire](../../evaluations/qcm-intermediaires/module-1-qcm.md)</h3><br><br><li><strong>8 questions</strong> couvrant tous les concepts</li><br><li><strong>Durée</strong> : 15 minutes</li><br><li><strong>Seuil de réussite</strong> : 6/8 (75%)</li><br><li><strong>Compétences évaluées</strong> : C8, C17</li><br><br>#### Répartition des Questions<br><li>Questions 1-2 : Concepts CI/CD</li><br><li>Questions 3-4 : Types de tests</li><br><li>Questions 5-6 : Intégration dans pipelines</li><br><li>Questions 7-8 : Outils et bonnes pratiques</li><br><br><h2>🔗 Liens Croisés</h2><br><br><h3>Vers les Autres Modules</h3><br><li><strong>[Module 2](../module-2-ia-tests/README.md)</strong> : Approfondissement avec l'IA</li><br><li><strong>[Module 3](../module-3-tests-fonctionnels/README.md)</strong> : Tests fonctionnels avancés</li><br><li><strong>[Module 4](../module-4-documentation/README.md)</strong> : Documentation des pipelines</li><br><br><h3>Vers les Ressources</h3><br><li><strong>[Templates GitHub Actions](../../ressources/templates/github-actions-templates.md)</strong></li><br><li><strong>[Configuration Docker](../../ressources/outils/docker-setup.md)</strong></li><br><li><strong>[Troubleshooting](../../ressources/troubleshooting.md#module-1)</strong></li><br><br><h3>Compétences Développées</h3><br><li><strong>[C8 - TDD](../../index.md#c8---test-driven-development-tdd)</strong> : Sections 2.1, 2.2 + Exercices 1.2, 1.3</li><br><li><strong>[C17 - Tests CI/CD](../../index.md#c17---tests-automatises-dans-cicd)</strong> : Toutes les sections + Tous les exercices</li><br><br><h2>📅 Planning Détaillé</h2><br><br><h3>Matin (4h) - Jour 1</h3><br><br>| Horaire | Activité | Durée | Type |<br>|---------|----------|-------|------|<br>| 09:00-09:45 | [Section 1 : Concepts CI/CD](support-theorique.md#section-1) | 45 min | 📖 Théorie |<br>| 09:45-10:15 | [Exercice 1.1 : Premier pipeline](../../exercices/module-1/exercice-1-1.md) | 30 min | 💻 Pratique |<br>| 10:15-10:30 | <strong>Pause</strong> | 15 min | ☕ |<br>| 10:30-11:15 | [Section 2 : Types de tests](support-theorique.md#section-2) | 45 min | 📖 Théorie |<br>| 11:15-11:45 | [Exercice 1.2 : Tests automatisés](../../exercices/module-1/exercice-1-2.md) | 30 min | 💻 Pratique |<br>| 11:45-12:30 | [Section 3 : Intégration tests](support-theorique.md#section-3) | 45 min | 📖 Théorie |<br>| 12:30-13:00 | [Exercice 1.3 : Tests parallèles](../../exercices/module-1/exercice-1-3.md) | 30 min | 💻 Pratique |<br>| 13:00-13:15 | [QCM Module 1](../../evaluations/qcm-intermediaires/module-1-qcm.md) | 15 min | ✅ Évaluation |<br><br><h2>🛠️ Prérequis Techniques</h2><br><br><h3>Logiciels Requis</h3><br><li><strong>Git</strong> (version 2.30+)</li><br><li><strong>Docker</strong> (version 20.10+)</li><br><li><strong>Éditeur de code</strong> (VS Code recommandé)</li><br><li><strong>Navigateur web</strong> moderne</li><br><br><h3>Comptes Nécessaires</h3><br><li><strong>GitHub</strong> (compte gratuit)</li><br><li><strong>Docker Hub</strong> (compte gratuit)</li><br><br><h3>Configuration</h3><br><li><strong>[Guide d'installation](../../ressources/outils/installation-guide.md#module-1)</strong></li><br><li><strong>[Vérification environnement](../../ressources/outils/environment-check.md)</strong></li><br><br><h2>📊 Évaluation et Validation</h2><br><br><h3>Critères de Réussite</h3><br><li>✅ Complétion des 3 exercices pratiques</li><br><li>✅ Score minimum 6/8 au QCM intermédiaire</li><br><li>✅ Démonstration d'un pipeline fonctionnel</li><br><br><h3>Indicateurs de Progression</h3><br><li><strong>Débutant</strong> : Comprend les concepts, suit les exercices guidés</li><br><li><strong>Intermédiaire</strong> : Adapte les solutions, résout les problèmes mineurs</li><br><li><strong>Avancé</strong> : Propose des améliorations, aide les autres participants</li><br><br><h2>🆘 Support et Aide</h2><br><br><h3>Pendant le Module</h3><br><li><strong>Formateur</strong> disponible en permanence</li><br><li><strong>Documentation</strong> complète fournie</li><br><li><strong>Pair programming</strong> encouragé</li><br><br><h3>Ressources d'Aide</h3><br><li><strong>[FAQ Module 1](../../ressources/faq-technique.md#module-1)</strong></li><br><li><strong>[Troubleshooting](../../ressources/troubleshooting.md#module-1)</strong></li><br><li><strong>[Glossaire](../../ressources/glossaire.md)</strong></li><br><br>---<br><br><h2>🧭 Navigation</h2><br><br><h3>Navigation Principale</h3><br><li><strong>[⬅️ Retour aux modules](../README.md)</strong></li><br><li><strong>[🏠 Index général](../../index.md)</strong></li><br><li><strong>[➡️ Module 2](../module-2-ia-tests/README.md)</strong></li><br><br><h3>Navigation Interne</h3><br><li><strong>[📖 Commencer la théorie](support-theorique.md)</strong></li><br><li><strong>[💻 Voir les exercices](../../exercices/module-1/README.md)</strong></li><br><li><strong>[✅ Passer le QCM](../../evaluations/qcm-intermediaires/module-1-qcm.md)</strong></li><br><br><h3>Outils Formateur</h3><br><li><strong>[📊 Tableau de bord](../../guides/guide-formateur.md#module-1)</strong></li><br><li><strong>[🎯 Objectifs pédagogiques](../../guides/guide-formateur.md#objectifs-module-1)</strong></li><br><li><strong>[⏱️ Gestion du temps](../../guides/guide-formateur.md#timing-module-1)</strong></li><br><br><em>Dernière mise à jour : [Date] | Version : 1.0</em><br><br>\newpage<br><br><h1>Support Théorique</h1><br><br><h1>1. Introduction à l'Automatisation des Tests</h1><br><br><h2>🎯 Objectifs d'Apprentissage</h2><br><br>À l'issue de cette section, vous serez capable de :<br><li>Distinguer les tests manuels des tests automatisés</li><br><li>Identifier les avantages et inconvénients de chaque approche</li><br><li>Comprendre les différentes catégories de tests automatisés</li><br><li>Positionner les tests dans la pyramide de test</li><br><br><h2>📋 Tests Manuels vs Tests Automatisés</h2><br><br><h3>Tests Manuels</h3><br><br>#### Définition<br>Les tests manuels sont exécutés par des testeurs humains qui interagissent directement avec l'application pour vérifier son comportement.<br><br>#### Avantages ✅<br><li><strong>Flexibilité</strong> : Adaptation rapide aux changements</li><br><li><strong>Créativité</strong> : Découverte de bugs inattendus</li><br><li><strong>Tests exploratoires</strong> : Investigation approfondie</li><br><li><strong>Tests d'utilisabilité</strong> : Évaluation de l'expérience utilisateur</li><br><li><strong>Coût initial faible</strong> : Pas de développement de scripts</li><br><br>#### Inconvénients ❌<br><li><strong>Temps d'exécution</strong> : Lent et répétitif</li><br><li><strong>Erreur humaine</strong> : Risque d'oublis ou d'incohérences</li><br><li><strong>Coût à long terme</strong> : Ressources humaines importantes</li><br><li><strong>Reproductibilité</strong> : Difficile à standardiser</li><br><li><strong>Couverture limitée</strong> : Impossible de tester tous les cas</li><br><br><h3>Tests Automatisés</h3><br><br>#### Définition<br>Les tests automatisés sont exécutés par des scripts ou des outils qui simulent les interactions utilisateur et vérifient automatiquement les résultats.<br><br>#### Avantages ✅<br><li><strong>Rapidité</strong> : Exécution en quelques minutes/heures</li><br><li><strong>Reproductibilité</strong> : Résultats cohérents et fiables</li><br><li><strong>Couverture étendue</strong> : Tests de régression complets</li><br><li><strong>Exécution continue</strong> : Intégration dans les pipelines CI/CD</li><br><li><strong>ROI à long terme</strong> : Économies sur la durée</li><br><br>#### Inconvénients ❌<br><li><strong>Coût initial élevé</strong> : Développement et maintenance des scripts</li><br><li><strong>Rigidité</strong> : Adaptation difficile aux changements d'interface</li><br><li><strong>Faux positifs/négatifs</strong> : Scripts fragiles</li><br><li><strong>Compétences techniques</strong> : Expertise en programmation requise</li><br><li><strong>Maintenance</strong> : Mise à jour constante des scripts</li><br><br><h2>🏗️ Catégories de Tests Automatisés</h2><br><br><h3>1. Tests Unitaires</h3><br><br>#### Définition<br>Tests qui vérifient le comportement d'une unité de code isolée (fonction, méthode, classe).<br><br>#### Caractéristiques<br><li><strong>Portée</strong> : Très limitée (une fonction)</li><br><li><strong>Vitesse</strong> : Très rapide (millisecondes)</li><br><li><strong>Isolation</strong> : Aucune dépendance externe</li><br><li><strong>Maintenance</strong> : Faible</li><br><br>#### Exemple<br><pre><code>python<br>def test_addition():<br>    assert add(2, 3) == 5<br>    assert add(-1, 1) == 0<br>    assert add(0, 0) == 0<br></code></pre><br><br><h3>2. Tests d'Intégration</h3><br><br>#### Définition<br>Tests qui vérifient l'interaction entre plusieurs composants ou modules.<br><br>#### Types<br><li><strong>Intégration de composants</strong> : Entre modules de l'application</li><br><li><strong>Intégration de systèmes</strong> : Entre applications différentes</li><br><li><strong>Intégration d'API</strong> : Entre services web</li><br><br>#### Exemple<br><pre><code>python<br>def test_user_registration_integration():<br>    # Test de l'intégration entre le service utilisateur et la base de données<br>    user_service = UserService()<br>    user_data = {"name": "John", "email": "john@example.com"}<br>    <br>    user_id = user_service.create_user(user_data)<br>    retrieved_user = user_service.get_user(user_id)<br>    <br>    assert retrieved_user.name == "John"<br>    assert retrieved_user.email == "john@example.com"<br></code></pre><br><br><h3>3. Tests End-to-End (E2E)</h3><br><br>#### Définition<br>Tests qui simulent un parcours utilisateur complet à travers l'application.<br><br>#### Caractéristiques<br><li><strong>Portée</strong> : Application complète</li><br><li><strong>Vitesse</strong> : Lent (minutes)</li><br><li><strong>Réalisme</strong> : Proche de l'utilisation réelle</li><br><li><strong>Complexité</strong> : Élevée</li><br><br>#### Exemple<br><pre><code>javascript<br>// Test Cypress E2E<br>describe('User Login Flow', () => {<br>  it('should allow user to login and access dashboard', () => {<br>    cy.visit('/login')<br>    cy.get('[data-cy=email]').type('user@example.com')<br>    cy.get('[data-cy=password]').type('password123')<br>    cy.get('[data-cy=login-button]').click()<br>    <br>    cy.url().should('include', '/dashboard')<br>    cy.get('[data-cy=welcome-message]').should('contain', 'Welcome')<br>  })<br>})<br></code></pre><br><br><h3>4. Tests Non-Fonctionnels</h3><br><br>#### Tests de Performance<br>Vérifient les temps de réponse, le débit et la consommation de ressources.<br><br><pre><code>bash<br><h1>Exemple avec JMeter</h1><br>jmeter -n -t test-plan.jmx -l results.jtl<br></code></pre><br><br>#### Tests de Sécurité<br>Identifient les vulnérabilités et failles de sécurité.<br><br><pre><code>bash<br><h1>Exemple avec OWASP ZAP</h1><br>zap-baseline.py -t https://example.com<br></code></pre><br><br>#### Tests de Charge<br>Évaluent le comportement sous forte charge utilisateur.<br><br><h2>📊 La Pyramide de Test</h2><br><br><h3>Structure de la Pyramide</h3><br><br><pre><code><br>        /\<br>       /  \<br>      / E2E \<br>     /______\<br>    /        \<br>   /Integration\<br>  /__________\<br> /            \<br>/   Unitaires  \<br>/______________\<br></code></pre><br><br><h3>Répartition Recommandée</h3><br><li><strong>70% Tests Unitaires</strong> : Base solide, rapides et fiables</li><br><li><strong>20% Tests d'Intégration</strong> : Vérification des interactions</li><br><li><strong>10% Tests E2E</strong> : Validation des parcours critiques</li><br><br><h3>Principes</h3><br>1. <strong>Plus on monte, plus c'est lent</strong> : Les tests E2E prennent plus de temps<br>2. <strong>Plus on monte, plus c'est fragile</strong> : Les tests E2E sont plus susceptibles de casser<br>3. <strong>Plus on monte, plus c'est cher</strong> : Coût de développement et maintenance élevé<br><br><h2>🔄 Cycle de Vie des Tests Automatisés</h2><br><br><h3>1. Planification</h3><br><li>Identification des cas de test à automatiser</li><br><li>Priorisation selon le ROI</li><br><li>Choix des outils et frameworks</li><br><br><h3>2. Développement</h3><br><li>Écriture des scripts de test</li><br><li>Mise en place de l'infrastructure</li><br><li>Configuration des environnements</li><br><br><h3>3. Exécution</h3><br><li>Lancement des tests</li><br><li>Collecte des résultats</li><br><li>Analyse des échecs</li><br><br><h3>4. Maintenance</h3><br><li>Mise à jour des scripts</li><br><li>Optimisation des performances</li><br><li>Refactoring du code de test</li><br><br><h2>🎯 Critères de Sélection pour l'Automatisation</h2><br><br><h3>Tests à Automatiser ✅</h3><br><li><strong>Tests de régression</strong> : Exécutés fréquemment</li><br><li><strong>Tests répétitifs</strong> : Même scénario, données différentes</li><br><li><strong>Tests critiques</strong> : Fonctionnalités essentielles</li><br><li><strong>Tests de performance</strong> : Impossible manuellement</li><br><li><strong>Tests sur plusieurs environnements</strong> : Navigateurs, OS</li><br><br><h3>Tests à Garder Manuels ❌</h3><br><li><strong>Tests exploratoires</strong> : Créativité humaine requise</li><br><li><strong>Tests d'utilisabilité</strong> : Ressenti utilisateur</li><br><li><strong>Tests ad-hoc</strong> : Exécution ponctuelle</li><br><li><strong>Tests complexes</strong> : ROI négatif</li><br><li><strong>Tests d'accessibilité</strong> : Jugement humain nécessaire</li><br><br><h2>📈 Métriques et Indicateurs</h2><br><br><h3>Métriques de Couverture</h3><br><li><strong>Couverture de code</strong> : Pourcentage de code testé</li><br><li><strong>Couverture fonctionnelle</strong> : Pourcentage de fonctionnalités testées</li><br><li><strong>Couverture de régression</strong> : Tests de non-régression</li><br><br><h3>Métriques de Qualité</h3><br><li><strong>Taux de détection de bugs</strong> : Bugs trouvés par les tests</li><br><li><strong>Temps de feedback</strong> : Délai entre commit et résultat</li><br><li><strong>Stabilité des tests</strong> : Pourcentage de tests stables</li><br><br><h3>Métriques de Performance</h3><br><li><strong>Temps d'exécution</strong> : Durée totale des tests</li><br><li><strong>Parallélisation</strong> : Nombre de tests en parallèle</li><br><li><strong>Utilisation des ressources</strong> : CPU, mémoire, réseau</li><br><br><h2>🛠️ Bonnes Pratiques</h2><br><br><h3>1. Stratégie de Test</h3><br><li>Suivre la pyramide de test</li><br><li>Prioriser selon la criticité business</li><br><li>Maintenir un équilibre coût/bénéfice</li><br><br><h3>2. Conception des Tests</h3><br><li>Tests indépendants et isolés</li><br><li>Données de test gérées proprement</li><br><li>Assertions claires et spécifiques</li><br><br><h3>3. Maintenance</h3><br><li>Refactoring régulier du code de test</li><br><li>Suppression des tests obsolètes</li><br><li>Documentation à jour</li><br><br><h3>4. Intégration CI/CD</h3><br><li>Exécution automatique sur chaque commit</li><br><li>Feedback rapide aux développeurs</li><br><li>Blocage des déploiements en cas d'échec</li><br><br><h2>🎓 Points Clés à Retenir</h2><br><br>1. <strong>Complémentarité</strong> : Tests manuels et automatisés se complètent<br>2. <strong>Pyramide de test</strong> : Fondation solide avec les tests unitaires<br>3. <strong>ROI</strong> : L'automatisation est un investissement à long terme<br>4. <strong>Maintenance</strong> : Les tests automatisés nécessitent une maintenance continue<br>5. <strong>Stratégie</strong> : Choisir les bons tests à automatiser est crucial<br><br>---<br><br><strong>Prochaine section :</strong> [Mise en place d'un pipeline CI/CD de base](02-pipeline-cicd-base.md)<br><br><strong>Compétences travaillées :</strong> C8, C17  <br><strong>Durée estimée :</strong> 90 minutes<br><br><h1>2. Mise en Place d'un Pipeline CI/CD de Base</h1><br><br><h2>🎯 Objectifs d'Apprentissage</h2><br><br>À l'issue de cette section, vous serez capable de :<br><li>Comprendre les concepts fondamentaux de CI/CD</li><br><li>Différencier CI, CD (Delivery) et CD (Deployment)</li><br><li>Identifier les composants d'un pipeline CI/CD</li><br><li>Configurer un pipeline simple avec GitHub Actions</li><br><br><h2>🔄 Concepts Fondamentaux CI/CD</h2><br><br><h3>Continuous Integration (CI)</h3><br><br>#### Définition<br>L'intégration continue est une pratique de développement où les développeurs intègrent fréquemment leur code dans un dépôt partagé, déclenchant automatiquement des builds et des tests.<br><br>#### Principes Clés<br><li><strong>Commits fréquents</strong> : Intégration plusieurs fois par jour</li><br><li><strong>Build automatique</strong> : Compilation automatique du code</li><br><li><strong>Tests automatiques</strong> : Validation immédiate des changements</li><br><li><strong>Feedback rapide</strong> : Notification immédiate des problèmes</li><br><br>#### Bénéfices<br><li><strong>Détection précoce des bugs</strong> : Problèmes identifiés rapidement</li><br><li><strong>Réduction des conflits</strong> : Intégration fréquente évite les gros merges</li><br><li><strong>Qualité constante</strong> : Validation continue du code</li><br><li><strong>Confiance accrue</strong> : Base de code toujours stable</li><br><br><h3>Continuous Delivery (CD)</h3><br><br>#### Définition<br>La livraison continue étend la CI en automatisant la préparation des releases, rendant le code toujours prêt à être déployé en production.<br><br>#### Caractéristiques<br><li><strong>Automatisation complète</strong> : Du code à l'environnement de staging</li><br><li><strong>Déploiement manuel</strong> : Décision humaine pour la production</li><br><li><strong>Environnements identiques</strong> : Cohérence dev/staging/prod</li><br><li><strong>Rollback facile</strong> : Retour en arrière rapide si nécessaire</li><br><br><h3>Continuous Deployment (CD)</h3><br><br>#### Définition<br>Le déploiement continu pousse l'automatisation jusqu'au déploiement automatique en production après validation des tests.<br><br>#### Différences avec Delivery<br><li><strong>Déploiement automatique</strong> : Aucune intervention humaine</li><br><li><strong>Tests exhaustifs</strong> : Couverture de test très élevée requise</li><br><li><strong>Monitoring avancé</strong> : Surveillance continue de la production</li><br><li><strong>Culture DevOps mature</strong> : Organisation adaptée aux changements fréquents</li><br><br><h2>🏗️ Architecture d'un Pipeline CI/CD</h2><br><br><h3>Composants Principaux</h3><br><br><pre><code>mermaid<br>graph LR<br>    A[Code Source] --> B[Build]<br>    B --> C[Tests Unitaires]<br>    C --> D[Tests d'Intégration]<br>    D --> E[Packaging]<br>    E --> F[Déploiement Staging]<br>    F --> G[Tests E2E]<br>    G --> H[Déploiement Production]<br></code></pre><br><br><h3>1. Source Control</h3><br><li><strong>Git</strong> : Gestion de versions distribuée</li><br><li><strong>Branches</strong> : Stratégies de branching (GitFlow, GitHub Flow)</li><br><li><strong>Pull Requests</strong> : Revue de code et validation</li><br><br><h3>2. Build Stage</h3><br><li><strong>Compilation</strong> : Transformation du code source</li><br><li><strong>Gestion des dépendances</strong> : Installation des packages</li><br><li><strong>Optimisation</strong> : Minification, bundling</li><br><li><strong>Artefacts</strong> : Production des livrables</li><br><br><h3>3. Test Stage</h3><br><li><strong>Tests unitaires</strong> : Validation des composants isolés</li><br><li><strong>Tests d'intégration</strong> : Vérification des interactions</li><br><li><strong>Tests de sécurité</strong> : Scan des vulnérabilités</li><br><li><strong>Analyse de code</strong> : Qualité et conformité</li><br><br><h3>4. Deploy Stage</h3><br><li><strong>Environnements</strong> : Dev, Staging, Production</li><br><li><strong>Stratégies</strong> : Blue-Green, Rolling, Canary</li><br><li><strong>Configuration</strong> : Gestion des variables d'environnement</li><br><li><strong>Monitoring</strong> : Surveillance post-déploiement</li><br><br><h2>🛠️ Outils CI/CD Populaires</h2><br><br><h3>Plateformes Cloud</h3><br><li><strong>GitHub Actions</strong> : Intégré à GitHub, workflows YAML</li><br><li><strong>GitLab CI/CD</strong> : Pipeline as Code, runners distribués</li><br><li><strong>Azure DevOps</strong> : Suite complète Microsoft</li><br><li><strong>AWS CodePipeline</strong> : Service AWS natif</li><br><br><h3>Solutions On-Premise</h3><br><li><strong>Jenkins</strong> : Open source, très extensible</li><br><li><strong>TeamCity</strong> : JetBrains, interface intuitive</li><br><li><strong>Bamboo</strong> : Atlassian, intégration Jira</li><br><li><strong>CircleCI</strong> : Cloud et on-premise</li><br><br><h3>Outils Spécialisés</h3><br><li><strong>Docker</strong> : Containerisation des applications</li><br><li><strong>Kubernetes</strong> : Orchestration de conteneurs</li><br><li><strong>Terraform</strong> : Infrastructure as Code</li><br><li><strong>Ansible</strong> : Automatisation de configuration</li><br><br><h2>🚀 GitHub Actions - Introduction</h2><br><br><h3>Concepts de Base</h3><br><br>#### Workflow<br>Processus automatisé défini dans un fichier YAML, déclenché par des événements.<br><br><pre><code>yaml<br>name: CI Pipeline<br>on:<br>  push:<br>    branches: [ main, develop ]<br>  pull_request:<br>    branches: [ main ]<br></code></pre><br><br>#### Jobs<br>Ensemble d'étapes exécutées sur un runner.<br><br><pre><code>yaml<br>jobs:<br>  build:<br>    runs-on: ubuntu-latest<br>    steps:<br>      - uses: actions/checkout@v3<br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: '18'<br></code></pre><br><br>#### Actions<br>Composants réutilisables pour automatiser des tâches.<br><br><pre><code>yaml<br><li>name: Run tests</li><br>  run: npm test<br><li>name: Upload coverage</li><br>  uses: codecov/codecov-action@v3<br></code></pre><br><br><h3>Structure d'un Workflow</h3><br><br><pre><code>yaml<br>name: Complete CI/CD Pipeline<br><br>on:<br>  push:<br>    branches: [ main ]<br>  pull_request:<br>    branches: [ main ]<br><br>env:<br>  NODE_VERSION: '18'<br><br>jobs:<br>  test:<br>    runs-on: ubuntu-latest<br>    steps:<br>      - name: Checkout code<br>        uses: actions/checkout@v3<br>      <br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: ${{ env.NODE_VERSION }}<br>          cache: 'npm'<br>      <br>      - name: Install dependencies<br>        run: npm ci<br>      <br>      - name: Run linting<br>        run: npm run lint<br>      <br>      - name: Run unit tests<br>        run: npm test -- --coverage<br>      <br>      - name: Upload coverage reports<br>        uses: codecov/codecov-action@v3<br><br>  build:<br>    needs: test<br>    runs-on: ubuntu-latest<br>    steps:<br>      - name: Checkout code<br>        uses: actions/checkout@v3<br>      <br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: ${{ env.NODE_VERSION }}<br>          cache: 'npm'<br>      <br>      - name: Install dependencies<br>        run: npm ci<br>      <br>      - name: Build application<br>        run: npm run build<br>      <br>      - name: Upload build artifacts<br>        uses: actions/upload-artifact@v3<br>        with:<br>          name: build-files<br>          path: dist/<br><br>  deploy:<br>    needs: build<br>    runs-on: ubuntu-latest<br>    if: github.ref == 'refs/heads/main'<br>    steps:<br>      - name: Download build artifacts<br>        uses: actions/download-artifact@v3<br>        with:<br>          name: build-files<br>          path: dist/<br>      <br>      - name: Deploy to staging<br>        run: |<br>          echo "Deploying to staging environment"<br>          # Commandes de déploiement<br></code></pre><br><br><h2>🔧 Configuration d'un Pipeline Simple</h2><br><br><h3>Étape 1 : Préparation du Projet</h3><br><br><pre><code>bash<br><h1>Structure du projet</h1><br>my-app/<br>├── .github/<br>│   └── workflows/<br>│       └── ci.yml<br>├── src/<br>├── tests/<br>├── package.json<br>└── README.md<br></code></pre><br><br><h3>Étape 2 : Configuration Package.json</h3><br><br><pre><code>json<br>{<br>  "name": "my-app",<br>  "scripts": {<br>    "test": "jest",<br>    "lint": "eslint src/",<br>    "build": "webpack --mode production",<br>    "start": "node dist/server.js"<br>  },<br>  "devDependencies": {<br>    "jest": "^29.0.0",<br>    "eslint": "^8.0.0",<br>    "webpack": "^5.0.0"<br>  }<br>}<br></code></pre><br><br><h3>Étape 3 : Workflow CI/CD</h3><br><br><pre><code>yaml<br>name: CI/CD Pipeline<br><br>on:<br>  push:<br>    branches: [ main, develop ]<br>  pull_request:<br>    branches: [ main ]<br><br>jobs:<br>  quality-checks:<br>    runs-on: ubuntu-latest<br>    steps:<br>      - uses: actions/checkout@v3<br>      <br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: '18'<br>          cache: 'npm'<br>      <br>      - name: Install dependencies<br>        run: npm ci<br>      <br>      - name: Code linting<br>        run: npm run lint<br>      <br>      - name: Security audit<br>        run: npm audit --audit-level high<br>      <br>      - name: Run tests<br>        run: npm test -- --coverage --watchAll=false<br>      <br>      - name: SonarCloud Scan<br>        uses: SonarSource/sonarcloud-github-action@master<br>        env:<br>          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}<br>          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}<br><br>  build-and-deploy:<br>    needs: quality-checks<br>    runs-on: ubuntu-latest<br>    if: github.ref == 'refs/heads/main'<br>    steps:<br>      - uses: actions/checkout@v3<br>      <br>      - name: Setup Node.js<br>        uses: actions/setup-node@v3<br>        with:<br>          node-version: '18'<br>          cache: 'npm'<br>      <br>      - name: Install dependencies<br>        run: npm ci<br>      <br>      - name: Build application<br>        run: npm run build<br>      <br>      - name: Build Docker image<br>        run: |<br>          docker build -t my-app:${{ github.sha }} .<br>          docker tag my-app:${{ github.sha }} my-app:latest<br>      <br>      - name: Deploy to staging<br>        run: |<br>          echo "Deploying to staging environment"<br>          # Commandes de déploiement spécifiques<br></code></pre><br><br><h2>📊 Métriques et Monitoring</h2><br><br><h3>Métriques de Pipeline</h3><br><li><strong>Temps de build</strong> : Durée totale du pipeline</li><br><li><strong>Taux de succès</strong> : Pourcentage de builds réussis</li><br><li><strong>Temps de feedback</strong> : Délai entre commit et notification</li><br><li><strong>Fréquence de déploiement</strong> : Nombre de déploiements par période</li><br><br><h3>Monitoring des Applications</h3><br><li><strong>Uptime</strong> : Disponibilité du service</li><br><li><strong>Performance</strong> : Temps de réponse, throughput</li><br><li><strong>Erreurs</strong> : Taux d'erreur, logs d'exception</li><br><li><strong>Utilisation</strong> : CPU, mémoire, stockage</li><br><br><h3>Outils de Monitoring</h3><br><li><strong>Prometheus + Grafana</strong> : Métriques et dashboards</li><br><li><strong>ELK Stack</strong> : Logs centralisés</li><br><li><strong>New Relic / DataDog</strong> : APM complet</li><br><li><strong>GitHub Insights</strong> : Métriques de développement</li><br><br><h2>🛡️ Sécurité dans les Pipelines</h2><br><br><h3>Gestion des Secrets</h3><br><pre><code>yaml<br><li>name: Deploy to production</li><br>  env:<br>    API_KEY: ${{ secrets.API_KEY }}<br>    DB_PASSWORD: ${{ secrets.DB_PASSWORD }}<br>  run: |<br>    echo "Deploying with secure credentials"<br></code></pre><br><br><h3>Scan de Sécurité</h3><br><pre><code>yaml<br><li>name: Security scan</li><br>  uses: securecodewarrior/github-action-add-sarif@v1<br>  with:<br>    sarif-file: security-scan-results.sarif<br></code></pre><br><br><h3>Bonnes Pratiques</h3><br><li><strong>Principe du moindre privilège</strong> : Permissions minimales</li><br><li><strong>Rotation des secrets</strong> : Renouvellement régulier</li><br><li><strong>Audit des accès</strong> : Traçabilité des actions</li><br><li><strong>Isolation des environnements</strong> : Séparation dev/prod</li><br><br><h2>🎯 Stratégies de Déploiement</h2><br><br><h3>Blue-Green Deployment</h3><br><li><strong>Deux environnements identiques</strong> : Blue (actuel) et Green (nouveau)</li><br><li><strong>Bascule instantanée</strong> : Switch du trafic</li><br><li><strong>Rollback rapide</strong> : Retour à l'environnement précédent</li><br><br><h3>Rolling Deployment</h3><br><li><strong>Mise à jour progressive</strong> : Instance par instance</li><br><li><strong>Disponibilité continue</strong> : Service toujours accessible</li><br><li><strong>Détection d'erreurs</strong> : Arrêt automatique si problème</li><br><br><h3>Canary Deployment</h3><br><li><strong>Déploiement partiel</strong> : Petit pourcentage d'utilisateurs</li><br><li><strong>Validation progressive</strong> : Augmentation graduelle</li><br><li><strong>Risque minimisé</strong> : Impact limité en cas de problème</li><br><br><h2>🎓 Points Clés à Retenir</h2><br><br>1. <strong>CI/CD = Automatisation</strong> : Réduction des tâches manuelles répétitives<br>2. <strong>Feedback rapide</strong> : Détection précoce des problèmes<br>3. <strong>Déploiements fréquents</strong> : Réduction des risques par petits changements<br>4. <strong>Culture DevOps</strong> : Collaboration entre développement et opérations<br>5. <strong>Amélioration continue</strong> : Optimisation constante des processus<br><br>---<br><br><strong>Section précédente :</strong> [Introduction à l'automatisation des tests](01-introduction-automatisation-tests.md)  <br><strong>Prochaine section :</strong> [Intégration des tests dans CI/CD](03-integration-tests-cicd.md)<br><br><strong>Compétences travaillées :</strong> C8, C17  <br><strong>Durée estimée :</strong> 120 minutes<br><br><h1>3. Intégration des Tests dans le Cycle CI/CD</h1><br><br><h2>🎯 Objectifs d'Apprentissage</h2><br><br>À l'issue de cette section, vous serez capable de :<br><li>Intégrer différents types de tests dans un pipeline CI/CD</li><br><li>Configurer l'exécution parallèle des tests</li><br><li>Mettre en place des gates de qualité</li><br><li>Optimiser les temps d'exécution des tests</li><br><br><h2>🔄 Stratégie d'Intégration des Tests</h2><br><br><h3>Placement des Tests dans le Pipeline</h3><br><br><pre><code>mermaid<br>graph TD<br>    A[Code Commit] --> B[Build]<br>    B --> C[Tests Unitaires]<br>    C --> D[Tests d'Intégration]<br>    D --> E[Analyse Statique]<br>    E --> F[Build Artefacts]<br>    F --> G[Déploiement Staging]<br>    G --> H[Tests E2E]<br>    H --> I[Tests de Performance]<br>    I --> J[Tests de Sécurité]<br>    J --> K[Déploiement Production]<br>    <br>    C --> L[Fail Fast]<br>    D --> L<br>    H --> M[Rollback si échec]<br>    I --> M<br>    J --> M<br></code></pre><br><br><h3>Principe du "Fail Fast"</h3><br><br>#### Concept<br>Arrêter le pipeline dès qu'un test échoue pour économiser du temps et des ressources.<br><br>#### Implémentation<br><pre><code>yaml<br>jobs:<br>  unit-tests:<br>    runs-on: ubuntu-latest<br>    steps:<br>      - name: Run unit tests<br>        run: npm test<br>        # Si les tests unitaires échouent, le pipeline s'arrête ici<br>  <br>  integration-tests:<br>    needs: unit-tests  # Ne s'exécute que si unit-tests réussit<br>    runs-on: ubuntu-latest<br>    steps:<br>      - name: Run integration tests<br>        run: npm run test:integration<br></code></pre><br><br><h2>🧪 Configuration des Tests par Type</h2><br><br><h3>Tests Unitaires</h3><br><br>#### Caractéristiques<br><li><strong>Exécution</strong> : Première étape après le build</li><br><li><strong>Durée</strong> : Très rapide (< 5 minutes)</li><br><li><strong>Parallélisation</strong> : Fortement recommandée</li><br><li><strong>Couverture</strong> : Objectif 80%+</li><br><br>#### Configuration GitHub Actions<br><pre><code>yaml<br>unit-tests:<br>  runs-on: ubuntu-latest<br>  strategy:<br>    matrix:<br>      node-version: [16, 18, 20]<br>  steps:<br>    - uses: actions/checkout@v3<br>    - name: Setup Node.js ${{ matrix.node-version }}<br>      uses: actions/setup-node@v3<br>      with:<br>        node-version: ${{ matrix.node-version }}<br>    <br>    - name: Install dependencies<br>      run: npm ci<br>    <br>    - name: Run unit tests<br>      run: npm test -- --coverage --maxWorkers=4<br>    <br>    - name: Upload coverage to Codecov<br>      uses: codecov/codecov-action@v3<br>      with:<br>        file: ./coverage/lcov.info<br>        flags: unittests<br>        name: codecov-umbrella<br></code></pre><br><br><h3>Tests d'Intégration</h3><br><br>#### Configuration avec Services<br><pre><code>yaml<br>integration-tests:<br>  runs-on: ubuntu-latest<br>  services:<br>    postgres:<br>      image: postgres:13<br>      env:<br>        POSTGRES_PASSWORD: postgres<br>        POSTGRES_DB: testdb<br>      options: >-<br>        --health-cmd pg_isready<br>        --health-interval 10s<br>        --health-timeout 5s<br>        --health-retries 5<br>    <br>    redis:<br>      image: redis:6<br>      options: >-<br>        --health-cmd "redis-cli ping"<br>        --health-interval 10s<br>        --health-timeout 5s<br>        --health-retries 5<br>  <br>  steps:<br>    - uses: actions/checkout@v3<br>    - name: Setup Node.js<br>      uses: actions/setup-node@v3<br>      with:<br>        node-version: '18'<br>    <br>    - name: Install dependencies<br>      run: npm ci<br>    <br>    - name: Run database migrations<br>      run: npm run db:migrate<br>      env:<br>        DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb<br>    <br>    - name: Run integration tests<br>      run: npm run test:integration<br>      env:<br>        DATABASE_URL: postgres://postgres:postgres@localhost:5432/testdb<br>        REDIS_URL: redis://localhost:6379<br></code></pre><br><br><h3>Tests End-to-End</h3><br><br>#### Configuration avec Cypress<br><pre><code>yaml<br>e2e-tests:<br>  runs-on: ubuntu-latest<br>  steps:<br>    - uses: actions/checkout@v3<br>    <br>    - name: Setup Node.js<br>      uses: actions/setup-node@v3<br>      with:<br>        node-version: '18'<br>    <br>    - name: Install dependencies<br>      run: npm ci<br>    <br>    - name: Build application<br>      run: npm run build<br>    <br>    - name: Start application<br>      run: npm start &<br>      <br>    - name: Wait for application<br>      run: npx wait-on http://localhost:3000<br>    <br>    - name: Run Cypress tests<br>      uses: cypress-io/github-action@v5<br>      with:<br>        start: npm start<br>        wait-on: 'http://localhost:3000'<br>        wait-on-timeout: 120<br>        browser: chrome<br>        record: true<br>      env:<br>        CYPRESS_RECORD_KEY: ${{ secrets.CYPRESS_RECORD_KEY }}<br>        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}<br></code></pre><br><br><h2>⚡ Optimisation des Performances</h2><br><br><h3>Parallélisation des Tests</h3><br><br>#### Tests Unitaires en Parallèle<br><pre><code>yaml<br>unit-tests:<br>  runs-on: ubuntu-latest<br>  strategy:<br>    matrix:<br>      shard: [1, 2, 3, 4]<br>  steps:<br>    - uses: actions/checkout@v3<br>    - name: Setup Node.js<br>      uses: actions/setup-node@v3<br>      with:<br>        node-version: '18'<br>    <br>    - name: Install dependencies<br>      run: npm ci<br>    <br>    - name: Run tests shard ${{ matrix.shard }}<br>      run: npm test -- --shard=${{ matrix.shard }}/4<br></code></pre><br><br>#### Tests E2E en Parallèle<br><pre><code>yaml<br>e2e-tests:<br>  runs-on: ubuntu-latest<br>  strategy:<br>    matrix:<br>      containers: [1, 2, 3, 4]<br>  steps:<br>    - uses: actions/checkout@v3<br>    - name: Run Cypress tests<br>      uses: cypress-io/github-action@v5<br>      with:<br>        start: npm start<br>        wait-on: 'http://localhost:3000'<br>        record: true<br>        parallel: true<br>        group: 'Actions example'<br>      env:<br>        CYPRESS_RECORD_KEY: ${{ secrets.CYPRESS_RECORD_KEY }}<br></code></pre><br><br><h3>Cache et Optimisations</h3><br><br>#### Cache des Dépendances<br><pre><code>yaml<br><li>name: Cache Node modules</li><br>  uses: actions/cache@v3<br>  with:<br>    path: ~/.npm<br>    key: ${{ runner.os }}-node-${{ hashFiles('<em></em>/package-lock.json') }}<br>    restore-keys: |<br>      ${{ runner.os }}-node-<br><br><li>name: Install dependencies</li><br>  run: npm ci --prefer-offline --no-audit<br></code></pre><br><br>#### Cache des Builds<br><pre><code>yaml<br><li>name: Cache build output</li><br>  uses: actions/cache@v3<br>  with:<br>    path: |<br>      dist/<br>      .next/cache<br>    key: ${{ runner.os }}-build-${{ github.sha }}<br>    restore-keys: |<br>      ${{ runner.os }}-build-<br></code></pre><br><br><h2>🚪 Gates de Qualité</h2><br><br><h3>Couverture de Code</h3><br><br>#### Configuration avec Jest<br><pre><code>javascript<br>// jest.config.js<br>module.exports = {<br>  collectCoverage: true,<br>  coverageThreshold: {<br>    global: {<br>      branches: 80,<br>      functions: 80,<br>      lines: 80,<br>      statements: 80<br>    }<br>  },<br>  coverageReporters: ['text', 'lcov', 'html']<br>};<br></code></pre><br><br>#### Intégration dans le Pipeline<br><pre><code>yaml<br><li>name: Run tests with coverage</li><br>  run: npm test -- --coverage<br>  <br><li>name: Check coverage threshold</li><br>  run: |<br>    COVERAGE=$(cat coverage/coverage-summary.json | jq '.total.lines.pct')<br>    if (( $(echo "$COVERAGE < 80" | bc -l) )); then<br>      echo "Coverage $COVERAGE% is below threshold of 80%"<br>      exit 1<br>    fi<br></code></pre><br><br><h3>Analyse Statique</h3><br><br>#### SonarQube Integration<br><pre><code>yaml<br><li>name: SonarQube Scan</li><br>  uses: sonarqube-quality-gate-action@master<br>  env:<br>    SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}<br>  with:<br>    scanMetadataReportFile: target/sonar/report-task.txt<br><br><li>name: Quality Gate check</li><br>  id: sonarqube-quality-gate-check<br>  uses: sonarqube-quality-gate-action@master<br>  timeout-minutes: 5<br>  env:<br>    SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}<br></code></pre><br><br>#### ESLint avec Annotations<br><pre><code>yaml<br><li>name: Run ESLint</li><br>  run: npx eslint . --format @microsoft/eslint-formatter-sarif --output-file eslint-results.sarif<br>  continue-on-error: true<br><br><li>name: Upload analysis results to GitHub</li><br>  uses: github/codeql-action/upload-sarif@v2<br>  with:<br>    sarif_file: eslint-results.sarif<br>    wait-for-processing: true<br></code></pre><br><br><h2>🔍 Tests de Sécurité</h2><br><br><h3>Scan des Dépendances</h3><br><br>#### npm audit<br><pre><code>yaml<br><li>name: Security audit</li><br>  run: |<br>    npm audit --audit-level high<br>    npm audit --json > audit-results.json<br>    <br><li>name: Upload audit results</li><br>  uses: actions/upload-artifact@v3<br>  with:<br>    name: security-audit<br>    path: audit-results.json<br></code></pre><br><br>#### Snyk Integration<br><pre><code>yaml<br><li>name: Run Snyk to check for vulnerabilities</li><br>  uses: snyk/actions/node@master<br>  env:<br>    SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}<br>  with:<br>    args: --severity-threshold=high<br></code></pre><br><br><h3>SAST (Static Application Security Testing)</h3><br><br>#### CodeQL Analysis<br><pre><code>yaml<br><li>name: Initialize CodeQL</li><br>  uses: github/codeql-action/init@v2<br>  with:<br>    languages: javascript<br><br><li>name: Autobuild</li><br>  uses: github/codeql-action/autobuild@v2<br><br><li>name: Perform CodeQL Analysis</li><br>  uses: github/codeql-action/analyze@v2<br></code></pre><br><br><h2>📊 Reporting et Notifications</h2><br><br><h3>Test Results Reporting</h3><br><br>#### Jest JUnit Reporter<br><pre><code>yaml<br><li>name: Run tests with JUnit output</li><br>  run: npm test -- --reporters=default --reporters=jest-junit<br>  env:<br>    JEST_JUNIT_OUTPUT_DIR: ./test-results<br>    JEST_JUNIT_OUTPUT_NAME: junit.xml<br><br><li>name: Publish test results</li><br>  uses: dorny/test-reporter@v1<br>  if: always()<br>  with:<br>    name: Jest Tests<br>    path: test-results/junit.xml<br>    reporter: jest-junit<br></code></pre><br><br>#### Allure Reports<br><pre><code>yaml<br><li>name: Generate Allure Report</li><br>  uses: simple-elf/allure-report-action@master<br>  if: always()<br>  with:<br>    allure_results: allure-results<br>    allure_history: allure-history<br><br><li>name: Deploy to GitHub Pages</li><br>  uses: peaceiris/actions-gh-pages@v3<br>  if: always()<br>  with:<br>    github_token: ${{ secrets.GITHUB_TOKEN }}<br>    publish_dir: allure-history<br></code></pre><br><br><h3>Notifications</h3><br><br>#### Slack Integration<br><pre><code>yaml<br><li>name: Notify Slack on failure</li><br>  if: failure()<br>  uses: 8398a7/action-slack@v3<br>  with:<br>    status: failure<br>    channel: '#ci-cd'<br>    text: 'Pipeline failed for ${{ github.repository }}'<br>  env:<br>    SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}<br></code></pre><br><br>#### Email Notifications<br><pre><code>yaml<br><li>name: Send email on failure</li><br>  if: failure()<br>  uses: dawidd6/action-send-mail@v3<br>  with:<br>    server_address: smtp.gmail.com<br>    server_port: 465<br>    username: ${{ secrets.MAIL_USERNAME }}<br>    password: ${{ secrets.MAIL_PASSWORD }}<br>    subject: 'CI/CD Pipeline Failed'<br>    to: team@company.com<br>    from: ci-cd@company.com<br>    body: |<br>      Pipeline failed for repository: ${{ github.repository }}<br>      Commit: ${{ github.sha }}<br>      Author: ${{ github.actor }}<br></code></pre><br><br><h2>🎯 Stratégies de Test par Environnement</h2><br><br><h3>Environnement de Développement</h3><br><pre><code>yaml<br>dev-tests:<br>  if: github.ref == 'refs/heads/develop'<br>  runs-on: ubuntu-latest<br>  steps:<br>    - name: Fast feedback tests<br>      run: |<br>        npm run test:unit<br>        npm run lint<br>        npm run type-check<br></code></pre><br><br><h3>Environnement de Staging</h3><br><pre><code>yaml<br>staging-tests:<br>  if: github.ref == 'refs/heads/main'<br>  runs-on: ubuntu-latest<br>  steps:<br>    - name: Comprehensive testing<br>      run: |<br>        npm run test:unit<br>        npm run test:integration<br>        npm run test:e2e<br>        npm run test:performance<br></code></pre><br><br><h3>Environnement de Production</h3><br><pre><code>yaml<br>production-tests:<br>  runs-on: ubuntu-latest<br>  steps:<br>    - name: Smoke tests<br>      run: npm run test:smoke<br>    <br>    - name: Health checks<br>      run: |<br>        curl -f https://api.example.com/health<br>        npm run test:api-health<br></code></pre><br><br><h2>🛠️ Outils d'Intégration Avancés</h2><br><br><h3>Docker pour les Tests</h3><br><br>#### Multi-stage Dockerfile<br><pre><code>dockerfile<br><h1>Test stage</h1><br>FROM node:18-alpine AS test<br>WORKDIR /app<br>COPY package*.json ./<br>RUN npm ci<br>COPY . .<br>RUN npm test<br>RUN npm run test:integration<br><br><h1>Build stage</h1><br>FROM node:18-alpine AS build<br>WORKDIR /app<br>COPY package*.json ./<br>RUN npm ci --only=production<br>COPY . .<br>RUN npm run build<br><br><h1>Production stage</h1><br>FROM node:18-alpine AS production<br>WORKDIR /app<br>COPY --from=build /app/dist ./dist<br>COPY --from=build /app/node_modules ./node_modules<br>COPY package*.json ./<br>EXPOSE 3000<br>CMD ["npm", "start"]<br></code></pre><br><br>#### Docker Compose pour Tests<br><pre><code>yaml<br>version: '3.8'<br>services:<br>  app:<br>    build:<br>      context: .<br>      target: test<br>    depends_on:<br>      - postgres<br>      - redis<br>    environment:<br>      - DATABASE_URL=postgres://user:pass@postgres:5432/testdb<br>      - REDIS_URL=redis://redis:6379<br>    command: npm test<br><br>  postgres:<br>    image: postgres:13<br>    environment:<br>      POSTGRES_USER: user<br>      POSTGRES_PASSWORD: pass<br>      POSTGRES_DB: testdb<br><br>  redis:<br>    image: redis:6-alpine<br></code></pre><br><br><h2>🎓 Points Clés à Retenir</h2><br><br>1. <strong>Stratégie de placement</strong> : Tests rapides en premier, tests lents en dernier<br>2. <strong>Parallélisation</strong> : Optimiser les temps d'exécution<br>3. <strong>Gates de qualité</strong> : Bloquer les déploiements si critères non respectés<br>4. <strong>Feedback rapide</strong> : Notifier immédiatement les développeurs<br>5. <strong>Monitoring continu</strong> : Surveiller les métriques de test<br><br>---<br><br><strong>Section précédente :</strong> [Pipeline CI/CD de base](02-pipeline-cicd-base.md)  <br><strong>Prochaine section :</strong> [Outils et bonnes pratiques](04-outils-bonnes-pratiques.md)<br><br><strong>Compétences travaillées :</strong> C8, C17  <br><strong>Durée estimée :</strong> 150 minutes<br><br><h1>4. Outils et Bonnes Pratiques</h1><br><br><h2>🎯 Objectifs d'Apprentissage</h2><br><br>À l'issue de cette section, vous serez capable de :<br><li>Choisir les outils appropriés selon le contexte</li><br><li>Appliquer les bonnes pratiques de l'industrie</li><br><li>Configurer des environnements de test robustes</li><br><li>Optimiser les workflows CI/CD</li><br><br><h2>🛠️ Panorama des Outils de Test</h2><br><br><h3>Frameworks de Test JavaScript</h3><br><br>#### Jest<br><strong>Avantages :</strong><br><li>Configuration zéro par défaut</li><br><li>Mocking intégré puissant</li><br><li>Snapshot testing</li><br><li>Couverture de code native</li><br><br><strong>Configuration type :</strong><br><pre><code>javascript<br>// jest.config.js<br>module.exports = {<br>  testEnvironment: 'node',<br>  collectCoverageFrom: [<br>    'src/<em></em>/*.{js,jsx}',<br>    '!src/index.js',<br>    '!src/<em></em>/*.test.js'<br>  ],<br>  setupFilesAfterEnv: ['<rootDir>/src/setupTests.js'],<br>  testMatch: [<br>    '<rootDir>/src/<strong>/__tests__/</strong>/*.{js,jsx}',<br>    '<rootDir>/src/<em></em>/*.{test,spec}.{js,jsx}'<br>  ]<br>};<br></code></pre><br><br><strong>Exemple de test :</strong><br><pre><code>javascript<br>// user.test.js<br>import { createUser, validateEmail } from './user';<br><br>describe('User Management', () => {<br>  test('should create user with valid data', () => {<br>    const userData = {<br>      name: 'John Doe',<br>      email: 'john@example.com'<br>    };<br>    <br>    const user = createUser(userData);<br>    <br>    expect(user).toHaveProperty('id');<br>    expect(user.name).toBe('John Doe');<br>    expect(user.email).toBe('john@example.com');<br>  });<br><br>  test('should validate email format', () => {<br>    expect(validateEmail('valid@email.com')).toBe(true);<br>    expect(validateEmail('invalid-email')).toBe(false);<br>  });<br>});<br></code></pre><br><br>#### Mocha + Chai<br><strong>Avantages :</strong><br><li>Flexibilité maximale</li><br><li>Nombreux plugins disponibles</li><br><li>Syntaxe expressive avec Chai</li><br><br><strong>Configuration :</strong><br><pre><code>javascript<br>// mocha.opts<br>--require @babel/register<br>--recursive<br>--timeout 5000<br>test/<em></em>/*.test.js<br></code></pre><br><br><strong>Exemple de test :</strong><br><pre><code>javascript<br>import { expect } from 'chai';<br>import { calculateTotal } from './calculator';<br><br>describe('Calculator', () => {<br>  it('should calculate total with tax', () => {<br>    const result = calculateTotal(100, 0.2);<br>    expect(result).to.equal(120);<br>  });<br><br>  it('should handle edge cases', () => {<br>    expect(() => calculateTotal(-100, 0.2)).to.throw('Invalid amount');<br>  });<br>});<br></code></pre><br><br><h3>Outils de Test E2E</h3><br><br>#### Cypress<br><strong>Avantages :</strong><br><li>Interface utilisateur intuitive</li><br><li>Debugging en temps réel</li><br><li>Screenshots et vidéos automatiques</li><br><li>API moderne et simple</li><br><br><strong>Configuration :</strong><br><pre><code>javascript<br>// cypress.config.js<br>import { defineConfig } from 'cypress'<br><br>export default defineConfig({<br>  e2e: {<br>    baseUrl: 'http://localhost:3000',<br>    supportFile: 'cypress/support/e2e.js',<br>    specPattern: 'cypress/e2e/<em></em>/*.cy.{js,jsx,ts,tsx}',<br>    video: true,<br>    screenshotOnRunFailure: true,<br>    viewportWidth: 1280,<br>    viewportHeight: 720,<br>    defaultCommandTimeout: 10000,<br>    requestTimeout: 10000,<br>    responseTimeout: 10000<br>  }<br>})<br></code></pre><br><br><strong>Exemple de test :</strong><br><pre><code>javascript<br>// cypress/e2e/login.cy.js<br>describe('User Authentication', () => {<br>  beforeEach(() => {<br>    cy.visit('/login');<br>  });<br><br>  it('should login with valid credentials', () => {<br>    cy.get('[data-cy=email]').type('user@example.com');<br>    cy.get('[data-cy=password]').type('password123');<br>    cy.get('[data-cy=login-button]').click();<br>    <br>    cy.url().should('include', '/dashboard');<br>    cy.get('[data-cy=welcome-message]').should('be.visible');<br>  });<br><br>  it('should show error with invalid credentials', () => {<br>    cy.get('[data-cy=email]').type('invalid@example.com');<br>    cy.get('[data-cy=password]').type('wrongpassword');<br>    cy.get('[data-cy=login-button]').click();<br>    <br>    cy.get('[data-cy=error-message]')<br>      .should('be.visible')<br>      .and('contain', 'Invalid credentials');<br>  });<br>});<br></code></pre><br><br>#### Playwright<br><strong>Avantages :</strong><br><li>Support multi-navigateurs natif</li><br><li>Parallélisation avancée</li><br><li>API moderne avec async/await</li><br><li>Capture de traces détaillées</li><br><br><strong>Configuration :</strong><br><pre><code>javascript<br>// playwright.config.js<br>import { defineConfig, devices } from '@playwright/test';<br><br>export default defineConfig({<br>  testDir: './tests',<br>  fullyParallel: true,<br>  forbidOnly: !!process.env.CI,<br>  retries: process.env.CI ? 2 : 0,<br>  workers: process.env.CI ? 1 : undefined,<br>  reporter: 'html',<br>  use: {<br>    baseURL: 'http://localhost:3000',<br>    trace: 'on-first-retry',<br>    screenshot: 'only-on-failure',<br>  },<br>  projects: [<br>    {<br>      name: 'chromium',<br>      use: { ...devices['Desktop Chrome'] },<br>    },<br>    {<br>      name: 'firefox',<br>      use: { ...devices['Desktop Firefox'] },<br>    },<br>    {<br>      name: 'webkit',<br>      use: { ...devices['Desktop Safari'] },<br>    },<br>  ],<br>});<br></code></pre><br><br><strong>Exemple de test :</strong><br><pre><code>javascript<br>// tests/login.spec.js<br>import { test, expect } from '@playwright/test';<br><br>test.describe('User Authentication', () => {<br>  test('should login successfully', async ({ page }) => {<br>    await page.goto('/login');<br>    <br>    await page.fill('[data-testid=email]', 'user@example.com');<br>    await page.fill('[data-testid=password]', 'password123');<br>    await page.click('[data-testid=login-button]');<br>    <br>    await expect(page).toHaveURL(/.*dashboard/);<br>    await expect(page.locator('[data-testid=welcome]')).toBeVisible();<br>  });<br><br>  test('should handle login failure', async ({ page }) => {<br>    await page.goto('/login');<br>    <br>    await page.fill('[data-testid=email]', 'invalid@example.com');<br>    await page.fill('[data-testid=password]', 'wrongpassword');<br>    await page.click('[data-testid=login-button]');<br>    <br>    await expect(page.locator('[data-testid=error]')).toContainText('Invalid credentials');<br>  });<br>});<br></code></pre><br><br>#### Selenium WebDriver<br><strong>Avantages :</strong><br><li>Standard de l'industrie</li><br><li>Support de nombreux langages</li><br><li>Écosystème mature</li><br><li>Grid pour tests distribués</li><br><br><strong>Exemple avec Node.js :</strong><br><pre><code>javascript<br>// selenium-test.js<br>import { Builder, By, until } from 'selenium-webdriver';<br>import chrome from 'selenium-webdriver/chrome';<br><br>describe('Selenium Tests', () => {<br>  let driver;<br><br>  beforeEach(async () => {<br>    const options = new chrome.Options();<br>    options.addArguments('--headless');<br>    options.addArguments('--no-sandbox');<br>    <br>    driver = await new Builder()<br>      .forBrowser('chrome')<br>      .setChromeOptions(options)<br>      .build();<br>  });<br><br>  afterEach(async () => {<br>    await driver.quit();<br>  });<br><br>  test('should perform login', async () => {<br>    await driver.get('http://localhost:3000/login');<br>    <br>    await driver.findElement(By.id('email')).sendKeys('user@example.com');<br>    await driver.findElement(By.id('password')).sendKeys('password123');<br>    await driver.findElement(By.id('login-button')).click();<br>    <br>    await driver.wait(until.urlContains('dashboard'), 10000);<br>    <br>    const welcomeElement = await driver.findElement(By.id('welcome'));<br>    const isDisplayed = await welcomeElement.isDisplayed();<br>    expect(isDisplayed).toBe(true);<br>  });<br>});<br></code></pre><br><br><h2>🔧 Outils d'Analyse et de Qualité</h2><br><br><h3>ESLint - Analyse Statique</h3><br><br>#### Configuration avancée<br><pre><code>javascript<br>// .eslintrc.js<br>module.exports = {<br>  env: {<br>    browser: true,<br>    es2021: true,<br>    node: true,<br>    jest: true<br>  },<br>  extends: [<br>    'eslint:recommended',<br>    '@typescript-eslint/recommended',<br>    'plugin:react/recommended',<br>    'plugin:react-hooks/recommended',<br>    'plugin:jsx-a11y/recommended'<br>  ],<br>  parser: '@typescript-eslint/parser',<br>  parserOptions: {<br>    ecmaFeatures: {<br>      jsx: true<br>    },<br>    ecmaVersion: 12,<br>    sourceType: 'module'<br>  },<br>  plugins: [<br>    'react',<br>    '@typescript-eslint',<br>    'jsx-a11y',<br>    'import'<br>  ],<br>  rules: {<br>    'no-console': 'warn',<br>    'no-unused-vars': 'error',<br>    'prefer-const': 'error',<br>    'react/prop-types': 'off',<br>    '@typescript-eslint/no-unused-vars': 'error',<br>    'import/order': ['error', {<br>      'groups': ['builtin', 'external', 'internal'],<br>      'newlines-between': 'always'<br>    }]<br>  },<br>  settings: {<br>    react: {<br>      version: 'detect'<br>    }<br>  }<br>};<br></code></pre><br><br><h3>SonarQube - Qualité de Code</h3><br><br>#### Configuration projet<br><pre><code>properties<br><h1>sonar-project.properties</h1><br>sonar.projectKey=my-project<br>sonar.projectName=My Project<br>sonar.projectVersion=1.0<br>sonar.sources=src<br>sonar.tests=src<br>sonar.test.inclusions=<strong>/<em>.test.js,</strong>/</em>.spec.js<br>sonar.javascript.lcov.reportPaths=coverage/lcov.info<br>sonar.coverage.exclusions=<strong>/<em>.test.js,</strong>/</em>.spec.js,<strong>/node_modules/</strong><br></code></pre><br><br>#### Intégration CI/CD<br><pre><code>yaml<br><li>name: SonarQube Scan</li><br>  uses: sonarqube-quality-gate-action@master<br>  env:<br>    SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}<br>    SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}<br></code></pre><br><br><h3>Lighthouse - Performance Web</h3><br><br>#### Configuration CI<br><pre><code>yaml<br><li>name: Lighthouse CI</li><br>  uses: treosh/lighthouse-ci-action@v9<br>  with:<br>    configPath: './lighthouserc.json'<br>    uploadArtifacts: true<br>    temporaryPublicStorage: true<br></code></pre><br><br>#### Configuration Lighthouse<br><pre><code>json<br>{<br>  "ci": {<br>    "collect": {<br>      "url": ["http://localhost:3000"],<br>      "startServerCommand": "npm start",<br>      "numberOfRuns": 3<br>    },<br>    "assert": {<br>      "assertions": {<br>        "categories:performance": ["warn", {"minScore": 0.9}],<br>        "categories:accessibility": ["error", {"minScore": 0.9}],<br>        "categories:best-practices": ["warn", {"minScore": 0.9}],<br>        "categories:seo": ["warn", {"minScore": 0.9}]<br>      }<br>    },<br>    "upload": {<br>      "target": "temporary-public-storage"<br>    }<br>  }<br>}<br></code></pre><br><br><h2>📊 Monitoring et Observabilité</h2><br><br><h3>Prometheus + Grafana</h3><br><br>#### Métriques applicatives<br><pre><code>javascript<br>// metrics.js<br>import client from 'prom-client';<br><br>const httpRequestDuration = new client.Histogram({<br>  name: 'http_request_duration_seconds',<br>  help: 'Duration of HTTP requests in seconds',<br>  labelNames: ['method', 'route', 'status_code']<br>});<br><br>const httpRequestsTotal = new client.Counter({<br>  name: 'http_requests_total',<br>  help: 'Total number of HTTP requests',<br>  labelNames: ['method', 'route', 'status_code']<br>});<br><br>export const recordHttpRequest = (method, route, statusCode, duration) => {<br>  httpRequestsTotal.inc({ method, route, status_code: statusCode });<br>  httpRequestDuration.observe({ method, route, status_code: statusCode }, duration);<br>};<br></code></pre><br><br>#### Dashboard Grafana<br><pre><code>json<br>{<br>  "dashboard": {<br>    "title": "Application Metrics",<br>    "panels": [<br>      {<br>        "title": "Request Rate",<br>        "type": "graph",<br>        "targets": [<br>          {<br>            "expr": "rate(http_requests_total[5m])",<br>            "legendFormat": "{{method}} {{route}}"<br>          }<br>        ]<br>      },<br>      {<br>        "title": "Response Time",<br>        "type": "graph",<br>        "targets": [<br>          {<br>            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",<br>            "legendFormat": "95th percentile"<br>          }<br>        ]<br>      }<br>    ]<br>  }<br>}<br></code></pre><br><br><h3>ELK Stack - Logs</h3><br><br>#### Configuration Logstash<br><pre><code>ruby<br><h1>logstash.conf</h1><br>input {<br>  beats {<br>    port => 5044<br>  }<br>}<br><br>filter {<br>  if [fields][logtype] == "application" {<br>    json {<br>      source => "message"<br>    }<br>    <br>    date {<br>      match => [ "timestamp", "ISO8601" ]<br>    }<br>    <br>    mutate {<br>      remove_field => [ "message" ]<br>    }<br>  }<br>}<br><br>output {<br>  elasticsearch {<br>    hosts => ["elasticsearch:9200"]<br>    index => "application-logs-%{+YYYY.MM.dd}"<br>  }<br>}<br></code></pre><br><br><h2>🏗️ Infrastructure as Code</h2><br><br><h3>Docker pour les Tests</h3><br><br>#### Multi-stage optimisé<br><pre><code>dockerfile<br><h1>Dockerfile.test</h1><br>FROM node:18-alpine AS base<br>WORKDIR /app<br>COPY package*.json ./<br>RUN npm ci --only=production && npm cache clean --force<br><br>FROM base AS dev-deps<br>RUN npm ci<br><br>FROM dev-deps AS test<br>COPY . .<br>RUN npm run lint<br>RUN npm run test:unit<br>RUN npm run test:integration<br><br>FROM base AS production<br>COPY --from=test /app/dist ./dist<br>EXPOSE 3000<br>CMD ["npm", "start"]<br></code></pre><br><br>#### Docker Compose pour développement<br><pre><code>yaml<br><h1>docker-compose.test.yml</h1><br>version: '3.8'<br><br>services:<br>  app:<br>    build:<br>      context: .<br>      dockerfile: Dockerfile.test<br>      target: test<br>    depends_on:<br>      postgres:<br>        condition: service_healthy<br>      redis:<br>        condition: service_healthy<br>    environment:<br>      - NODE_ENV=test<br>      - DATABASE_URL=postgres://test:test@postgres:5432/testdb<br>      - REDIS_URL=redis://redis:6379<br>    volumes:<br>      - ./coverage:/app/coverage<br><br>  postgres:<br>    image: postgres:13-alpine<br>    environment:<br>      POSTGRES_USER: test<br>      POSTGRES_PASSWORD: test<br>      POSTGRES_DB: testdb<br>    healthcheck:<br>      test: ["CMD-SHELL", "pg_isready -U test"]<br>      interval: 10s<br>      timeout: 5s<br>      retries: 5<br><br>  redis:<br>    image: redis:6-alpine<br>    healthcheck:<br>      test: ["CMD", "redis-cli", "ping"]<br>      interval: 10s<br>      timeout: 5s<br>      retries: 5<br></code></pre><br><br><h3>Kubernetes pour les Tests</h3><br><br>#### Job de test<br><pre><code>yaml<br><h1>test-job.yaml</h1><br>apiVersion: batch/v1<br>kind: Job<br>metadata:<br>  name: app-tests<br>spec:<br>  template:<br>    spec:<br>      containers:<br>      - name: test-runner<br>        image: myapp:test<br>        command: ["npm", "run", "test:ci"]<br>        env:<br>        - name: DATABASE_URL<br>          valueFrom:<br>            secretKeyRef:<br>              name: db-secret<br>              key: url<br>        resources:<br>          requests:<br>            memory: "512Mi"<br>            cpu: "500m"<br>          limits:<br>            memory: "1Gi"<br>            cpu: "1000m"<br>      restartPolicy: Never<br>  backoffLimit: 3<br></code></pre><br><br><h2>🎯 Bonnes Pratiques Avancées</h2><br><br><h3>Test Data Management</h3><br><br>#### Factory Pattern<br><pre><code>javascript<br>// factories/userFactory.js<br>import { faker } from '@faker-js/faker';<br><br>export const createUser = (overrides = {}) => ({<br>  id: faker.datatype.uuid(),<br>  name: faker.name.fullName(),<br>  email: faker.internet.email(),<br>  createdAt: faker.date.recent(),<br>  ...overrides<br>});<br><br>export const createUsers = (count = 5, overrides = {}) => <br>  Array.from({ length: count }, () => createUser(overrides));<br></code></pre><br><br>#### Database Seeding<br><pre><code>javascript<br>// seeds/testData.js<br>import { createUser } from '../factories/userFactory';<br>import { User } from '../models/User';<br><br>export const seedTestData = async () => {<br>  // Clean existing data<br>  await User.deleteMany({});<br>  <br>  // Create test users<br>  const users = createUsers(10);<br>  await User.insertMany(users);<br>  <br>  return { users };<br>};<br></code></pre><br><br><h3>Page Object Model</h3><br><br>#### Page Object<br><pre><code>javascript<br>// pages/LoginPage.js<br>export class LoginPage {<br>  constructor(page) {<br>    this.page = page;<br>    this.emailInput = '[data-testid=email]';<br>    this.passwordInput = '[data-testid=password]';<br>    this.loginButton = '[data-testid=login-button]';<br>    this.errorMessage = '[data-testid=error-message]';<br>  }<br><br>  async goto() {<br>    await this.page.goto('/login');<br>  }<br><br>  async login(email, password) {<br>    await this.page.fill(this.emailInput, email);<br>    await this.page.fill(this.passwordInput, password);<br>    await this.page.click(this.loginButton);<br>  }<br><br>  async getErrorMessage() {<br>    return await this.page.textContent(this.errorMessage);<br>  }<br><br>  async isErrorVisible() {<br>    return await this.page.isVisible(this.errorMessage);<br>  }<br>}<br></code></pre><br><br>#### Utilisation dans les tests<br><pre><code>javascript<br>// tests/login.spec.js<br>import { test, expect } from '@playwright/test';<br>import { LoginPage } from '../pages/LoginPage';<br><br>test.describe('Login Tests', () => {<br>  let loginPage;<br><br>  test.beforeEach(async ({ page }) => {<br>    loginPage = new LoginPage(page);<br>    await loginPage.goto();<br>  });<br><br>  test('should login with valid credentials', async () => {<br>    await loginPage.login('user@example.com', 'password123');<br>    await expect(page).toHaveURL(/.*dashboard/);<br>  });<br><br>  test('should show error with invalid credentials', async () => {<br>    await loginPage.login('invalid@example.com', 'wrongpassword');<br>    <br>    expect(await loginPage.isErrorVisible()).toBe(true);<br>    expect(await loginPage.getErrorMessage()).toContain('Invalid credentials');<br>  });<br>});<br></code></pre><br><br><h3>Test Environment Management</h3><br><br>#### Configuration par environnement<br><pre><code>javascript<br>// config/test.js<br>const config = {<br>  development: {<br>    database: {<br>      host: 'localhost',<br>      port: 5432,<br>      name: 'myapp_dev'<br>    },<br>    redis: {<br>      host: 'localhost',<br>      port: 6379<br>    }<br>  },<br>  test: {<br>    database: {<br>      host: process.env.DB_HOST || 'localhost',<br>      port: process.env.DB_PORT || 5432,<br>      name: 'myapp_test'<br>    },<br>    redis: {<br>      host: process.env.REDIS_HOST || 'localhost',<br>      port: process.env.REDIS_PORT || 6379<br>    }<br>  },<br>  ci: {<br>    database: {<br>      host: 'postgres',<br>      port: 5432,<br>      name: 'testdb'<br>    },<br>    redis: {<br>      host: 'redis',<br>      port: 6379<br>    }<br>  }<br>};<br><br>export default config[process.env.NODE_ENV || 'development'];<br></code></pre><br><br><h2>🎓 Points Clés à Retenir</h2><br><br>1. <strong>Choix d'outils</strong> : Adapter selon le contexte et les besoins<br>2. <strong>Configuration</strong> : Investir dans une configuration robuste<br>3. <strong>Maintenance</strong> : Prévoir la maintenance des tests et outils<br>4. <strong>Monitoring</strong> : Surveiller les performances et la qualité<br>5. <strong>Évolution</strong> : Rester à jour avec les nouvelles pratiques<br><br>---<br><br><strong>Section précédente :</strong> [Intégration des tests dans CI/CD](03-integration-tests-cicd.md)  <br><strong>Module suivant :</strong> [Module 2 - IA et Automatisation des Tests](../../module-2-ia-tests/README.md)<br><br><strong>Compétences travaillées :</strong> C8, C17  <br><strong>Durée estimée :</strong> 120 minutes<br><br><h1>Support Théorique - Module 1 : Fondamentaux CI/CD</h1><br><br><h2>Vue d'Ensemble du Contenu</h2><br><br>Ce support théorique couvre l'ensemble des concepts fondamentaux nécessaires pour comprendre et implémenter l'automatisation des tests dans un contexte CI/CD. Le contenu est structuré en 4 sections progressives, équivalent à 30 slides de présentation.<br><br><h2>Progression Pédagogique</h2><br><br><h3>🎯 Objectifs Généraux</h3><br>À l'issue de ce module théorique, les apprenants seront capables de :<br><li>Maîtriser les concepts fondamentaux de CI/CD</li><br><li>Distinguer et utiliser les différents types de tests automatisés</li><br><li>Configurer un pipeline CI/CD complet avec GitHub Actions</li><br><li>Appliquer les bonnes pratiques de l'industrie</li><br><li>Choisir les outils appropriés selon le contexte</li><br><br><h2>Structure du Contenu</h2><br><br><h3>[Section 1 : Introduction à l'Automatisation des Tests](01-introduction-automatisation-tests.md)</h3><br><strong>Durée :</strong> 90 minutes | <strong>Slides équivalent :</strong> 8 slides<br><br>#### Points Clés Abordés<br><li><strong>Tests Manuels vs Automatisés</strong> : Avantages, inconvénients, cas d'usage</li><br><li><strong>Catégories de Tests</strong> : Unitaires, intégration, E2E, non-fonctionnels</li><br><li><strong>Pyramide de Test</strong> : Structure, répartition, principes</li><br><li><strong>Critères de Sélection</strong> : Quels tests automatiser, ROI</li><br><li><strong>Métriques</strong> : Couverture, qualité, performance</li><br><br>#### Compétences Développées<br><li>Analyse des besoins en automatisation</li><br><li>Compréhension des stratégies de test</li><br><li>Évaluation du ROI de l'automatisation</li><br><br>---<br><br><h3>[Section 2 : Mise en Place d'un Pipeline CI/CD de Base](02-pipeline-cicd-base.md)</h3><br><strong>Durée :</strong> 120 minutes | <strong>Slides équivalent :</strong> 10 slides<br><br>#### Points Clés Abordés<br><li><strong>Concepts CI/CD</strong> : Définitions, différences CI/CD/CD</li><br><li><strong>Architecture Pipeline</strong> : Composants, flux, étapes</li><br><li><strong>GitHub Actions</strong> : Workflows, jobs, actions</li><br><li><strong>Configuration</strong> : YAML, variables, secrets</li><br><li><strong>Stratégies de Déploiement</strong> : Blue-Green, Rolling, Canary</li><br><br>#### Compétences Développées<br><li>Configuration de workflows automatisés</li><br><li>Compréhension des architectures CI/CD</li><br><li>Maîtrise des outils cloud (GitHub Actions)</li><br><br>---<br><br><h3>[Section 3 : Intégration des Tests dans le Cycle CI/CD](03-integration-tests-cicd.md)</h3><br><strong>Durée :</strong> 150 minutes | <strong>Slides équivalent :</strong> 12 slides<br><br>#### Points Clés Abordés<br><li><strong>Stratégies d'Intégration</strong> : Placement, séquencement, parallélisation</li><br><li><strong>Configuration par Type</strong> : Unitaires, intégration, E2E</li><br><li><strong>Optimisation</strong> : Cache, parallélisation, fail-fast</li><br><li><strong>Gates de Qualité</strong> : Couverture, seuils, blocages</li><br><li><strong>Reporting</strong> : Notifications, métriques, dashboards</li><br><br>#### Compétences Développées<br><li>Optimisation des pipelines de test</li><br><li>Configuration d'environnements de test</li><br><li>Mise en place de gates de qualité</li><br><br>---<br><br><h3>[Section 4 : Outils et Bonnes Pratiques](04-outils-bonnes-pratiques.md)</h3><br><strong>Durée :</strong> 120 minutes | <strong>Slides équivalent :</strong> 10 slides<br><br>#### Points Clés Abordés<br><li><strong>Frameworks de Test</strong> : Jest, Mocha, Cypress, Playwright, Selenium</li><br><li><strong>Outils d'Analyse</strong> : ESLint, SonarQube, Lighthouse</li><br><li><strong>Infrastructure</strong> : Docker, Kubernetes, IaC</li><br><li><strong>Patterns Avancés</strong> : Page Object Model, Factory Pattern</li><br><li><strong>Monitoring</strong> : Prometheus, Grafana, ELK Stack</li><br><br>#### Compétences Développées<br><li>Sélection d'outils appropriés</li><br><li>Application de patterns de test</li><br><li>Mise en place de monitoring</li><br><br><h2>Ressources Pédagogiques</h2><br><br><h3>Diagrammes et Schémas</h3><br><li>Pyramide de test interactive</li><br><li>Architecture de pipeline CI/CD</li><br><li>Flux de données dans les tests</li><br><li>Comparaison d'outils</li><br><br><h3>Exemples de Code</h3><br><li>Configuration GitHub Actions complète</li><br><li>Tests unitaires avec Jest</li><br><li>Tests E2E avec Cypress et Playwright</li><br><li>Configuration Docker multi-stage</li><br><br><h3>Cas Pratiques</h3><br><li>Projet web moderne (React/Node.js)</li><br><li>API REST avec base de données</li><br><li>Application microservices</li><br><li>Pipeline de déploiement cloud</li><br><br><h2>Évaluation des Acquis</h2><br><br><h3>Questions de Compréhension</h3><br>Chaque section inclut des questions pour vérifier la compréhension :<br><li>Questions conceptuelles</li><br><li>Exercices de réflexion</li><br><li>Cas d'usage pratiques</li><br><br><h3>QCM Intermédiaire</h3><br>8 questions couvrant l'ensemble du module :<br><li>2 questions sur les concepts de base</li><br><li>2 questions sur les types de tests</li><br><li>2 questions sur les pipelines CI/CD</li><br><li>2 questions sur les outils et bonnes pratiques</li><br><br><h2>Liens entre les Sections</h2><br><br><pre><code>mermaid<br>graph TD<br>    A[Section 1: Introduction Tests] --> B[Section 2: Pipeline CI/CD]<br>    B --> C[Section 3: Intégration Tests]<br>    C --> D[Section 4: Outils & Pratiques]<br>    <br>    A --> E[Concepts Fondamentaux]<br>    B --> F[Configuration Pratique]<br>    C --> G[Optimisation]<br>    D --> H[Expertise Avancée]<br>    <br>    E --> F --> G --> H<br></code></pre><br><br><h2>Adaptation selon le Public</h2><br><br><h3>Développeurs Débutants</h3><br><li>Focus sur les concepts de base</li><br><li>Exemples simples et progressifs</li><br><li>Accompagnement renforcé sur la configuration</li><br><br><h3>Développeurs Expérimentés</h3><br><li>Approfondissement des bonnes pratiques</li><br><li>Patterns avancés</li><br><li>Optimisations et monitoring</li><br><br><h3>DevOps/SRE</h3><br><li>Architecture et scalabilité</li><br><li>Monitoring et observabilité</li><br><li>Stratégies de déploiement avancées</li><br><br><h2>Ressources Complémentaires</h2><br><br><h3>Documentation Officielle</h3><br><li>[GitHub Actions](https://docs.github.com/en/actions)</li><br><li>[Jest](https://jestjs.io/docs/getting-started)</li><br><li>[Cypress](https://docs.cypress.io/)</li><br><li>[Playwright](https://playwright.dev/docs/intro)</li><br><br><h3>Articles et Blogs</h3><br><li>Martin Fowler sur les tests</li><br><li>Google Testing Blog</li><br><li>DevOps.com ressources CI/CD</li><br><br><h3>Outils en Ligne</h3><br><li>GitHub Actions Marketplace</li><br><li>Cypress Dashboard</li><br><li>SonarCloud</li><br><br><h2>Prochaines Étapes</h2><br><br>Après ce module théorique, les apprenants pourront :<br>1. <strong>Passer aux exercices pratiques</strong> du Module 1<br>2. <strong>Approfondir avec le Module 2</strong> (IA et automatisation)<br>3. <strong>Appliquer dans leurs projets</strong> personnels ou professionnels<br><br>---<br><br><strong>Compétences ECF travaillées :</strong> C8 (Réaliser des tests d'intégration), C17 (Automatiser les tests)  <br><strong>Durée totale :</strong> 480 minutes (8 heures)  <br><strong>Format :</strong> Théorie interactive avec démonstrations<br><br>\newpage<br><br><h1>Exercices Pratiques</h1><br><br><h1>Exercices Pratiques - Module 1 : Fondamentaux CI/CD</h1><br><br><h2>Vue d'Ensemble</h2><br><br>Ce module contient 3 exercices pratiques progressifs qui permettent d'appliquer concrètement les concepts théoriques abordés dans le Module 1. Chaque exercice est conçu pour renforcer les compétences C8 (Réaliser des tests d'intégration) et C17 (Automatiser les tests).<br><br><h2>Structure des Exercices</h2><br><br><h3>🎯 Progression Pédagogique</h3><br><br>Les exercices suivent une progression logique :<br>1. <strong>Exercice 1.1</strong> : Découverte et configuration de base<br>2. <strong>Exercice 1.2</strong> : Approfondissement avec containerisation<br>3. <strong>Exercice 1.3</strong> : Optimisation et bonnes pratiques<br><br><h3>📋 Format Standard</h3><br><br>Chaque exercice comprend :<br><li><strong>Objectifs d'apprentissage</strong> clairs et mesurables</li><br><li><strong>Prérequis techniques</strong> et connaissances nécessaires</li><br><li><strong>Énoncé détaillé</strong> avec contexte professionnel</li><br><li><strong>Instructions étape par étape</strong> avec captures d'écran</li><br><li><strong>Fichiers de ressources</strong> et templates fournis</li><br><li><strong>Solution complète</strong> avec explications</li><br><li><strong>Points de validation</strong> pour auto-évaluation</li><br><li><strong>Extensions possibles</strong> pour aller plus loin</li><br><br><h2>Liste des Exercices</h2><br><br><h3>[Exercice 1.1 - Premier Pipeline CI/CD avec GitHub Actions](exercice-1.1-premier-pipeline/README.md)</h3><br><strong>Durée :</strong> 90 minutes  <br><strong>Niveau :</strong> Débutant  <br><strong>Objectif :</strong> Créer son premier workflow GitHub Actions avec build et tests unitaires<br><br><strong>Compétences travaillées :</strong><br><li>Configuration de workflows automatisés</li><br><li>Intégration de tests unitaires dans CI/CD</li><br><li>Gestion des artefacts de build</li><br><br>---<br><br><h3>[Exercice 1.2 - Configuration de Tests Automatisés avec Docker](exercice-1.2-tests-docker/README.md)</h3><br><strong>Durée :</strong> 120 minutes  <br><strong>Niveau :</strong> Intermédiaire  <br><strong>Objectif :</strong> Mettre en place un environnement de test containerisé avec services<br><br><strong>Compétences travaillées :</strong><br><li>Containerisation des environnements de test</li><br><li>Configuration de services de test (base de données, cache)</li><br><li>Tests d'intégration avec dépendances externes</li><br><br>---<br><br><h3>[Exercice 1.3 - Intégration de Tests en Parallèle](exercice-1.3-tests-paralleles/README.md)</h3><br><strong>Durée :</strong> 90 minutes  <br><strong>Niveau :</strong> Intermédiaire/Avancé  <br><strong>Objectif :</strong> Optimiser les temps d'exécution avec la parallélisation des tests<br><br><strong>Compétences travaillées :</strong><br><li>Optimisation des pipelines CI/CD</li><br><li>Parallélisation des tests</li><br><li>Monitoring et métriques de performance</li><br><br><h2>Prérequis Généraux</h2><br><br><h3>Outils Requis</h3><br><li><strong>Git</strong> : Version 2.30+</li><br><li><strong>Node.js</strong> : Version 18+ avec npm</li><br><li><strong>Docker Desktop</strong> : Version 4.0+</li><br><li><strong>Compte GitHub</strong> : Avec accès aux GitHub Actions</li><br><li><strong>IDE</strong> : VS Code recommandé avec extensions Git et Docker</li><br><br><h3>Connaissances Préalables</h3><br><li>Bases de Git (clone, commit, push, pull)</li><br><li>Notions de ligne de commande</li><br><li>Concepts de base du développement web</li><br><li>Compréhension des concepts HTTP/REST</li><br><br><h3>Configuration de l'Environnement</h3><br>Avant de commencer les exercices, suivez le [Guide de Configuration](../../../ressources/outils/outils-requis.md) pour préparer votre environnement de développement.<br><br><h2>Évaluation et Validation</h2><br><br><h3>Critères de Réussite</h3><br>Chaque exercice inclut des <strong>points de validation</strong> permettant de vérifier :<br><li>✅ Configuration correcte des outils</li><br><li>✅ Fonctionnement des workflows CI/CD</li><br><li>✅ Exécution réussie des tests</li><br><li>✅ Respect des bonnes pratiques</li><br><br><h3>Auto-Évaluation</h3><br>Des <strong>questions de réflexion</strong> sont proposées à la fin de chaque exercice pour :<br><li>Analyser les résultats obtenus</li><br><li>Identifier les points d'amélioration</li><br><li>Réfléchir aux applications en contexte professionnel</li><br><br><h3>Support et Aide</h3><br><li><strong>Solutions détaillées</strong> disponibles pour chaque exercice</li><br><li><strong>FAQ</strong> avec problèmes courants et résolutions</li><br><li><strong>Ressources complémentaires</strong> pour approfondir</li><br><br><h2>Ressources Communes</h2><br><br><h3>Templates et Fichiers de Base</h3><br><li>Configuration GitHub Actions de base</li><br><li>Dockerfile multi-stage pour tests</li><br><li>Scripts de configuration d'environnement</li><br><li>Exemples d'applications de test</li><br><br><h3>Documentation de Référence</h3><br><li>[GitHub Actions Documentation](https://docs.github.com/en/actions)</li><br><li>[Docker Documentation](https://docs.docker.com/)</li><br><li>[Jest Testing Framework](https://jestjs.io/)</li><br><li>[Node.js Best Practices](https://github.com/goldbergyoni/nodebestpractices)</li><br><br><h2>Planning Suggéré</h2><br><br><h3>Session de 4 heures (demi-journée)</h3><br><pre><code><br>09:00-09:15  | Présentation des exercices et setup<br>09:15-10:45  | Exercice 1.1 - Premier pipeline<br>10:45-11:00  | Pause<br>11:00-13:00  | Exercice 1.2 - Tests avec Docker<br>13:00-14:00  | Déjeuner<br>14:00-15:30  | Exercice 1.3 - Tests en parallèle<br>15:30-16:00  | Débriefing et questions<br></code></pre><br><br><h3>Session de 6 heures (journée complète)</h3><br><pre><code><br>09:00-09:30  | Présentation et setup environnement<br>09:30-11:00  | Exercice 1.1 - Premier pipeline<br>11:00-11:15  | Pause<br>11:15-13:15  | Exercice 1.2 - Tests avec Docker<br>13:15-14:15  | Déjeuner<br>14:15-15:45  | Exercice 1.3 - Tests en parallèle<br>15:45-16:00  | Pause<br>16:00-17:00  | Débriefing et extensions<br></code></pre><br><br><h2>Extensions et Approfondissements</h2><br><br><h3>Pour Aller Plus Loin</h3><br><li>Intégration avec SonarQube pour l'analyse de qualité</li><br><li>Configuration de notifications Slack/Teams</li><br><li>Déploiement automatique sur des environnements cloud</li><br><li>Mise en place de tests de sécurité avec Snyk</li><br><br><h3>Projets Personnels</h3><br>Les apprenants sont encouragés à :<br><li>Appliquer les concepts sur leurs propres projets</li><br><li>Adapter les configurations à leur stack technique</li><br><li>Partager leurs expériences et difficultés rencontrées</li><br><br>---<br><br><strong>Compétences ECF :</strong> C8, C17  <br><strong>Durée totale :</strong> 300 minutes (5 heures)  <br><strong>Format :</strong> Travaux pratiques individuels avec support formateur<br><br>
</body>
</html>