<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Module 3 - Tests Fonctionnels et Non-Fonctionnels</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 2cm; line-height: 1.6; }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; }
        h2 { color: #34495e; margin-top: 2em; }
        h3 { color: #7f8c8d; }
        code { background: #f8f9fa; padding: 2px 4px; border-radius: 3px; }
        pre { background: #f8f9fa; padding: 1em; border-radius: 5px; overflow-x: auto; }
        li { margin: 0.5em 0; }
        @media print {
            body { margin: 1cm; }
            h1 { page-break-before: always; }
        }
    </style>
</head>
<body>
    <h1>Module 3 - Tests Fonctionnels et Non-Fonctionnels</h1>
    <h1>Module 3 - Tests Fonctionnels et Non-Fonctionnels</h1><br><br><h1>Module 3 : Tests fonctionnels et non fonctionnels dans un pipeline CI/CD</h1><br><br><h2>Objectifs du module</h2><br><li>Ex√©cuter des tests fonctionnels et non fonctionnels dans un pipeline automatis√©</li><br><li>Assurer la qualit√© logicielle en int√©grant des tests de s√©curit√© et de performance</li><br><br><h2>Dur√©e</h2><br>6 heures (1,5 jour)<br><br><h2>Pr√©requis</h2><br><li>Environnements de test cloud (SauceLabs, BrowserStack)</li><br><li>Frameworks de test de charge (JMeter, Gatling)</li><br><li>Outils de scan de s√©curit√© (OWASP ZAP, Burp Suite)</li><br><br><h2>Structure du module</h2><br><li><code>support-theorique/</code> - Contenu des cours et pr√©sentations</li><br><li><code>exercices/</code> - Exercices pratiques avec solutions</li><br><li><code>qcm/</code> - Questions d'√©valuation interm√©diaire</li><br><li><code>ressources/</code> - Fichiers de support et templates</li><br><br>\newpage<br><br><h1>Support Th√©orique</h1><br><br><h1>1. Tests Fonctionnels Automatis√©s</h1><br><br><h2>1.1 Introduction aux Tests Fonctionnels</h2><br><br><h3>D√©finition et Objectifs</h3><br><br>Les tests fonctionnels v√©rifient que l'application fonctionne conform√©ment aux sp√©cifications m√©tier. Ils valident :<br><li>Les fonctionnalit√©s utilisateur</li><br><li>Les flux de navigation</li><br><li>L'int√©gration entre composants</li><br><li>La conformit√© aux exigences</li><br><br><h3>Types de Tests Fonctionnels</h3><br><br><strong>Tests d'Interface Utilisateur (UI)</strong><br><li>Validation des √©l√©ments visuels</li><br><li>V√©rification des interactions utilisateur</li><br><li>Tests de navigation et de workflow</li><br><br><strong>Tests d'API</strong><br><li>Validation des endpoints REST/GraphQL</li><br><li>V√©rification des contrats d'interface</li><br><li>Tests d'int√©gration entre services</li><br><br><strong>Tests End-to-End (E2E)</strong><br><li>Simulation de parcours utilisateur complets</li><br><li>Validation des flux m√©tier critiques</li><br><li>Tests cross-browser et cross-platform</li><br><br><h2>1.2 Tests UI avec Selenium</h2><br><br><h3>Pr√©sentation de Selenium</h3><br><br>Selenium est une suite d'outils pour l'automatisation des navigateurs web :<br><li><strong>Selenium WebDriver</strong> : API pour contr√¥ler les navigateurs</li><br><li><strong>Selenium Grid</strong> : Ex√©cution distribu√©e des tests</li><br><li><strong>Selenium IDE</strong> : Enregistrement et lecture de tests</li><br><br><h3>Architecture Selenium WebDriver</h3><br><br><pre><code><br>Test Script ‚Üí WebDriver API ‚Üí Browser Driver ‚Üí Browser<br></code></pre><br><br><h3>Avantages de Selenium</h3><br><li>Support multi-navigateurs (Chrome, Firefox, Safari, Edge)</li><br><li>Langages multiples (Java, Python, C#, JavaScript)</li><br><li>Int√©gration CI/CD native</li><br><li>Communaut√© active et √©cosyst√®me riche</li><br><br><h3>Exemple de Test Selenium (JavaScript)</h3><br><br><pre><code>javascript<br>const { Builder, By, until } = require('selenium-webdriver');<br><br>describe('Login Test', () => {<br>  let driver;<br><br>  beforeEach(async () => {<br>    driver = await new Builder().forBrowser('chrome').build();<br>  });<br><br>  afterEach(async () => {<br>    await driver.quit();<br>  });<br><br>  it('should login successfully', async () => {<br>    await driver.get('http://localhost:3000/login');<br>    <br>    await driver.findElement(By.id('username')).sendKeys('testuser');<br>    await driver.findElement(By.id('password')).sendKeys('password123');<br>    await driver.findElement(By.css('button[type="submit"]')).click();<br>    <br>    await driver.wait(until.urlContains('/dashboard'), 5000);<br>    <br>    const title = await driver.getTitle();<br>    expect(title).toContain('Dashboard');<br>  });<br>});<br></code></pre><br><br><h2>1.3 Tests UI avec Cypress</h2><br><br><h3>Pr√©sentation de Cypress</h3><br><br>Cypress est un framework de test moderne con√ßu pour les applications web :<br><li>Ex√©cution dans le navigateur</li><br><li>Debugging en temps r√©el</li><br><li>Captures d'√©cran et vid√©os automatiques</li><br><li>API intuitive et moderne</li><br><br><h3>Architecture Cypress</h3><br><br><pre><code><br>Test Runner ‚Üí Cypress App ‚Üí Browser (m√™me origine)<br></code></pre><br><br><h3>Avantages de Cypress</h3><br><li>Configuration minimale</li><br><li>Debugging interactif</li><br><li>Tests rapides et fiables</li><br><li>Mocking et stubbing int√©gr√©s</li><br><li>Time-travel debugging</li><br><br><h3>Exemple de Test Cypress</h3><br><br><pre><code>javascript<br>describe('E-commerce Checkout', () => {<br>  beforeEach(() => {<br>    cy.visit('/products');<br>  });<br><br>  it('should complete purchase flow', () => {<br>    // Ajouter un produit au panier<br>    cy.get('[data-testid="product-1"]').click();<br>    cy.get('[data-testid="add-to-cart"]').click();<br>    <br>    // Aller au panier<br>    cy.get('[data-testid="cart-icon"]').click();<br>    cy.url().should('include', '/cart');<br>    <br>    // Proc√©der au checkout<br>    cy.get('[data-testid="checkout-btn"]').click();<br>    <br>    // Remplir les informations<br>    cy.get('#email').type('user@example.com');<br>    cy.get('#address').type('123 Test Street');<br>    cy.get('#payment-method').select('credit-card');<br>    <br>    // Confirmer la commande<br>    cy.get('[data-testid="confirm-order"]').click();<br>    <br>    // V√©rifier la confirmation<br>    cy.contains('Order confirmed').should('be.visible');<br>    cy.url().should('include', '/order-confirmation');<br>  });<br>});<br></code></pre><br><br><h2>1.4 Tests API avec Postman</h2><br><br><h3>Pr√©sentation de Postman</h3><br><br>Postman est une plateforme compl√®te pour le d√©veloppement et test d'API :<br><li>Interface graphique intuitive</li><br><li>Collections et environnements</li><br><li>Tests automatis√©s avec scripts</li><br><li>Monitoring et documentation</li><br><br><h3>Fonctionnalit√©s Cl√©s</h3><br><li><strong>Collections</strong> : Organisation des requ√™tes</li><br><li><strong>Environments</strong> : Gestion des variables</li><br><li><strong>Tests Scripts</strong> : Validation automatis√©e</li><br><li><strong>Newman</strong> : Ex√©cution en ligne de commande</li><br><br><h3>Exemple de Test Postman</h3><br><br><pre><code>javascript<br>// Test de cr√©ation d'utilisateur<br>pm.test("User creation successful", function () {<br>    pm.response.to.have.status(201);<br>    <br>    const responseJson = pm.response.json();<br>    pm.expect(responseJson).to.have.property('id');<br>    pm.expect(responseJson.email).to.eql(pm.environment.get('user_email'));<br>    <br>    // Sauvegarder l'ID pour les tests suivants<br>    pm.environment.set('user_id', responseJson.id);<br>});<br><br>pm.test("Response time is acceptable", function () {<br>    pm.expect(pm.response.responseTime).to.be.below(2000);<br>});<br></code></pre><br><br><h2>1.5 Tests API avec RestAssured</h2><br><br><h3>Pr√©sentation de RestAssured</h3><br><br>RestAssured est une biblioth√®que Java pour tester les services REST :<br><li>Syntaxe fluide et expressive</li><br><li>Validation JSON/XML int√©gr√©e</li><br><li>Support OAuth et authentification</li><br><li>Int√©gration JUnit/TestNG</li><br><br><h3>Avantages de RestAssured</h3><br><li>API intuitive (Given-When-Then)</li><br><li>Validation de sch√©ma automatique</li><br><li>Gestion des cookies et sessions</li><br><li>Logging d√©taill√© des requ√™tes/r√©ponses</li><br><br><h3>Exemple de Test RestAssured</h3><br><br><pre><code>java<br>import static io.restassured.RestAssured.*;<br>import static org.hamcrest.Matchers.*;<br><br>public class UserApiTest {<br>    <br>    @Test<br>    public void testCreateUser() {<br>        given()<br>            .contentType("application/json")<br>            .body("{ \"name\": \"John Doe\", \"email\": \"john@example.com\" }")<br>        .when()<br>            .post("/api/users")<br>        .then()<br>            .statusCode(201)<br>            .body("name", equalTo("John Doe"))<br>            .body("email", equalTo("john@example.com"))<br>            .body("id", notNullValue())<br>            .time(lessThan(2000L));<br>    }<br>    <br>    @Test<br>    public void testGetUserById() {<br>        int userId = createTestUser();<br>        <br>        given()<br>            .pathParam("id", userId)<br>        .when()<br>            .get("/api/users/{id}")<br>        .then()<br>            .statusCode(200)<br>            .body("id", equalTo(userId))<br>            .body("name", notNullValue())<br>            .body("email", matchesPattern(".<em>@.</em>\\..*"));<br>    }<br>}<br></code></pre><br><br><h2>1.6 Strat√©gies de Test et Bonnes Pratiques</h2><br><br><h3>Pyramide des Tests</h3><br><br><pre><code><br>    E2E Tests (Peu)<br>   ‚Üó              ‚Üñ<br>Integration Tests (Quelques)<br>‚Üó                        ‚Üñ<br>Unit Tests (Beaucoup)<br></code></pre><br><br><h3>Bonnes Pratiques</h3><br><br><strong>Organisation des Tests</strong><br><li>Structure claire et coh√©rente</li><br><li>Nommage descriptif des tests</li><br><li>Groupement par fonctionnalit√©</li><br><li>Isolation des tests</li><br><br><strong>Donn√©es de Test</strong><br><li>Utilisation de fixtures</li><br><li>Nettoyage apr√®s chaque test</li><br><li>Donn√©es anonymis√©es</li><br><li>Environnements d√©di√©s</li><br><br><strong>Maintenance</strong><br><li>Page Object Model pour UI</li><br><li>Factorisation du code commun</li><br><li>Gestion des s√©lecteurs robustes</li><br><li>Documentation des tests</li><br><br><h3>Int√©gration CI/CD</h3><br><br><strong>Configuration Pipeline</strong><br><pre><code>yaml<br>test-functional:<br>  stage: test<br>  script:<br>    - npm install<br>    - npm run test:api<br>    - npm run test:ui:headless<br>  artifacts:<br>    reports:<br>      junit: test-results.xml<br>    paths:<br>      - screenshots/<br>      - videos/<br></code></pre><br><br><strong>Parall√©lisation</strong><br><li>Ex√©cution simultan√©e des tests</li><br><li>Distribution sur plusieurs agents</li><br><li>Optimisation des temps d'ex√©cution</li><br><li>Gestion des ressources partag√©es</li><br><br><h1>2. Tests de Performance et de Charge</h1><br><br><h2>2.1 Concepts de Performance et M√©triques Cl√©s</h2><br><br><h3>D√©finitions Essentielles</h3><br><br><strong>Tests de Performance</strong><br><li>√âvaluation des performances sous conditions normales</li><br><li>Mesure des temps de r√©ponse et du d√©bit</li><br><li>Identification des goulots d'√©tranglement</li><br><br><strong>Tests de Charge</strong><br><li>Validation sous charge utilisateur attendue</li><br><li>V√©rification de la stabilit√© syst√®me</li><br><li>Mesure de la d√©gradation des performances</li><br><br><strong>Tests de Stress</strong><br><li>√âvaluation au-del√† des limites normales</li><br><li>Identification du point de rupture</li><br><li>Test de r√©cup√©ration apr√®s incident</li><br><br><h3>M√©triques Cl√©s de Performance</h3><br><br><strong>Temps de R√©ponse</strong><br><li>Temps moyen, m√©dian, 95e percentile</li><br><li>Temps de premi√®re r√©ponse (TTFB)</li><br><li>Temps de chargement complet</li><br><br><strong>D√©bit (Throughput)</strong><br><li>Requ√™tes par seconde (RPS)</li><br><li>Transactions par seconde (TPS)</li><br><li>Bande passante utilis√©e</li><br><br><strong>Utilisation des Ressources</strong><br><li>CPU, m√©moire, disque, r√©seau</li><br><li>Connexions base de donn√©es</li><br><li>Files d'attente et pools de threads</li><br><br><strong>M√©triques Utilisateur</strong><br><li>Taux d'erreur</li><br><li>Taux d'abandon</li><br><li>Satisfaction utilisateur (Apdex)</li><br><br><h2>2.2 Tests de Charge avec JMeter</h2><br><br><h3>Pr√©sentation d'Apache JMeter</h3><br><br>JMeter est un outil open-source pour les tests de performance :<br><li>Interface graphique intuitive</li><br><li>Support multi-protocoles (HTTP, JDBC, JMS, etc.)</li><br><li>Extensibilit√© via plugins</li><br><li>Rapports d√©taill√©s</li><br><br><h3>Architecture JMeter</h3><br><br><pre><code><br>Test Plan<br>‚îú‚îÄ‚îÄ Thread Groups (Utilisateurs virtuels)<br>‚îú‚îÄ‚îÄ Samplers (Requ√™tes)<br>‚îú‚îÄ‚îÄ Listeners (Collecte de r√©sultats)<br>‚îú‚îÄ‚îÄ Timers (D√©lais)<br>‚îî‚îÄ‚îÄ Assertions (Validations)<br></code></pre><br><br><h3>Configuration d'un Test de Charge</h3><br><br><strong>1. Plan de Test Basique</strong><br><br><pre><code>xml<br><?xml version="1.0" encoding="UTF-8"?><br><jmeterTestPlan version="1.2"><br>  <hashTree><br>    <TestPlan testname="API Load Test"><br>      <elementProp name="TestPlan.arguments" elementType="Arguments"/><br>      <boolProp name="TestPlan.functional_mode">false</boolProp><br>      <boolProp name="TestPlan.serialize_threadgroups">false</boolProp><br>    </TestPlan><br>    <hashTree><br>      <ThreadGroup testname="Users"><br>        <stringProp name="ThreadGroup.num_threads">100</stringProp><br>        <stringProp name="ThreadGroup.ramp_time">60</stringProp><br>        <stringProp name="ThreadGroup.duration">300</stringProp><br>      </ThreadGroup><br>    </hashTree><br>  </hashTree><br></jmeterTestPlan><br></code></pre><br><br><strong>2. Exemple de Requ√™te HTTP</strong><br><br><pre><code><br>HTTP Request Sampler:<br><li>Server: api.example.com</li><br><li>Port: 443</li><br><li>Protocol: https</li><br><li>Method: POST</li><br><li>Path: /api/users</li><br><li>Body: {"name": "Test User", "email": "test@example.com"}</li><br></code></pre><br><br><h3>Strat√©gies de Mont√©e en Charge</h3><br><br><strong>Mont√©e Progressive</strong><br><pre><code><br>Utilisateurs: 0 ‚Üí 50 ‚Üí 100 ‚Üí 150 ‚Üí 200<br>Dur√©e: 0min ‚Üí 15min ‚Üí 30min ‚Üí 45min ‚Üí 60min<br></code></pre><br><br><strong>Test de Pic</strong><br><pre><code><br>Utilisateurs: 10 ‚Üí 500 ‚Üí 10<br>Dur√©e: 0min ‚Üí 5min ‚Üí 10min<br></code></pre><br><br><strong>Test de Stabilit√©</strong><br><pre><code><br>Utilisateurs: 100 (constant)<br>Dur√©e: 2 heures<br></code></pre><br><br><h2>2.3 Monitoring des Temps de R√©ponse</h2><br><br><h3>Outils de Monitoring</h3><br><br><strong>Application Performance Monitoring (APM)</strong><br><li>New Relic, Datadog, AppDynamics</li><br><li>Monitoring en temps r√©el</li><br><li>Alertes automatiques</li><br><li>Analyse des traces</li><br><br><strong>Monitoring Infrastructure</strong><br><li>Prometheus + Grafana</li><br><li>M√©triques syst√®me et application</li><br><li>Dashboards personnalis√©s</li><br><li>Historique des performances</li><br><br><h3>Configuration Prometheus</h3><br><br><pre><code>yaml<br><h1>prometheus.yml</h1><br>global:<br>  scrape_interval: 15s<br><br>scrape_configs:<br>  - job_name: 'api-server'<br>    static_configs:<br>      - targets: ['localhost:8080']<br>    metrics_path: '/metrics'<br>    scrape_interval: 5s<br></code></pre><br><br><h3>M√©triques Applicatives</h3><br><br><pre><code>javascript<br>// Exemple Node.js avec Prometheus<br>const promClient = require('prom-client');<br><br>const httpRequestDuration = new promClient.Histogram({<br>  name: 'http_request_duration_seconds',<br>  help: 'Duration of HTTP requests in seconds',<br>  labelNames: ['method', 'route', 'status_code'],<br>  buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10]<br>});<br><br>app.use((req, res, next) => {<br>  const start = Date.now();<br>  <br>  res.on('finish', () => {<br>    const duration = (Date.now() - start) / 1000;<br>    httpRequestDuration<br>      .labels(req.method, req.route?.path || req.path, res.statusCode)<br>      .observe(duration);<br>  });<br>  <br>  next();<br>});<br></code></pre><br><br><h2>2.4 Analyse et Interpr√©tation des R√©sultats</h2><br><br><h3>Lecture des Rapports JMeter</h3><br><br><strong>M√©triques Principales</strong><br><li><strong>Average</strong> : Temps de r√©ponse moyen</li><br><li><strong>Median</strong> : 50e percentile</li><br><li><strong>90% Line</strong> : 90e percentile</li><br><li><strong>95% Line</strong> : 95e percentile</li><br><li><strong>99% Line</strong> : 99e percentile</li><br><li><strong>Min/Max</strong> : Temps minimum et maximum</li><br><li><strong>Error %</strong> : Pourcentage d'erreurs</li><br><li><strong>Throughput</strong> : D√©bit (req/sec)</li><br><br><h3>Identification des Probl√®mes</h3><br><br><strong>Temps de R√©ponse √âlev√©s</strong><br><pre><code><br>Causes possibles:<br><li>Requ√™tes base de donn√©es lentes</li><br><li>Goulots d'√©tranglement r√©seau</li><br><li>Traitement CPU intensif</li><br><li>Manque de mise en cache</li><br></code></pre><br><br><strong>Taux d'Erreur √âlev√©</strong><br><pre><code><br>Types d'erreurs:<br><li>5xx: Erreurs serveur</li><br><li>4xx: Erreurs client</li><br><li>Timeouts: D√©passement de d√©lai</li><br><li>Connexions refus√©es</li><br></code></pre><br><br><h3>Optimisations Courantes</h3><br><br><strong>Base de Donn√©es</strong><br><li>Indexation appropri√©e</li><br><li>Optimisation des requ√™tes</li><br><li>Pool de connexions</li><br><li>Cache de requ√™tes</li><br><br><strong>Application</strong><br><li>Mise en cache (Redis, Memcached)</li><br><li>Optimisation des algorithmes</li><br><li>Lazy loading</li><br><li>Compression des r√©ponses</li><br><br><strong>Infrastructure</strong><br><li>Load balancing</li><br><li>CDN pour les assets statiques</li><br><li>Scaling horizontal/vertical</li><br><li>Optimisation r√©seau</li><br><br><h2>2.5 Int√©gration dans le Pipeline CI/CD</h2><br><br><h3>Tests de Performance Automatis√©s</h3><br><br><pre><code>yaml<br><h1>.github/workflows/performance.yml</h1><br>name: Performance Tests<br><br>on:<br>  push:<br>    branches: [main]<br>  pull_request:<br>    branches: [main]<br><br>jobs:<br>  performance-test:<br>    runs-on: ubuntu-latest<br>    <br>    steps:<br>    - uses: actions/checkout@v2<br>    <br>    - name: Setup JMeter<br>      run: |<br>        wget https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-5.4.1.tgz<br>        tar -xzf apache-jmeter-5.4.1.tgz<br>        <br>    - name: Run Performance Tests<br>      run: |<br>        ./apache-jmeter-5.4.1/bin/jmeter -n -t tests/load-test.jmx -l results.jtl<br>        <br>    - name: Generate Report<br>      run: |<br>        ./apache-jmeter-5.4.1/bin/jmeter -g results.jtl -o report/<br>        <br>    - name: Upload Results<br>      uses: actions/upload-artifact@v2<br>      with:<br>        name: performance-report<br>        path: report/<br></code></pre><br><br><h3>Crit√®res de Validation</h3><br><br><strong>Seuils de Performance</strong><br><pre><code>yaml<br>performance_thresholds:<br>  response_time_95th: 2000ms<br>  error_rate: 1%<br>  throughput_min: 100rps<br>  cpu_usage_max: 80%<br>  memory_usage_max: 85%<br></code></pre><br><br><strong>Alertes et Notifications</strong><br><li>√âchec si seuils d√©pass√©s</li><br><li>Notifications Slack/Teams</li><br><li>Blocage du d√©ploiement</li><br><li>Rapport automatique aux √©quipes</li><br><br><h3>Bonnes Pratiques</h3><br><br><strong>Environnement de Test</strong><br><li>Isolation des tests de performance</li><br><li>Donn√©es repr√©sentatives</li><br><li>Configuration similaire √† la production</li><br><li>Nettoyage entre les tests</li><br><br><strong>Strat√©gie de Test</strong><br><li>Tests r√©guliers (nightly builds)</li><br><li>Tests sur les features critiques</li><br><li>Comparaison avec baseline</li><br><li>Tests de r√©gression performance</li><br><br><h1>3. Tests de S√©curit√© Automatis√©s</h1><br><br><h2>3.1 Principes de S√©curit√© dans les Tests</h2><br><br><h3>Importance des Tests de S√©curit√©</h3><br><br>Les tests de s√©curit√© automatis√©s sont essentiels pour :<br><li>D√©tecter les vuln√©rabilit√©s t√¥t dans le cycle de d√©veloppement</li><br><li>R√©duire les co√ªts de correction des failles</li><br><li>Assurer la conformit√© aux standards de s√©curit√©</li><br><li>Prot√©ger les donn√©es sensibles et la r√©putation</li><br><br><h3>Types de Tests de S√©curit√©</h3><br><br><strong>Tests Statiques (SAST)</strong><br><li>Analyse du code source</li><br><li>D√©tection de patterns dangereux</li><br><li>V√©rification des bonnes pratiques</li><br><li>Outils : SonarQube, Checkmarx, Veracode</li><br><br><strong>Tests Dynamiques (DAST)</strong><br><li>Analyse de l'application en fonctionnement</li><br><li>Tests de p√©n√©tration automatis√©s</li><br><li>Scan des vuln√©rabilit√©s web</li><br><li>Outils : OWASP ZAP, Burp Suite, Nessus</li><br><br><strong>Tests Interactifs (IAST)</strong><br><li>Combinaison SAST + DAST</li><br><li>Analyse en temps r√©el</li><br><li>Contexte d'ex√©cution pr√©cis</li><br><li>Outils : Contrast Security, Checkmarx IAST</li><br><br><h3>OWASP Top 10 - Vuln√©rabilit√©s Critiques</h3><br><br>1. <strong>Injection</strong> - SQL, NoSQL, OS, LDAP<br>2. <strong>Broken Authentication</strong> - Gestion des sessions<br>3. <strong>Sensitive Data Exposure</strong> - Chiffrement insuffisant<br>4. <strong>XML External Entities (XXE)</strong> - Parseurs XML vuln√©rables<br>5. <strong>Broken Access Control</strong> - Contr√¥les d'autorisation<br>6. <strong>Security Misconfiguration</strong> - Configuration par d√©faut<br>7. <strong>Cross-Site Scripting (XSS)</strong> - Injection de scripts<br>8. <strong>Insecure Deserialization</strong> - D√©s√©rialisation non s√©curis√©e<br>9. <strong>Using Components with Known Vulnerabilities</strong> - D√©pendances<br>10. <strong>Insufficient Logging & Monitoring</strong> - Surveillance inad√©quate<br><br><h2>3.2 Scan de Vuln√©rabilit√©s avec OWASP ZAP</h2><br><br><h3>Pr√©sentation d'OWASP ZAP</h3><br><br>OWASP Zed Attack Proxy (ZAP) est un outil de test de s√©curit√© :<br><li>Scanner de vuln√©rabilit√©s web gratuit</li><br><li>Interface graphique et API</li><br><li>Proxy intercepteur</li><br><li>Extensible via add-ons</li><br><br><h3>Architecture ZAP</h3><br><br><pre><code><br>Browser ‚Üí ZAP Proxy ‚Üí Web Application<br>           ‚Üì<br>    Vulnerability Scanner<br>           ‚Üì<br>        Reports<br></code></pre><br><br><h3>Installation et Configuration</h3><br><br><strong>Installation Docker</strong><br><pre><code>bash<br><h1>T√©l√©charger l'image ZAP</h1><br>docker pull owasp/zap2docker-stable<br><br><h1>Lancer ZAP en mode daemon</h1><br>docker run -u zap -p 8080:8080 -i owasp/zap2docker-stable zap.sh -daemon -host 0.0.0.0 -port 8080<br></code></pre><br><br><strong>Configuration de Base</strong><br><pre><code>bash<br><h1>Configuration du proxy</h1><br>export ZAP_PROXY=http://localhost:8080<br><br><h1>API Key pour l'authentification</h1><br>export ZAP_API_KEY=your-api-key-here<br></code></pre><br><br><h3>Scan Automatis√© avec ZAP</h3><br><br><strong>Script de Scan Basique</strong><br><pre><code>bash<br>#!/bin/bash<br><br>TARGET_URL="http://localhost:3000"<br>ZAP_API="http://localhost:8080"<br><br><h1>D√©marrer le spider pour d√©couvrir les URLs</h1><br>curl "$ZAP_API/JSON/spider/action/scan/?url=$TARGET_URL"<br><br><h1>Attendre la fin du spider</h1><br>while [ $(curl -s "$ZAP_API/JSON/spider/view/status/" | jq -r '.status') != "100" ]; do<br>  echo "Spider en cours..."<br>  sleep 5<br>done<br><br><h1>Lancer le scan actif</h1><br>curl "$ZAP_API/JSON/ascan/action/scan/?url=$TARGET_URL"<br><br><h1>Attendre la fin du scan</h1><br>while [ $(curl -s "$ZAP_API/JSON/ascan/view/status/" | jq -r '.status') != "100" ]; do<br>  echo "Scan actif en cours..."<br>  sleep 10<br>done<br><br><h1>G√©n√©rer le rapport</h1><br>curl "$ZAP_API/OTHER/core/other/htmlreport/" > security-report.html<br></code></pre><br><br><h3>Int√©gration dans les Tests</h3><br><br><strong>Test Selenium + ZAP</strong><br><pre><code>javascript<br>const { Builder, By } = require('selenium-webdriver');<br>const proxy = require('selenium-webdriver/proxy');<br><br>describe('Security Tests', () => {<br>  let driver;<br>  <br>  beforeAll(async () => {<br>    // Configuration du proxy ZAP<br>    const zapProxy = proxy.manual({<br>      http: 'localhost:8080',<br>      https: 'localhost:8080'<br>    });<br>    <br>    driver = await new Builder()<br>      .forBrowser('chrome')<br>      .setProxy(zapProxy)<br>      .build();<br>  });<br>  <br>  it('should perform authenticated scan', async () => {<br>    // Navigation authentifi√©e<br>    await driver.get('http://localhost:3000/login');<br>    await driver.findElement(By.id('username')).sendKeys('testuser');<br>    await driver.findElement(By.id('password')).sendKeys('password');<br>    await driver.findElement(By.css('button[type="submit"]')).click();<br>    <br>    // Navigation dans l'application<br>    await driver.get('http://localhost:3000/dashboard');<br>    await driver.get('http://localhost:3000/profile');<br>    await driver.get('http://localhost:3000/settings');<br>    <br>    // ZAP enregistre automatiquement toutes les requ√™tes<br>  });<br>});<br></code></pre><br><br><h2>3.3 Analyse des D√©pendances avec Snyk</h2><br><br><h3>Pr√©sentation de Snyk</h3><br><br>Snyk est une plateforme de s√©curit√© pour les d√©veloppeurs :<br><li>Scan des d√©pendances open source</li><br><li>D√©tection des vuln√©rabilit√©s connues</li><br><li>Suggestions de correction automatiques</li><br><li>Int√©gration CI/CD native</li><br><br><h3>Types de Scans Snyk</h3><br><br><strong>Snyk Open Source</strong><br><li>Vuln√©rabilit√©s dans les d√©pendances</li><br><li>Licences probl√©matiques</li><br><li>Suggestions de mise √† jour</li><br><br><strong>Snyk Code</strong><br><li>Analyse statique du code</li><br><li>D√©tection de failles de s√©curit√©</li><br><li>Recommandations de correction</li><br><br><strong>Snyk Container</strong><br><li>Scan des images Docker</li><br><li>Vuln√©rabilit√©s du syst√®me de base</li><br><li>Optimisation des images</li><br><br><strong>Snyk Infrastructure as Code</strong><br><li>Scan des fichiers Terraform, Kubernetes</li><br><li>D√©tection de mauvaises configurations</li><br><li>Bonnes pratiques de s√©curit√©</li><br><br><h3>Installation et Utilisation</h3><br><br><strong>Installation CLI</strong><br><pre><code>bash<br><h1>Installation via npm</h1><br>npm install -g snyk<br><br><h1>Authentification</h1><br>snyk auth<br><br><h1>Scan du projet</h1><br>snyk test<br><br><h1>Scan avec rapport JSON</h1><br>snyk test --json > security-report.json<br></code></pre><br><br><h3>Int√©gration dans le Pipeline</h3><br><br><strong>GitHub Actions avec Snyk</strong><br><pre><code>yaml<br>name: Security Scan<br><br>on: [push, pull_request]<br><br>jobs:<br>  security:<br>    runs-on: ubuntu-latest<br>    <br>    steps:<br>    - uses: actions/checkout@v2<br>    <br>    - name: Setup Node.js<br>      uses: actions/setup-node@v2<br>      with:<br>        node-version: '16'<br>        <br>    - name: Install dependencies<br>      run: npm ci<br>      <br>    - name: Run Snyk to check for vulnerabilities<br>      uses: snyk/actions/node@master<br>      env:<br>        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}<br>      with:<br>        args: --severity-threshold=high<br>        <br>    - name: Upload result to GitHub Code Scanning<br>      uses: github/codeql-action/upload-sarif@v1<br>      with:<br>        sarif_file: snyk.sarif<br></code></pre><br><br><h3>Configuration Avanc√©e</h3><br><br><strong>Fichier .snyk</strong><br><pre><code>yaml<br><h1>Ignorer certaines vuln√©rabilit√©s temporairement</h1><br>ignore:<br>  SNYK-JS-LODASH-567746:<br>    - '*':<br>        reason: 'Pas de fix disponible, risque acceptable'<br>        expires: '2024-12-31T23:59:59.999Z'<br><br><h1>Patches automatiques</h1><br>patches:<br>  SNYK-JS-MINIMIST-559764:<br>    - tap > nyc > minimist:<br>        patched: '2021-03-15T10:00:00.000Z'<br><br><h1>Exclusions de chemins</h1><br>exclude:<br>  global:<br>    - test/<em></em><br>    - docs/<em></em><br></code></pre><br><br><h2>3.4 Int√©gration dans le Pipeline CI/CD</h2><br><br><h3>Pipeline de S√©curit√© Complet</h3><br><br><pre><code>yaml<br><h1>.github/workflows/security.yml</h1><br>name: Security Pipeline<br><br>on:<br>  push:<br>    branches: [main, develop]<br>  pull_request:<br>    branches: [main]<br><br>jobs:<br>  dependency-scan:<br>    name: Dependency Vulnerability Scan<br>    runs-on: ubuntu-latest<br>    <br>    steps:<br>    - uses: actions/checkout@v2<br>    <br>    - name: Snyk Dependency Scan<br>      uses: snyk/actions/node@master<br>      env:<br>        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}<br>      with:<br>        args: --severity-threshold=medium<br>        <br>  code-scan:<br>    name: Static Code Analysis<br>    runs-on: ubuntu-latest<br>    <br>    steps:<br>    - uses: actions/checkout@v2<br>    <br>    - name: SonarCloud Scan<br>      uses: SonarSource/sonarcloud-github-action@master<br>      env:<br>        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}<br>        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}<br>        <br>  dynamic-scan:<br>    name: Dynamic Security Testing<br>    runs-on: ubuntu-latest<br>    needs: [dependency-scan, code-scan]<br>    <br>    steps:<br>    - uses: actions/checkout@v2<br>    <br>    - name: Start Application<br>      run: |<br>        docker-compose up -d<br>        sleep 30<br>        <br>    - name: OWASP ZAP Scan<br>      uses: zaproxy/action-full-scan@v0.4.0<br>      with:<br>        target: 'http://localhost:3000'<br>        rules_file_name: '.zap/rules.tsv'<br>        cmd_options: '-a'<br>        <br>    - name: Stop Application<br>      run: docker-compose down<br></code></pre><br><br><h3>Gestion des R√©sultats</h3><br><br><strong>Seuils de S√©curit√©</strong><br><pre><code>yaml<br>security_thresholds:<br>  critical_vulnerabilities: 0<br>  high_vulnerabilities: 2<br>  medium_vulnerabilities: 10<br>  low_vulnerabilities: 50<br>  <br>quality_gates:<br>  block_deployment_on_critical: true<br>  require_approval_on_high: true<br>  notify_team_on_medium: true<br></code></pre><br><br><strong>Rapports et Notifications</strong><br><pre><code>javascript<br>// Exemple de notification Slack<br>const sendSecurityAlert = async (vulnerabilities) => {<br>  const criticalCount = vulnerabilities.filter(v => v.severity === 'critical').length;<br>  const highCount = vulnerabilities.filter(v => v.severity === 'high').length;<br>  <br>  if (criticalCount > 0 || highCount > 5) {<br>    await slack.chat.postMessage({<br>      channel: '#security-alerts',<br>      text: <code>üö® Vuln√©rabilit√©s d√©tect√©es: ${criticalCount} critiques, ${highCount} √©lev√©es</code>,<br>      attachments: [{<br>        color: 'danger',<br>        fields: vulnerabilities.slice(0, 5).map(v => ({<br>          title: v.title,<br>          value: <code>S√©v√©rit√©: ${v.severity}\nCVE: ${v.cve}</code>,<br>          short: true<br>        }))<br>      }]<br>    });<br>  }<br>};<br></code></pre><br><br><h2>3.5 Bonnes Pratiques de S√©curit√©</h2><br><br><h3>Shift-Left Security</h3><br><br><strong>Int√©gration Pr√©coce</strong><br><li>Tests de s√©curit√© d√®s le d√©veloppement</li><br><li>Formation des d√©veloppeurs</li><br><li>Outils int√©gr√©s dans l'IDE</li><br><li>Revues de code s√©curis√©es</li><br><br><strong>Automatisation Compl√®te</strong><br><li>Scans √† chaque commit</li><br><li>Validation des pull requests</li><br><li>D√©ploiement conditionnel</li><br><li>Monitoring continu</li><br><br><h3>Gestion des Secrets</h3><br><br><strong>Bonnes Pratiques</strong><br><pre><code>yaml<br><h1>Mauvais - secrets en dur</h1><br>database_url: "postgresql://user:password@localhost/db"<br><br><h1>Bon - utilisation de variables d'environnement</h1><br>database_url: "${DATABASE_URL}"<br></code></pre><br><br><strong>Outils de Gestion</strong><br><li>HashiCorp Vault</li><br><li>AWS Secrets Manager</li><br><li>Azure Key Vault</li><br><li>Kubernetes Secrets</li><br><br><h3>Monitoring et R√©ponse</h3><br><br><strong>D√©tection d'Intrusion</strong><br><li>Logs d'acc√®s anormaux</li><br><li>Tentatives d'authentification</li><br><li>Patterns d'attaque connus</li><br><li>Alertes en temps r√©el</li><br><br><strong>Plan de R√©ponse</strong><br>1. D√©tection automatique<br>2. Isolation des syst√®mes<br>3. Analyse forensique<br>4. Correction et patch<br>5. Post-mortem et am√©lioration<br><br><h1>4. Environnements de Test Cloud</h1><br><br><h2>4.1 Avantages des Environnements Cloud</h2><br><br><h3>B√©n√©fices Principaux</h3><br><br><strong>Scalabilit√© √âlastique</strong><br><li>Adaptation automatique √† la charge</li><br><li>Provisioning rapide des ressources</li><br><li>Tests de mont√©e en charge r√©alistes</li><br><li>Optimisation des co√ªts</li><br><br><strong>Disponibilit√© Globale</strong><br><li>Tests multi-r√©gions</li><br><li>Simulation de latence r√©seau</li><br><li>Validation de la g√©o-r√©plication</li><br><li>Tests de disaster recovery</li><br><br><strong>Diversit√© des Environnements</strong><br><li>Multiples OS et navigateurs</li><br><li>Versions diff√©rentes des runtime</li><br><li>Configurations mat√©rielles vari√©es</li><br><li>Tests de compatibilit√© √©tendus</li><br><br><h3>Comparaison Cloud vs On-Premise</h3><br><br>| Aspect | Cloud | On-Premise |<br>|--------|-------|------------|<br>| <strong>Co√ªt initial</strong> | Faible | √âlev√© |<br>| <strong>Maintenance</strong> | G√©r√©e par le provider | √Ä charge de l'√©quipe |<br>| <strong>Scalabilit√©</strong> | √âlastique | Limit√©e par le mat√©riel |<br>| <strong>S√©curit√©</strong> | Partag√©e | Contr√¥le total |<br>| <strong>Latence</strong> | Variable | Pr√©visible |<br>| <strong>Compliance</strong> | D√©pend du provider | Contr√¥le total |<br><br><h2>4.2 Plateformes de Test Cloud</h2><br><br><h3>BrowserStack</h3><br><br><strong>Fonctionnalit√©s Cl√©s</strong><br><li>3000+ combinaisons navigateur/OS</li><br><li>Tests en temps r√©el et automatis√©s</li><br><li>Debugging interactif</li><br><li>Int√©gration CI/CD native</li><br><br><strong>Exemple d'Int√©gration</strong><br><pre><code>javascript<br>// Configuration BrowserStack<br>const capabilities = {<br>  'browserName': 'Chrome',<br>  'browserVersion': 'latest',<br>  'os': 'Windows',<br>  'osVersion': '10',<br>  'buildName': 'CI Build #123',<br>  'sessionName': 'Login Test',<br>  'local': 'false'<br>};<br><br>const driver = new webdriver.Builder()<br>  .usingServer('https://hub-cloud.browserstack.com/wd/hub')<br>  .withCapabilities(capabilities)<br>  .build();<br></code></pre><br><br><h3>Sauce Labs</h3><br><br><strong>Avantages Sp√©cifiques</strong><br><li>Tests sur appareils mobiles r√©els</li><br><li>Analytics et insights d√©taill√©s</li><br><li>Tests de performance int√©gr√©s</li><br><li>Support des frameworks populaires</li><br><br><strong>Configuration CI/CD</strong><br><pre><code>yaml<br><h1>GitHub Actions avec Sauce Labs</h1><br><li>name: Run Tests on Sauce Labs</li><br>  env:<br>    SAUCE_USERNAME: ${{ secrets.SAUCE_USERNAME }}<br>    SAUCE_ACCESS_KEY: ${{ secrets.SAUCE_ACCESS_KEY }}<br>  run: |<br>    npm test -- --sauce<br></code></pre><br><br><h3>AWS Device Farm</h3><br><br><strong>Sp√©cificit√©s AWS</strong><br><li>Tests sur appareils mobiles physiques</li><br><li>Int√©gration native avec AWS</li><br><li>Tests automatis√©s et exploratoires</li><br><li>Rapports d√©taill√©s avec captures</li><br><br><h3>Kubernetes pour Tests</h3><br><br><strong>Avantages de K8s</strong><br><li>Orchestration des environnements de test</li><br><li>Isolation des tests</li><br><li>Scaling automatique</li><br><li>Gestion des ressources</li><br><br><strong>Exemple de D√©ploiement</strong><br><pre><code>yaml<br>apiVersion: apps/v1<br>kind: Deployment<br>metadata:<br>  name: test-environment<br>spec:<br>  replicas: 3<br>  selector:<br>    matchLabels:<br>      app: test-app<br>  template:<br>    metadata:<br>      labels:<br>        app: test-app<br>    spec:<br>      containers:<br>      - name: app<br>        image: myapp:test<br>        ports:<br>        - containerPort: 3000<br>        env:<br>        - name: NODE_ENV<br>          value: "test"<br>        - name: DATABASE_URL<br>          valueFrom:<br>            secretKeyRef:<br>              name: db-secret<br>              key: url<br></code></pre><br><br><h2>4.3 Configuration et Orchestration</h2><br><br><h3>Infrastructure as Code (IaC)</h3><br><br><strong>Terraform pour AWS</strong><br><pre><code>hcl<br><h1>Environnement de test automatis√©</h1><br>resource "aws_instance" "test_server" {<br>  count         = var.test_instances<br>  ami           = "ami-0c55b159cbfafe1d0"<br>  instance_type = "t3.medium"<br>  <br>  tags = {<br>    Name        = "test-server-${count.index}"<br>    Environment = "testing"<br>    Purpose     = "automated-testing"<br>  }<br>  <br>  user_data = <<-EOF<br>    #!/bin/bash<br>    docker run -d -p 80:3000 myapp:${var.app_version}<br>    docker run -d -p 8080:8080 owasp/zap2docker-stable<br>  EOF<br>}<br><br>resource "aws_lb" "test_lb" {<br>  name               = "test-load-balancer"<br>  internal           = false<br>  load_balancer_type = "application"<br>  <br>  dynamic "subnet_mapping" {<br>    for_each = aws_instance.test_server<br>    content {<br>      subnet_id = subnet_mapping.value.subnet_id<br>    }<br>  }<br>}<br></code></pre><br><br><strong>Docker Compose pour Environnements Locaux</strong><br><pre><code>yaml<br>version: '3.8'<br><br>services:<br>  app:<br>    build: .<br>    ports:<br>      - "3000:3000"<br>    environment:<br>      - NODE_ENV=test<br>      - DATABASE_URL=postgresql://test:test@db:5432/testdb<br>    depends_on:<br>      - db<br>      - redis<br>    <br>  db:<br>    image: postgres:13<br>    environment:<br>      - POSTGRES_DB=testdb<br>      - POSTGRES_USER=test<br>      - POSTGRES_PASSWORD=test<br>    volumes:<br>      - test_db_data:/var/lib/postgresql/data<br>    <br>  redis:<br>    image: redis:6-alpine<br>    <br>  selenium-hub:<br>    image: selenium/hub:4.0.0<br>    ports:<br>      - "4444:4444"<br>    <br>  selenium-chrome:<br>    image: selenium/node-chrome:4.0.0<br>    depends_on:<br>      - selenium-hub<br>    environment:<br>      - HUB_HOST=selenium-hub<br>    <br>  zap:<br>    image: owasp/zap2docker-stable<br>    ports:<br>      - "8080:8080"<br>    command: zap.sh -daemon -host 0.0.0.0 -port 8080<br><br>volumes:<br>  test_db_data:<br></code></pre><br><br><h3>Gestion des Donn√©es de Test</h3><br><br><strong>Strat√©gies de Donn√©es</strong><br><pre><code>javascript<br>// Factory pour g√©n√©ration de donn√©es<br>class TestDataFactory {<br>  static createUser(overrides = {}) {<br>    return {<br>      id: faker.datatype.uuid(),<br>      name: faker.name.findName(),<br>      email: faker.internet.email(),<br>      createdAt: faker.date.recent(),<br>      ...overrides<br>    };<br>  }<br>  <br>  static createProduct(overrides = {}) {<br>    return {<br>      id: faker.datatype.uuid(),<br>      name: faker.commerce.productName(),<br>      price: faker.commerce.price(),<br>      category: faker.commerce.department(),<br>      ...overrides<br>    };<br>  }<br>}<br><br>// Seeding de base de donn√©es<br>const seedDatabase = async () => {<br>  await db.users.deleteMany({});<br>  await db.products.deleteMany({});<br>  <br>  const users = Array.from({ length: 100 }, () => TestDataFactory.createUser());<br>  const products = Array.from({ length: 50 }, () => TestDataFactory.createProduct());<br>  <br>  await db.users.insertMany(users);<br>  await db.products.insertMany(products);<br>};<br></code></pre><br><br><h2>4.4 Optimisation des Co√ªts et Performances</h2><br><br><h3>Strat√©gies d'Optimisation des Co√ªts</h3><br><br><strong>Scheduling Intelligent</strong><br><pre><code>yaml<br><h1>Tests programm√©s pendant les heures creuses</h1><br>schedule:<br>  - cron: '0 2 <em> </em> *'  # 2h du matin UTC<br>    branches: [main]<br>    <br>  - cron: '0 14 <em> </em> 1-5'  # 14h en semaine<br>    branches: [develop]<br></code></pre><br><br><strong>Auto-scaling Bas√© sur la Charge</strong><br><pre><code>yaml<br>apiVersion: autoscaling/v2<br>kind: HorizontalPodAutoscaler<br>metadata:<br>  name: test-app-hpa<br>spec:<br>  scaleTargetRef:<br>    apiVersion: apps/v1<br>    kind: Deployment<br>    name: test-app<br>  minReplicas: 1<br>  maxReplicas: 10<br>  metrics:<br>  - type: Resource<br>    resource:<br>      name: cpu<br>      target:<br>        type: Utilization<br>        averageUtilization: 70<br></code></pre><br><br><strong>Spot Instances pour Tests</strong><br><pre><code>hcl<br>resource "aws_spot_instance_request" "test_spot" {<br>  ami           = "ami-0c55b159cbfafe1d0"<br>  instance_type = "c5.large"<br>  spot_price    = "0.05"<br>  <br>  tags = {<br>    Name = "test-spot-instance"<br>  }<br>  <br>  # Arr√™t automatique apr√®s 2h<br>  user_data = <<-EOF<br>    #!/bin/bash<br>    echo "sudo shutdown -h +120" | at now<br>  EOF<br>}<br></code></pre><br><br><h3>Optimisation des Performances</h3><br><br><strong>Mise en Cache des Artefacts</strong><br><pre><code>yaml<br><h1>GitHub Actions avec cache</h1><br><li>name: Cache Dependencies</li><br>  uses: actions/cache@v2<br>  with:<br>    path: |<br>      ~/.npm<br>      node_modules<br>    key: ${{ runner.os }}-node-${{ hashFiles('<em></em>/package-lock.json') }}<br>    <br><li>name: Cache Docker Layers</li><br>  uses: actions/cache@v2<br>  with:<br>    path: /tmp/.buildx-cache<br>    key: ${{ runner.os }}-buildx-${{ github.sha }}<br>    restore-keys: |<br>      ${{ runner.os }}-buildx-<br></code></pre><br><br><strong>Parall√©lisation des Tests</strong><br><pre><code>javascript<br>// Configuration Jest pour tests parall√®les<br>module.exports = {<br>  maxWorkers: '50%',<br>  testPathIgnorePatterns: ['/node_modules/', '/build/'],<br>  setupFilesAfterEnv: ['<rootDir>/src/setupTests.js'],<br>  <br>  // Groupement des tests par type<br>  projects: [<br>    {<br>      displayName: 'unit',<br>      testMatch: ['<rootDir>/src/<em></em>/*.test.js']<br>    },<br>    {<br>      displayName: 'integration',<br>      testMatch: ['<rootDir>/tests/integration/<em></em>/*.test.js']<br>    },<br>    {<br>      displayName: 'e2e',<br>      testMatch: ['<rootDir>/tests/e2e/<em></em>/*.test.js'],<br>      maxWorkers: 1  // Tests E2E s√©quentiels<br>    }<br>  ]<br>};<br></code></pre><br><br><h2>4.5 Bonnes Pratiques de D√©ploiement</h2><br><br><h3>Environnements √âph√©m√®res</h3><br><br><strong>Pull Request Environments</strong><br><pre><code>yaml<br>name: PR Environment<br><br>on:<br>  pull_request:<br>    types: [opened, synchronize]<br><br>jobs:<br>  deploy-pr-env:<br>    runs-on: ubuntu-latest<br>    <br>    steps:<br>    - name: Deploy to PR Environment<br>      run: |<br>        # Cr√©er un environnement unique pour la PR<br>        ENV_NAME="pr-${{ github.event.number }}"<br>        <br>        # D√©ployer l'application<br>        kubectl create namespace $ENV_NAME<br>        kubectl apply -f k8s/ -n $ENV_NAME<br>        <br>        # Configurer l'URL unique<br>        echo "Environment URL: https://$ENV_NAME.test.example.com"<br>        <br>    - name: Run Tests Against PR Environment<br>      run: |<br>        export TEST_URL="https://pr-${{ github.event.number }}.test.example.com"<br>        npm run test:e2e<br></code></pre><br><br><h3>Blue-Green Deployment pour Tests</h3><br><br><pre><code>yaml<br><h1>Configuration Blue-Green</h1><br>apiVersion: v1<br>kind: Service<br>metadata:<br>  name: app-service<br>spec:<br>  selector:<br>    app: myapp<br>    version: blue  # Bascule entre blue et green<br>  ports:<br>  - port: 80<br>    targetPort: 3000<br><br>---<br><h1>D√©ploiement Green (nouvelle version)</h1><br>apiVersion: apps/v1<br>kind: Deployment<br>metadata:<br>  name: app-green<br>spec:<br>  replicas: 3<br>  selector:<br>    matchLabels:<br>      app: myapp<br>      version: green<br>  template:<br>    metadata:<br>      labels:<br>        app: myapp<br>        version: green<br>    spec:<br>      containers:<br>      - name: app<br>        image: myapp:v2.0.0<br></code></pre><br><br><h3>Monitoring et Observabilit√©</h3><br><br><strong>M√©triques Personnalis√©es</strong><br><pre><code>javascript<br>// M√©triques de test avec Prometheus<br>const promClient = require('prom-client');<br><br>const testExecutionTime = new promClient.Histogram({<br>  name: 'test_execution_duration_seconds',<br>  help: 'Time spent executing tests',<br>  labelNames: ['test_suite', 'environment', 'status']<br>});<br><br>const testResults = new promClient.Counter({<br>  name: 'test_results_total',<br>  help: 'Total number of test results',<br>  labelNames: ['test_suite', 'status', 'environment']<br>});<br><br>// Utilisation dans les tests<br>const startTime = Date.now();<br>try {<br>  await runTestSuite();<br>  testResults.labels('e2e', 'passed', 'staging').inc();<br>} catch (error) {<br>  testResults.labels('e2e', 'failed', 'staging').inc();<br>} finally {<br>  const duration = (Date.now() - startTime) / 1000;<br>  testExecutionTime.labels('e2e', 'staging', 'completed').observe(duration);<br>}<br></code></pre><br><br><strong>Dashboards Grafana</strong><br><pre><code>json<br>{<br>  "dashboard": {<br>    "title": "Test Environment Monitoring",<br>    "panels": [<br>      {<br>        "title": "Test Success Rate",<br>        "type": "stat",<br>        "targets": [<br>          {<br>            "expr": "rate(test_results_total{status=\"passed\"}[5m]) / rate(test_results_total[5m]) * 100"<br>          }<br>        ]<br>      },<br>      {<br>        "title": "Test Execution Time",<br>        "type": "graph",<br>        "targets": [<br>          {<br>            "expr": "histogram_quantile(0.95, test_execution_duration_seconds_bucket)"<br>          }<br>        ]<br>      }<br>    ]<br>  }<br>}<br></code></pre><br><br><h1>Module 3 - Tests Fonctionnels et Non-Fonctionnels</h1><br><br><h2>Vue d'ensemble</h2><br><br>Ce module couvre les aspects essentiels des tests automatis√©s dans un environnement CI/CD, en se concentrant sur les tests fonctionnels et non-fonctionnels. Les apprenants d√©couvriront les outils et techniques pour automatiser les tests UI, API, de performance et de s√©curit√©.<br><br><h2>Objectifs p√©dagogiques</h2><br><br>√Ä l'issue de ce module, les apprenants seront capables de :<br><br><li>Impl√©menter des tests UI automatis√©s avec Selenium et Cypress</li><br><li>Cr√©er des tests API robustes avec Postman et RestAssured</li><br><li>Configurer des tests de performance et de charge avec JMeter</li><br><li>Mettre en place des tests de s√©curit√© automatis√©s avec OWASP ZAP</li><br><li>Utiliser les environnements de test cloud pour l'optimisation</li><br><li>Int√©grer ces tests dans un pipeline CI/CD complet</li><br><br><h2>Structure du contenu</h2><br><br>1. <strong>Tests Fonctionnels Automatis√©s</strong> (12 slides)<br>   - Introduction aux tests fonctionnels<br>   - Tests UI avec Selenium et Cypress<br>   - Tests API avec Postman et RestAssured<br>   - Strat√©gies de test et bonnes pratiques<br><br>2. <strong>Tests de Performance et de Charge</strong> (10 slides)<br>   - Concepts de performance et m√©triques cl√©s<br>   - Tests de charge avec JMeter<br>   - Monitoring des temps de r√©ponse<br>   - Analyse et interpr√©tation des r√©sultats<br><br>3. <strong>Tests de S√©curit√© Automatis√©s</strong> (8 slides)<br>   - Principes de s√©curit√© dans les tests<br>   - Scan de vuln√©rabilit√©s avec OWASP ZAP<br>   - Analyse des d√©pendances avec Snyk<br>   - Int√©gration dans le pipeline CI/CD<br><br>4. <strong>Environnements de Test Cloud</strong> (5 slides)<br>   - Avantages des environnements cloud<br>   - Configuration et orchestration<br>   - Optimisation des co√ªts et performances<br>   - Bonnes pratiques de d√©ploiement<br><br><h2>Dur√©e estim√©e</h2><br><br><li><strong>Th√©orie</strong> : 2h30</li><br><li><strong>Exercices pratiques</strong> : 4h</li><br><li><strong>QCM et synth√®se</strong> : 30min</li><br><li><strong>Total</strong> : 7h (1,5 jour)</li><br><br><h2>Pr√©requis</h2><br><br><li>Connaissances de base en d√©veloppement web</li><br><li>Familiarit√© avec les concepts CI/CD (Module 1)</li><br><li>Compr√©hension des tests automatis√©s</li><br><li>Acc√®s aux outils : Selenium, Cypress, JMeter, OWASP ZAP</li><br><br><h2>Ressources n√©cessaires</h2><br><br><li>Environnement de d√©veloppement configur√©</li><br><li>Applications de test (fournie)</li><br><li>Acc√®s internet pour les outils cloud</li><br><li>Comptes sur les plateformes de test (optionnel)</li><br><br>\newpage<br><br><h1>Exercices Pratiques</h1><br><br><h1>Exercices Pratiques - Module 3</h1><br><br><h2>Vue d'ensemble</h2><br><br>Ce module contient 6 exercices pratiques couvrant les tests fonctionnels et non-fonctionnels :<br><br>1. <strong>Tests UI avec Selenium et Cypress</strong> - Automatisation des tests d'interface utilisateur<br>2. <strong>Tests API avec Postman et RestAssured</strong> - Validation des services web<br>3. <strong>Simulation de charge avec JMeter</strong> - Tests de performance et de mont√©e en charge<br>4. <strong>Monitoring des temps de r√©ponse</strong> - Surveillance et m√©triques de performance<br>5. <strong>Scan de vuln√©rabilit√©s avec OWASP ZAP</strong> - Tests de s√©curit√© automatis√©s<br>6. <strong>Analyse des d√©pendances avec Snyk</strong> - D√©tection de vuln√©rabilit√©s dans les d√©pendances<br><br><h2>Pr√©requis Techniques</h2><br><br><li>Node.js 16+ et npm</li><br><li>Java 11+ (pour RestAssured et JMeter)</li><br><li>Docker et Docker Compose</li><br><li>Git</li><br><li>Navigateur Chrome/Firefox</li><br><br><h2>Installation des Outils</h2><br><br><pre><code>bash<br><h1>Installation des d√©pendances Node.js</h1><br>npm install -g @cypress/cli selenium-webdriver<br><br><h1>Installation de JMeter</h1><br>wget https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-5.4.1.tgz<br>tar -xzf apache-jmeter-5.4.1.tgz<br><br><h1>Installation de Snyk CLI</h1><br>npm install -g snyk<br><br><h1>Images Docker n√©cessaires</h1><br>docker pull owasp/zap2docker-stable<br>docker pull selenium/standalone-chrome<br></code></pre><br><br><h2>Structure des Exercices</h2><br><br>Chaque exercice suit la m√™me structure :<br><li><code>README.md</code> - Instructions d√©taill√©es</li><br><li><code>ressources/</code> - Code de base et fichiers de configuration</li><br><li><code>solution/</code> - Solution compl√®te avec explications</li><br><br><h2>Dur√©e Estim√©e</h2><br><br><li><strong>Exercice 3.1</strong> : 45 minutes</li><br><li><strong>Exercice 3.2</strong> : 45 minutes  </li><br><li><strong>Exercice 3.3</strong> : 60 minutes</li><br><li><strong>Exercice 3.4</strong> : 30 minutes</li><br><li><strong>Exercice 3.5</strong> : 45 minutes</li><br><li><strong>Exercice 3.6</strong> : 30 minutes</li><br><br><strong>Total</strong> : 4h15 (avec pauses et discussions)<br><br><h2>Ordre Recommand√©</h2><br><br>1. Commencer par les tests UI (3.1) pour √©tablir les bases<br>2. Encha√Æner avec les tests API (3.2) pour la compl√©mentarit√©<br>3. Aborder les tests de performance (3.3 et 3.4) ensemble<br>4. Terminer par la s√©curit√© (3.5 et 3.6) pour une approche compl√®te<br><br>
</body>
</html>